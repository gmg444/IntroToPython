{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API and SQL Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoplace_key for Mexico is 3996063 (you can look this up using the /lookup/location end point).  Using the /list/grants apibeta endpoint, add up the total amount of the top 10 grants to recipients in Mexico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705423747\n",
      "705423747\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json as js\n",
    "\n",
    "s = requests.Session()\n",
    "s.auth = ([provided in class])\n",
    "\n",
    "r = s.get('https://apibeta.foundationcenter.org/v2.0/list/grants?location=3996063&year=&subject=&population=&support=&transaction=&recip_id=&funder_id=&sort_by=amount&sort_order=desc&format=json')\n",
    "\n",
    "obj = js.loads(r.text)\n",
    "\n",
    "total = 0\n",
    "for row in obj['data']['results']:\n",
    "    total += row['amount_usd']\n",
    "print(total)\n",
    "    \n",
    "my_lst = [row['amount_usd'] for row in obj['data']['results']]  \n",
    "print(sum(my_lst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposed we wanted to get place identifiers mentioned in the grantmaker limitations text, for grantmakes located in Brooklyn.  You can get this text from the fc_sample database with a query like the following:\n",
    "\n",
    "SELECT a.fcdbwin_gm_key, \n",
    "       a.NAME, \n",
    "       b.description \n",
    "FROM   grantmaker a \n",
    "       INNER JOIN long_text b \n",
    "               ON a.gm_key = b.gm_key \n",
    "WHERE  b.text_type = 'LM' \n",
    "       AND a.state = 'NY' \n",
    "       AND a.county = 'Kings' \n",
    "       \n",
    "The api call has this format:\n",
    "\n",
    "https://apibeta.foundationcenter.org/v2.0/text/locations?text=[text]\n",
    "\n",
    "Write a program that gets the unique geoplace_keys referenced in this text for those grantmakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposed we wanted to get a sense of how grant funding is distributed among SDGs (sustainable development goals) for smal Ford Foundation grants in 2011.  ApiBeta has an endpoint that does this, text/taxonomies.  Here is a sample API call:\n",
    "\n",
    "https://apibeta.foundationcenter.org/v2.0/text/taxonomies?text=[text]&taxonomy=sdg&threshold=60&chunk_text=false\n",
    " \n",
    "We can get the grant description texts using a query something like this:\n",
    "\n",
    "SELECT grant_key, \n",
    "       description, \n",
    "       amount \n",
    "FROM   grants a \n",
    "       INNER JOIN grantmaker b \n",
    "               ON a.gm_link = b.gm_key \n",
    "WHERE  b.fcdbwin_gm_key = 'FORD010' \n",
    "       AND Year(a.date_issued) = 2011 \n",
    "       AND amount < 50000 \n",
    "       AND Len(Isnull(description, '')) > 100 \n",
    "\n",
    "Using the python features we've covered in class about dictionaries, sql, and web services, write a program that gets the grant descriptions and amounts from the database, gets the SDG goal codes based on the grant text, and sums up the grant amounts per SDG goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers\n",
    "\n",
    "From our class session on these problems - note that this code won't run within a notebook - you will need to create the geo file and call it from your main python code outside of the notebook, e.g., within pycharm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Contents of geo.py:\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "s = requests.Session()\n",
    "s.auth = ('[provided in class]', '[provided in class]')\n",
    "\n",
    "def anything(item):\n",
    "\n",
    "    r = s.get('https://apibeta.foundationcenter.org/v2.0/text/locations?text=' + item)\n",
    "\n",
    "    obj = json.loads(r.text)\n",
    "    lst = obj[\"data\"][\"results\"]\n",
    "    x = []\n",
    "\n",
    "    for i in range(len(lst)):\n",
    "        y = lst[i][\"geoplace_key\"]\n",
    "        z = lst[i][\"name\"]\n",
    "        r = (y, z)\n",
    "        x.append(r)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Content of main script file:\n",
    "\n",
    "import pyodbc\n",
    "import geo\n",
    "\n",
    "cnxn = pyodbc.connect(\"DRIVER={SQL Server};SERVER=172.16.7.121;DATABASE=fc_sample;uid=python_class_user;pwd=[provided in class]\")\n",
    "sql = \"SELECT top 10 a.fcdbwin_gm_key, a.NAME, b.description FROM grantmaker a INNER JOIN long_text b ON a.gm_key = b.gm_key WHERE b.text_type = 'LM' AND a.state = 'NY' AND a.county = 'Kings'\"\n",
    "cursor = cnxn.cursor()\n",
    "limitation = []\n",
    "\n",
    "for row in cursor.execute(sql):\n",
    "    limitation.append(row[2])\n",
    "\n",
    "cursor.close()\n",
    "q = []\n",
    "\n",
    "for item in limitation:\n",
    "    x = geo.anything(item)\n",
    "    q.append(x)\n",
    "pair = zip(q, limitation)\n",
    "\n",
    "print(list(pair))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Word Count and Grantmaker Similarity\n",
    "\n",
    "The challenge is to write a program that reads the grantmaker mission statements, and finds the most similar grantmaker based on their mission statements.  We can judge similarity by looking at the words that the mission statements have in common. \n",
    "\n",
    "To keep this manageable, let's just look at the grantmakers in California, and see which one is the most similar to PETCO Foundation (PETC003) based in their mission statements.\n",
    "\n",
    "    SELECT a.gm_key\n",
    "         ,NAME\n",
    "         ,description purpose\n",
    "    FROM grantmaker a\n",
    "    INNER JOIN long_text b ON a.gm_key = b.gm_key\n",
    "    WHERE IsNull(b.text_type, '') = 'PU'\n",
    "    amd state = 'CA'\n",
    "\n",
    "We can do this by creating a dictionary where each grantmaker has a key, and each dictionary is a dictionary of the words in the mission statement along with its count.\n",
    "\n",
    "In the simplest case, we can try to which is the most similar to PETCO Foundation by looking at each of the words in our vocabulary (stored in a separate set), and incremening a per-grantmaker score by each word found in common.  \n",
    "\n",
    "Then we can sort the results by score descending and seeing which grantmaker is the most similar.\n",
    "\n",
    "What is the most similar grantmaker according to this method?\n",
    "\n",
    "One possible improvement is to weight their score by penalizing words that are common, and weighting higher those words that are rare.  One easy was to do this is by multiplying the score by a weight calculated by multiplying these two terms together: \n",
    "\n",
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).\n",
    "\n",
    "tf-idf weight = TF * IDF, for each term\n",
    "\n",
    "### Here is some starting code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-16202c70dedf>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-16202c70dedf>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    cursor.close()\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import math\n",
    "\n",
    "cnxn = pyodbc.connect(\"DRIVER={SQL Server};SERVER=172.16.7.121;DATABASE=fc_sample;uid=[provided in class];pwd=[provided in class]\")\n",
    "sql = \"\"\"\n",
    "    SELECT a.fcdbwin_gm_key\n",
    "         ,description purpose\n",
    "    FROM grantmaker a\n",
    "    INNER JOIN long_text b ON a.gm_key = b.gm_key\n",
    "    WHERE IsNull(b.text_type, '') = 'PU'\n",
    "    and state = 'CA'\n",
    "    \"\"\"\n",
    "\n",
    "cursor = cnxn.cursor()\n",
    "gms = dict()\n",
    "vocabulary = set()\n",
    "\n",
    "for row in cursor.execute(sql):\n",
    "    # Create a word count dictionary for each grantmakers\n",
    "    # Add each word to the vocabulary\n",
    "\n",
    "cursor.close()\n",
    "\n",
    "# Get the counts for Petco\n",
    "source_counts = gms['PETC003']\n",
    "scores = dict()\n",
    "for k in gms.keys():\n",
    "    if k == 'PETC003':\n",
    "        continue\n",
    "    # For each vocabulary term, increase the score for those that appear in both\n",
    "    word_counts = gms[k]\n",
    "\n",
    "# Sort the scores descending and see which is closest to Petco.\n",
    "source_counts = gms['PETC003']\n",
    "scores = dict()\n",
    "counter = 0\n",
    "for k in gms.keys():\n",
    "    if k == 'PETC003':\n",
    "        continue\n",
    "    word_counts = gms[k]\n",
    "    score = 0.0\n",
    "    for v in vocabulary:\n",
    "        s1 = source_counts.get(v, 0)\n",
    "        s2 = word_counts.get(v, 0)\n",
    "        score += (s1 * s2) * math.log(len(gms) / doc_counts[v])\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print (counter, \"Processed\")\n",
    "    scores[k] = score\n",
    "\n",
    "num_docs = len(gms.keys())\n",
    "d = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "print (d[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
