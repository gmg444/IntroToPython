{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "Adapted from http://web.stanford.edu/~zlotnick/TextAsData/Web_Scraping_with_Beautiful_Soup.html\n",
    "\n",
    "Beautiful Soup is a handy library for dealing with messy html and other semi-structured text data. \n",
    "\n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "We can get a feel for it with a few examples.  If you visit this page, you can see that foundation names are set up as section headings.  Let's see how we could scrape these out of the html with Beautiful Soup.  \n",
    "\n",
    "http://www.climateworks.org/about-us/partners/foundation-partners/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe src=http://www.climateworks.org/about-us/partners/foundation-partners/ width=700 height=500></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "\n",
    "r = rq.get(\"http://www.climateworks.org/about-us/partners/foundation-partners/\")\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The html has a tree-like structure, which can be represented as a set of nested objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('http://www.openbookproject.net/tutorials/getdown/css/images/lesson4/HTMLDOMTree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Browsers wrap this structure up as an object, the DOM (document object model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image('http://www.cs.toronto.edu/~shiva/cscb07/img/dom/treeStructure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup does something similar.  Let's try opening up our sample html page as an object.  Once it's loaded we can start accessing the components as parts of the object it generates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "\n",
    "r = rq.get(\"http://www.climateworks.org/about-us/partners/foundation-partners/\")\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "print (soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the built-in functions to find things in the document.  Try looking around in the document and finding elements to pull out, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (soup.find_all(\"li\", id=\"menu-item-1118\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item can be accessed as an object, and we can use the object properties to access its sub elements, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag = soup.find(\"li\", id=\"menu-item-1118\")\n",
    "print(tag.name)\n",
    "print(tag[\"class\"])\n",
    "print(tag[\"id\"])\n",
    "print(tag.text)\n",
    "print(tag.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use this interface to search the entire DOM.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in soup.find_all(\"a\"):\n",
    "    print(a[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question - can you pull out the foundation names and their web site urls for ClimateWorks core funders, and put them in a list of two-element tuples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A possible answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = soup.find_all(\"h3\")\n",
    "names = []\n",
    "results = []\n",
    "for h in headers:\n",
    "    names.append(h.text)\n",
    "for a in soup.find_all(\"a\"):\n",
    "    for n in names:\n",
    "        if a.text == n:\n",
    "            results.append((n, a[\"href\"]))\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
