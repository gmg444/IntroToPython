{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "\n",
    "Based on a series of tutorials by Chris Fonnesbeck: \n",
    "\n",
    "https://github.com/fonnesbeck/statistical-analysis-python-tutorial\n",
    "\n",
    "Pandas provides a useful wrapper for tabular data, with lots of utilities for restructuring and analizing data.\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy\n",
    "\n",
    "Pandas uses the numerical python (numpy) library under the hood.  Numpy is a very high-performance multi-dimensional interface to blocks of memory that can be accessed efficiently.  See the introduction to Numpy for background information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set some Pandas options\n",
    "pd.set_option('html', False)\n",
    "pd.set_option('max_columns', 30)\n",
    "pd.set_option('max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "\n",
    "A **Series** is a single vector of data (like a NumPy array) with an *index* that labels each element in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     632\n",
       "1    1638\n",
       "2     569\n",
       "3     115\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = pd.Series([632, 1638, 569, 115])\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an index is not specified, a default sequence of integers is assigned as the index. A NumPy array comprises the values of the `Series`, while the index is a pandas `Index` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 632, 1638,  569,  115], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=4, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assign meaningful labels to the index, if they are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill & Melinda Gates Foundation        3921403840\n",
      "Schwab Charitable Fund                 1171857588\n",
      "Silicon Valley Community Foundation     964514537\n",
      "Gordon and Betty Moore Foundation       964514537\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_grantmakers_2014 = pd.Series([3921403840, 1171857588, 964514537, 964514537], \n",
    "    index=['Bill & Melinda Gates Foundation', 'Schwab Charitable Fund', 'Silicon Valley Community Foundation', 'Gordon and Betty Moore Foundation'])\n",
    "print (top_grantmakers_2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These labels can be used to refer to the values in the `Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "964514537"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grantmakers_2014['Silicon Valley Community Foundation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Schwab Charitable Fund    1171857588\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grantmakers_2014[[name.endswith('Fund') for name in top_grantmakers_2014.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name.endswith('Fund') for name in top_grantmakers_2014.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the indexing operation preserved the association between the values and the corresponding indices.\n",
    "\n",
    "We can still use positional indexing if we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1171857588"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grantmakers_2014[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give both the array of values and the index meaningful labels themselves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grantmaker\n",
       "Bill & Melinda Gates Foundation        3921403840\n",
       "Schwab Charitable Fund                 1171857588\n",
       "Silicon Valley Community Foundation     964514537\n",
       "Gordon and Betty Moore Foundation       964514537\n",
       "Name: Top Amounts, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grantmakers_2014.name = 'Top Amounts'\n",
    "top_grantmakers_2014.index.name = 'Grantmaker'\n",
    "top_grantmakers_2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy's math functions and other operations can be applied to Series without losing the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grantmaker\n",
       "Bill & Melinda Gates Foundation        22.089716\n",
       "Schwab Charitable Fund                 20.881856\n",
       "Silicon Valley Community Foundation    20.687135\n",
       "Gordon and Betty Moore Foundation      20.687135\n",
       "Name: Top Amounts, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(top_grantmakers_2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter according to the values in the `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grantmaker\n",
       "Bill & Melinda Gates Foundation    3921403840\n",
       "Schwab Charitable Fund             1171857588\n",
       "Name: Top Amounts, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_grantmakers_2014[top_grantmakers_2014>10**9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Series` can be thought of as an ordered key-value store. In fact, we can create one from a `dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill & Melinda Gates Foundation        3921403840\n",
      "Gordon and Betty Moore Foundation       964514537\n",
      "Schwab Charitable Fund                 1171857588\n",
      "Silicon Valley Community Foundation     964514537\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_gm_dict = {'Schwab Charitable Fund': 1171857588, 'Bill & Melinda Gates Foundation': 3921403840, 'Gordon and Betty Moore Foundation': 964514537, 'Silicon Valley Community Foundation': 964514537}\n",
    "print(pd.Series(top_gm_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `Series` is created in key-sorted order.\n",
    "\n",
    "If we pass a custom index to `Series`, it will select the corresponding values from the dict, and treat indices without corrsponding values as missing. Pandas uses the `NaN` (not a number) type for missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown                                         NaN\n",
      "Bill & Melinda Gates Foundation        3.921404e+09\n",
      "Schwab Charitable Fund                 1.171858e+09\n",
      "Silicon Valley Community Foundation    9.645145e+08\n",
      "Gordon and Betty Moore Foundation      9.645145e+08\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "top_gm_series = pd.Series(top_gm_dict, index=['Unknown', 'Bill & Melinda Gates Foundation','Schwab Charitable Fund','Silicon Valley Community Foundation','Gordon and Betty Moore Foundation'])\n",
    "print(top_gm_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unknown                                 True\n",
       "Bill & Melinda Gates Foundation        False\n",
       "Schwab Charitable Fund                 False\n",
       "Silicon Valley Community Foundation    False\n",
       "Gordon and Betty Moore Foundation      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_gm_series.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critically, the labels are used to **align data** when used in operations with other Series objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bill & Melinda Gates Foundation        7.842808e+09\n",
       "Gordon and Betty Moore Foundation      1.929029e+09\n",
       "Schwab Charitable Fund                 2.343715e+09\n",
       "Silicon Valley Community Foundation    1.929029e+09\n",
       "Unknown                                         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_gm_series + top_grantmakers_2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast this with NumPy arrays, where arrays of the same length will combine values element-wise; adding Series combined values with the same label in the resulting series. Notice also that the missing values were propogated by addition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "\n",
    "Inevitably, we want to be able to store, view and manipulate data that is *multivariate*, where for every index there are multiple fields or columns of data, often of varying data type.\n",
    "\n",
    "A `DataFrame` is a tabular data structure, encapsulating multiple series like columns in a spreadsheet. Data are stored internally as a 2-dimensional object, but the `DataFrame` allows us to represent and manipulate higher-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      amount gm_state recip_state\n",
      "0  569092056       CA          NJ\n",
      "1  538673007       CA          NY\n",
      "2  506235384       NY          MA\n",
      "3  467353105       NY          CA\n",
      "4  443120415       NY          DC\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({  'amount':[569092056, 538673007, 506235384, 467353105, 443120415],\n",
    "                     'gm_state':['CA', 'CA', 'NY', 'NY', 'NY'],\n",
    "                     'recip_state':['NJ', 'NY', 'MA', 'CA', 'DC']})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `DataFrame` is sorted by column name. We can change the order by indexing them in the order we desire:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  gm_state recip_state     amount\n",
       "0       CA          NJ  569092056\n",
       "1       CA          NY  538673007\n",
       "2       NY          MA  506235384\n",
       "3       NY          CA  467353105\n",
       "4       NY          DC  443120415"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['gm_state','recip_state','amount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` has a second index, representing the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount', 'gm_state', 'recip_state'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish to access columns, we can do so either by dict-like indexing or by attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569092056\n",
       "1    538673007\n",
       "2    506235384\n",
       "3    467353105\n",
       "4    443120415\n",
       "Name: amount, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569092056\n",
       "1    538673007\n",
       "2    506235384\n",
       "3    467353105\n",
       "4    443120415\n",
       "Name: amount, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[['amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice this is different than with `Series`, where dict-like indexing retrieved a particular element (row). If we want access to a row in a `DataFrame`, we index its `ix` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount         467353105\n",
       "gm_state              NY\n",
       "recip_state           CA\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ix[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can create a `DataFrame` with a dict of dicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0          1          2          3          4\n",
      "amount    569092056  538673007  506235384  467353105  443120415\n",
      "gm_state         CA         CA         NY         NY         NY\n",
      "phylum           NJ         NY         MA         CA         DC\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({0: {'gm_state': 'CA', 'phylum': 'NJ', 'amount': 569092056},\n",
    "                    1: {'gm_state': 'CA', 'phylum': 'NY', 'amount': 538673007},\n",
    "                    2: {'gm_state': 'NY', 'phylum': 'MA', 'amount': 506235384},\n",
    "                    3: {'gm_state': 'NY', 'phylum': 'CA', 'amount': 467353105},\n",
    "                    4: {'gm_state': 'NY', 'phylum': 'DC', 'amount': 443120415}})\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably want this transposed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      amount gm_state phylum\n",
       "0  569092056       CA     NJ\n",
       "1  538673007       CA     NY\n",
       "2  506235384       NY     MA\n",
       "3  467353105       NY     CA\n",
       "4  443120415       NY     DC"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its important to note that the Series returned when a DataFrame is indexed is merely a **view** on the DataFrame, and not a copy of the data itself. So you must be cautious when manipulating this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569092056\n",
       "1    538673007\n",
       "2    506235384\n",
       "3    467353105\n",
       "4    443120415\n",
       "Name: amount, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = df.amount\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    569092056\n",
       "1    538673007\n",
       "2    506235384\n",
       "3    467353105\n",
       "4            0\n",
       "Name: amount, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[4] = 0\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      amount gm_state phylum\n",
       "0  569092056       CA     NJ\n",
       "1  538673007       CA     NY\n",
       "2  506235384       NY     MA\n",
       "3  467353105       NY     CA\n",
       "4          0       NY     DC"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      amount gm_state phylum\n",
      "0  569092056       CA     NJ\n",
      "1  538673007       CA     NY\n",
      "2  506235384       NY     MA\n",
      "3  467353105       NY     CA\n",
      "4  443120415       NY     DC\n",
      "0    569092056\n",
      "1    538673007\n",
      "2    506235384\n",
      "3    467353105\n",
      "4            0\n",
      "Name: amount, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({0: {'gm_state': 'CA', 'phylum': 'NJ', 'amount': 569092056},\n",
    "                    1: {'gm_state': 'CA', 'phylum': 'NY', 'amount': 538673007},\n",
    "                    2: {'gm_state': 'NY', 'phylum': 'MA', 'amount': 506235384},\n",
    "                    3: {'gm_state': 'NY', 'phylum': 'CA', 'amount': 467353105},\n",
    "                    4: {'gm_state': 'NY', 'phylum': 'DC', 'amount': 443120415}})\n",
    "df = df.T\n",
    "vals = df.amount.copy()\n",
    "vals[4] = 0\n",
    "print(df)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create or modify columns by assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      amount gm_state phylum\n",
       "0  569092056       CA     NJ\n",
       "1  538673007       CA     NY\n",
       "2  506235384       NY     MA\n",
       "3      10000       NY     CA\n",
       "4  443120415       NY     DC"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.amount[3] = 10000\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      amount gm_state phylum\n",
       "0  569092056       MN     NJ\n",
       "1  538673007       MN     NY\n",
       "2  506235384       MN     MA\n",
       "3      10000       MN     CA\n",
       "4  443120415       MN     DC"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gm_state'] = 'MN'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But note, we cannot use the attribute indexing method to add a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year\n",
       "0       1      Firmicutes   632  2013\n",
       "1       1  Proteobacteria  1638  2013\n",
       "2       1  Actinobacteria   569  2013\n",
       "3       1   Bacteroidetes    14  2013\n",
       "4       2      Firmicutes   433  2013\n",
       "5       2  Proteobacteria     0  2013\n",
       "6       2  Actinobacteria   754  2013\n",
       "7       2   Bacteroidetes   555  2013"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.treatment = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying a `Series` as a new columns cause its values to be added according to the `DataFrame`'s index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "5    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment = pd.Series([0]*4 + [1]*2)\n",
    "treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555  2013        NaN"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['treatment'] = treatment\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other Python data structures (ones without an index) need to be the same length as the `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-360d03fdde9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmonth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Jan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Feb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mar'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Apr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1981\u001b[0m         \u001b[0mis_existing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1982\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1983\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1984\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2031\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_is_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2033\u001b[0;31m                 raise ValueError('Length of values does not match length of '\n\u001b[0m\u001b[1;32m   2034\u001b[0m                                  'index')\n\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "month = ['Jan', 'Feb', 'Mar', 'Apr']\n",
    "data['month'] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment month\n",
       "0       1      Firmicutes   632  2013          0   Jan\n",
       "1       1  Proteobacteria  1638  2013          0   Jan\n",
       "2       1  Actinobacteria   569  2013          0   Jan\n",
       "3       1   Bacteroidetes    14  2013          0   Jan\n",
       "4       2      Firmicutes   433  2013          1   Jan\n",
       "5       2  Proteobacteria     0  2013          1   Jan\n",
       "6       2  Actinobacteria   754  2013        NaN   Jan\n",
       "7       2   Bacteroidetes   555  2013        NaN   Jan"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['month'] = ['Jan']*len(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `del` to remove columns, in the same way `dict` entries can be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555  2013        NaN"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data['month']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the underlying data as a simple `ndarray` by accessing the `values` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Firmicutes', 632, 2013, 0.0],\n",
       "       [1, 'Proteobacteria', 1638, 2013, 0.0],\n",
       "       [1, 'Actinobacteria', 569, 2013, 0.0],\n",
       "       [1, 'Bacteroidetes', 14, 2013, 0.0],\n",
       "       [2, 'Firmicutes', 433, 2013, 1.0],\n",
       "       [2, 'Proteobacteria', 0, 2013, 1.0],\n",
       "       [2, 'Actinobacteria', 754, 2013, nan],\n",
       "       [2, 'Bacteroidetes', 555, 2013, nan]], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that because of the mix of string and integer (and `NaN`) values, the dtype of the array is `object`. The dtype will automatically be chosen to be as general as needed to accomodate all the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4,  1. ],\n",
       "       [-1. ,  2. ],\n",
       "       [ 4.5,  3. ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'foo': [1,2,3], 'bar':[0.4, -1.0, 4.5]})\n",
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas uses a custom data structure to represent the indices of Series and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6, 7], dtype='int64')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index objects are immutable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<class 'pandas.core.index.Int64Index'>' does not support mutable operations.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-42a852cc9eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m_disabled\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;34m\"\"\"This method will not function because object is immutable.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         raise TypeError(\"'%s' does not support mutable operations.\" %\n\u001b[0;32m--> 179\u001b[0;31m                         self.__class__)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0m__setitem__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__setslice__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__delitem__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__delslice__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_disabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<class 'pandas.core.index.Int64Index'>' does not support mutable operations."
     ]
    }
   ],
   "source": [
    "data.index[0] = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is so that Index objects can be shared between data structures without fear that they will be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bacteria2.index = bacteria.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes         NaN\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key, but often under-appreciated, step in data analysis is importing the data that we wish to analyze. Though it is easy to load basic data structures into Python using built-in tools or those provided by packages like NumPy, it is non-trivial to import structured data well, and to easily convert this input into a robust data structure:\n",
    "\n",
    "    genes = np.loadtxt(\"genes.csv\", delimiter=\",\", dtype=[('gene', '|S10'), ('value', '<f4')])\n",
    "\n",
    "Pandas provides a convenient set of functions for importing tabular data in a number of formats directly into a `DataFrame` object. These functions include a slew of options to perform type inference, indexing, parsing, iterating and cleaning automatically as data are imported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with some more bacteria data, stored in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxon,Patient,Tissue,Stool\r\n",
      "Firmicutes,1,632,305\r\n",
      "Firmicutes,2,136,4182\r\n",
      "Firmicutes,3,1174,703\r\n",
      "Firmicutes,4,408,3946\r\n",
      "Firmicutes,5,831,8605\r\n",
      "Firmicutes,6,693,50\r\n",
      "Firmicutes,7,718,717\r\n",
      "Firmicutes,8,173,33\r\n",
      "Firmicutes,9,228,80\r\n",
      "Firmicutes,10,162,3196\r\n",
      "Firmicutes,11,372,32\r\n",
      "Firmicutes,12,4255,4361\r\n",
      "Firmicutes,13,107,1667\r\n",
      "Firmicutes,14,96,223\r\n",
      "Firmicutes,15,281,2377\r\n",
      "Proteobacteria,1,1638,3886\r\n",
      "Proteobacteria,2,2469,1821\r\n",
      "Proteobacteria,3,839,661\r\n",
      "Proteobacteria,4,4414,18\r\n",
      "Proteobacteria,5,12044,83\r\n",
      "Proteobacteria,6,2310,12\r\n",
      "Proteobacteria,7,3053,547\r\n",
      "Proteobacteria,8,395,2174\r\n",
      "Proteobacteria,9,2651,767\r\n",
      "Proteobacteria,10,1195,76\r\n",
      "Proteobacteria,11,6857,795\r\n",
      "Proteobacteria,12,483,666\r\n",
      "Proteobacteria,13,2950,3994\r\n",
      "Proteobacteria,14,1541,816\r\n",
      "Proteobacteria,15,1307,53\r\n",
      "Actinobacteria,1,569,648\r\n",
      "Actinobacteria,2,1590,4\r\n",
      "Actinobacteria,3,25,2\r\n",
      "Actinobacteria,4,259,300\r\n",
      "Actinobacteria,5,568,7\r\n",
      "Actinobacteria,6,1102,9\r\n",
      "Actinobacteria,7,678,377\r\n",
      "Actinobacteria,8,260,58\r\n",
      "Actinobacteria,9,424,233\r\n",
      "Actinobacteria,10,548,21\r\n",
      "Actinobacteria,11,201,83\r\n",
      "Actinobacteria,12,42,75\r\n",
      "Actinobacteria,13,109,59\r\n",
      "Actinobacteria,14,51,183\r\n",
      "Actinobacteria,15,310,204\r\n",
      "Bacteroidetes,1,115,380\r\n",
      "Bacteroidetes,2,67,0\r\n",
      "Bacteroidetes,3,0,0\r\n",
      "Bacteroidetes,4,85,5\r\n",
      "Bacteroidetes,5,143,7\r\n",
      "Bacteroidetes,6,678,2\r\n",
      "Bacteroidetes,7,4829,209\r\n",
      "Bacteroidetes,8,74,651\r\n",
      "Bacteroidetes,9,169,254\r\n",
      "Bacteroidetes,10,106,10\r\n",
      "Bacteroidetes,11,73,381\r\n",
      "Bacteroidetes,12,30,359\r\n",
      "Bacteroidetes,13,51,51\r\n",
      "Bacteroidetes,14,2473,2314\r\n",
      "Bacteroidetes,15,102,33\r\n",
      "Other,1,114,277\r\n",
      "Other,2,195,18\r\n",
      "Other,3,42,2\r\n",
      "Other,4,316,43\r\n",
      "Other,5,202,40\r\n",
      "Other,6,116,0\r\n",
      "Other,7,527,12\r\n",
      "Other,8,357,11\r\n",
      "Other,9,106,11\r\n",
      "Other,10,67,14\r\n",
      "Other,11,203,6\r\n",
      "Other,12,392,6\r\n",
      "Other,13,28,25\r\n",
      "Other,14,12,22\r\n",
      "Other,15,305,32"
     ]
    }
   ],
   "source": [
    "!cat data/microbiome.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table can be read into a DataFrame using `read_csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Taxon  Patient  Tissue  Stool\n",
       "0   Firmicutes        1     632    305\n",
       "1   Firmicutes        2     136   4182\n",
       "2   Firmicutes        3    1174    703\n",
       "3   Firmicutes        4     408   3946\n",
       "4   Firmicutes        5     831   8605\n",
       "5   Firmicutes        6     693     50\n",
       "6   Firmicutes        7     718    717\n",
       "7   Firmicutes        8     173     33\n",
       "8   Firmicutes        9     228     80\n",
       "9   Firmicutes       10     162   3196\n",
       "..         ...      ...     ...    ...\n",
       "65       Other        6     116      0\n",
       "66       Other        7     527     12\n",
       "67       Other        8     357     11\n",
       "68       Other        9     106     11\n",
       "69       Other       10      67     14\n",
       "70       Other       11     203      6\n",
       "71       Other       12     392      6\n",
       "72       Other       13      28     25\n",
       "73       Other       14      12     22\n",
       "74       Other       15     305     32\n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = pd.read_csv(\"data/microbiome.csv\")\n",
    "mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `read_csv` automatically considered the first row in the file to be a header row.\n",
    "\n",
    "We can override default behavior by customizing some the arguments, like `header`, `names` or `index_col`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0        1       2      3\n",
       "0       Taxon  Patient  Tissue  Stool\n",
       "1  Firmicutes        1     632    305\n",
       "2  Firmicutes        2     136   4182\n",
       "3  Firmicutes        3    1174    703\n",
       "4  Firmicutes        4     408   3946"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/microbiome.csv\", header=None).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`read_csv` is just a convenience function for `read_table`, since csv is such a common format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb = pd.read_table(\"data/microbiome.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sep` argument can be customized as needed to accomodate arbitrary separators. For example, we can use a regular expression to define a variable amount of whitespace, which is unfortunately very common in some data formats: \n",
    "    \n",
    "    sep='\\s+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a more useful index, we can specify the first two columns, which together provide a unique index to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Tissue  Stool\n",
       "Taxon      Patient               \n",
       "Firmicutes 1           632    305\n",
       "           2           136   4182\n",
       "           3          1174    703\n",
       "           4           408   3946\n",
       "           5           831   8605"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb = pd.read_csv(\"data/microbiome.csv\", index_col=['Taxon','Patient'])\n",
    "mb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called a *hierarchical* index, which we will revisit later in the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have sections of data that we do not wish to import (for example, known bad data), we can populate the `skiprows` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Taxon  Patient  Tissue  Stool\n",
       "0  Firmicutes        1     632    305\n",
       "1  Firmicutes        2     136   4182\n",
       "2  Firmicutes        5     831   8605\n",
       "3  Firmicutes        7     718    717\n",
       "4  Firmicutes        8     173     33"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/microbiome.csv\", skiprows=[3,4,6]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversely, if we only want to import a small number of rows from, say, a very large data file we can use `nrows`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Taxon  Patient  Tissue  Stool\n",
       "0  Firmicutes        1     632    305\n",
       "1  Firmicutes        2     136   4182\n",
       "2  Firmicutes        3    1174    703\n",
       "3  Firmicutes        4     408   3946"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/microbiome.csv\", nrows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, if we want to process our data in reasonable chunks, the `chunksize` argument will return an iterable object that can be employed in a data processing loop. For example, our microbiome data are organized by bacterial phylum, with 15 patients represented in each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Actinobacteria': 449.06666666666666,\n",
       " 'Bacteroidetes': 599.66666666666663,\n",
       " 'Firmicutes': 684.39999999999998,\n",
       " 'Other': 198.80000000000001,\n",
       " 'Proteobacteria': 2943.0666666666666}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chunks = pd.read_csv(\"data/microbiome.csv\", chunksize=15)\n",
    "\n",
    "mean_tissue = {chunk.Taxon[0]:chunk.Tissue.mean() for chunk in data_chunks}\n",
    "    \n",
    "mean_tissue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most real-world data is incomplete, with values missing due to incomplete observation, data entry or transcription error, or other reasons. Pandas will automatically recognize and parse common missing data indicators, including `NA` and `NULL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxon,Patient,Tissue,Stool\r\n",
      "Firmicutes,1,632,305\r\n",
      "Firmicutes,2,136,4182\r\n",
      "Firmicutes,3,,703\r\n",
      "Firmicutes,4,408,3946\r\n",
      "Firmicutes,5,831,8605\r\n",
      "Firmicutes,6,693,50\r\n",
      "Firmicutes,7,718,717\r\n",
      "Firmicutes,8,173,33\r\n",
      "Firmicutes,9,228,NA\r\n",
      "Firmicutes,10,162,3196\r\n",
      "Firmicutes,11,372,-99999\r\n",
      "Firmicutes,12,4255,4361\r\n",
      "Firmicutes,13,107,1667\r\n",
      "Firmicutes,14,?,223\r\n",
      "Firmicutes,15,281,2377\r\n",
      "Proteobacteria,1,1638,3886\r\n",
      "Proteobacteria,2,2469,1821\r\n",
      "Proteobacteria,3,839,661\r\n",
      "Proteobacteria,4,4414,18\r\n",
      "Proteobacteria,5,12044,83\r\n",
      "Proteobacteria,6,2310,12\r\n",
      "Proteobacteria,7,3053,547\r\n",
      "Proteobacteria,8,395,2174\r\n",
      "Proteobacteria,9,2651,767\r\n",
      "Proteobacteria,10,1195,76\r\n",
      "Proteobacteria,11,6857,795\r\n",
      "Proteobacteria,12,483,666\r\n",
      "Proteobacteria,13,2950,3994\r\n",
      "Proteobacteria,14,1541,816\r\n",
      "Proteobacteria,15,1307,53\r\n",
      "Actinobacteria,1,569,648\r\n",
      "Actinobacteria,2,1590,4\r\n",
      "Actinobacteria,3,25,2\r\n",
      "Actinobacteria,4,259,300\r\n",
      "Actinobacteria,5,568,7\r\n",
      "Actinobacteria,6,1102,9\r\n",
      "Actinobacteria,7,678,377\r\n",
      "Actinobacteria,8,260,58\r\n",
      "Actinobacteria,9,424,233\r\n",
      "Actinobacteria,10,548,21\r\n",
      "Actinobacteria,11,201,83\r\n",
      "Actinobacteria,12,42,75\r\n",
      "Actinobacteria,13,109,59\r\n",
      "Actinobacteria,14,51,183\r\n",
      "Actinobacteria,15,310,204\r\n",
      "Bacteroidetes,1,115,380\r\n",
      "Bacteroidetes,2,67,0\r\n",
      "Bacteroidetes,3,0,0\r\n",
      "Bacteroidetes,4,85,5\r\n",
      "Bacteroidetes,5,143,7\r\n",
      "Bacteroidetes,6,678,2\r\n",
      "Bacteroidetes,7,4829,209\r\n",
      "Bacteroidetes,8,74,651\r\n",
      "Bacteroidetes,9,169,254\r\n",
      "Bacteroidetes,10,106,10\r\n",
      "Bacteroidetes,11,73,381\r\n",
      "Bacteroidetes,12,30,359\r\n",
      "Bacteroidetes,13,51,51\r\n",
      "Bacteroidetes,14,2473,2314\r\n",
      "Bacteroidetes,15,102,33\r\n",
      "Other,1,114,277\r\n",
      "Other,2,195,18\r\n",
      "Other,3,42,2\r\n",
      "Other,4,316,43\r\n",
      "Other,5,202,40\r\n",
      "Other,6,116,0\r\n",
      "Other,7,527,12\r\n",
      "Other,8,357,11\r\n",
      "Other,9,106,11\r\n",
      "Other,10,67,14\r\n",
      "Other,11,203,6\r\n",
      "Other,12,392,6\r\n",
      "Other,13,28,25\r\n",
      "Other,14,12,22\r\n",
      "Other,15,305,32"
     ]
    }
   ],
   "source": [
    "!cat data/microbiome_missing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Taxon  Patient Tissue  Stool\n",
       "0       Firmicutes        1    632    305\n",
       "1       Firmicutes        2    136   4182\n",
       "2       Firmicutes        3    NaN    703\n",
       "3       Firmicutes        4    408   3946\n",
       "4       Firmicutes        5    831   8605\n",
       "5       Firmicutes        6    693     50\n",
       "6       Firmicutes        7    718    717\n",
       "7       Firmicutes        8    173     33\n",
       "8       Firmicutes        9    228    NaN\n",
       "9       Firmicutes       10    162   3196\n",
       "10      Firmicutes       11    372 -99999\n",
       "11      Firmicutes       12   4255   4361\n",
       "12      Firmicutes       13    107   1667\n",
       "13      Firmicutes       14      ?    223\n",
       "14      Firmicutes       15    281   2377\n",
       "15  Proteobacteria        1   1638   3886\n",
       "16  Proteobacteria        2   2469   1821\n",
       "17  Proteobacteria        3    839    661\n",
       "18  Proteobacteria        4   4414     18\n",
       "19  Proteobacteria        5  12044     83"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/microbiome_missing.csv\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, Pandas recognized `NA` and an empty field as missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Taxon Patient Tissue  Stool\n",
       "0   False   False  False  False\n",
       "1   False   False  False  False\n",
       "2   False   False   True  False\n",
       "3   False   False  False  False\n",
       "4   False   False  False  False\n",
       "5   False   False  False  False\n",
       "6   False   False  False  False\n",
       "7   False   False  False  False\n",
       "8   False   False  False   True\n",
       "9   False   False  False  False\n",
       "10  False   False  False  False\n",
       "11  False   False  False  False\n",
       "12  False   False  False  False\n",
       "13  False   False  False  False\n",
       "14  False   False  False  False\n",
       "15  False   False  False  False\n",
       "16  False   False  False  False\n",
       "17  False   False  False  False\n",
       "18  False   False  False  False\n",
       "19  False   False  False  False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(pd.read_csv(\"data/microbiome_missing.csv\")).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there will sometimes be inconsistency with the conventions for missing data. In this example, there is a question mark \"?\" and a large negative number where there should have been a positive integer. We can specify additional symbols with the `na_values` argument:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Taxon  Patient  Tissue  Stool\n",
       "0       Firmicutes        1     632    305\n",
       "1       Firmicutes        2     136   4182\n",
       "2       Firmicutes        3     NaN    703\n",
       "3       Firmicutes        4     408   3946\n",
       "4       Firmicutes        5     831   8605\n",
       "5       Firmicutes        6     693     50\n",
       "6       Firmicutes        7     718    717\n",
       "7       Firmicutes        8     173     33\n",
       "8       Firmicutes        9     228    NaN\n",
       "9       Firmicutes       10     162   3196\n",
       "10      Firmicutes       11     372    NaN\n",
       "11      Firmicutes       12    4255   4361\n",
       "12      Firmicutes       13     107   1667\n",
       "13      Firmicutes       14     NaN    223\n",
       "14      Firmicutes       15     281   2377\n",
       "15  Proteobacteria        1    1638   3886\n",
       "16  Proteobacteria        2    2469   1821\n",
       "17  Proteobacteria        3     839    661\n",
       "18  Proteobacteria        4    4414     18\n",
       "19  Proteobacteria        5   12044     83"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/microbiome_missing.csv\", na_values=['?', -99999]).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can be specified on a column-wise basis using an appropriate dict as the argument for `na_values`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft Excel\n",
    "\n",
    "Since so much financial and scientific data ends up in Excel spreadsheets (regrettably), Pandas' ability to directly import Excel spreadsheets is valuable. This support is contingent on having one or two dependencies (depending on what version of Excel file is being imported) installed: `xlrd` and `openpyxl` (these may be installed with either `pip` or `easy_install`).\n",
    "\n",
    "Importing Excel data to Pandas is a two-step process. First, we create an `ExcelFile` object using the path of the file:                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.excel.ExcelFile at 0x10f8426d0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_file = pd.ExcelFile('data/microbiome/MID1.xls')\n",
    "mb_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, since modern spreadsheets consist of one or more \"sheets\", we parse the sheet with the data of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Taxon  Count\n",
       "0  Archaea \"Crenarchaeota\" Thermoprotei Desulfuro...      7\n",
       "1  Archaea \"Crenarchaeota\" Thermoprotei Desulfuro...      2\n",
       "2  Archaea \"Crenarchaeota\" Thermoprotei Sulfoloba...      3\n",
       "3  Archaea \"Crenarchaeota\" Thermoprotei Thermopro...      3\n",
       "4  Archaea \"Euryarchaeota\" \"Methanomicrobia\" Meth...      7"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1 = mb_file.parse(\"Sheet 1\", header=None)\n",
    "mb1.columns = [\"Taxon\", \"Count\"]\n",
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is now a `read_excel` conveneince function in Pandas that combines these steps into a single call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   0   1\n",
       "0  Archaea \"Crenarchaeota\" Thermoprotei Acidiloba...   2\n",
       "1  Archaea \"Crenarchaeota\" Thermoprotei Acidiloba...  14\n",
       "2  Archaea \"Crenarchaeota\" Thermoprotei Desulfuro...  23\n",
       "3  Archaea \"Crenarchaeota\" Thermoprotei Desulfuro...   1\n",
       "4  Archaea \"Crenarchaeota\" Thermoprotei Desulfuro...   2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb2 = pd.read_excel('data/microbiome/MID2.xls', sheetname='Sheet 1', header=None)\n",
    "mb2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several other data formats that can be imported into Python and converted into DataFrames, with the help of buitl-in or third-party libraries. These include JSON, XML, HDF5, relational and non-relational databases, and various web APIs. These are beyond the scope of this tutorial, but are covered in [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section introduces the new user to the key functionality of Pandas that is required to use the software effectively.\n",
    "\n",
    "For some variety, we will leave our digestive tract bacteria behind and employ some baseball data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team  lg   g  ab  r   h  X2b  X3b  hr  rbi  sb  \\\n",
       "id                                                                             \n",
       "88641  womacto01  2006      2  CHN  NL  19  50  6  14    1    0   1    2   1   \n",
       "88643  schilcu01  2006      1  BOS  AL  31   2  0   1    0    0   0    0   0   \n",
       "88645  myersmi01  2006      1  NYA  AL  62   0  0   0    0    0   0    0   0   \n",
       "88649  helliri01  2006      1  MIL  NL  20   3  0   0    0    0   0    0   0   \n",
       "88650  johnsra05  2006      1  NYA  AL  33   6  0   1    0    0   0    0   0   \n",
       "\n",
       "       cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "id                                         \n",
       "88641   1   4   4    0    0   3   0     0  \n",
       "88643   0   0   1    0    0   0   0     0  \n",
       "88645   0   0   0    0    0   0   0     0  \n",
       "88649   0   0   2    0    0   0   0     0  \n",
       "88650   0   0   4    0    0   0   0     0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball = pd.read_csv(\"data/baseball.csv\", index_col='id')\n",
    "baseball.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we specified the `id` column as the index, since it appears to be a unique identifier. We could try to create a unique index ourselves by combining `player` and `year`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  player  year  stint team  lg   g  ab  r   h  X2b  X3b  hr  \\\n",
       "womacto012006  womacto01  2006      2  CHN  NL  19  50  6  14    1    0   1   \n",
       "schilcu012006  schilcu01  2006      1  BOS  AL  31   2  0   1    0    0   0   \n",
       "myersmi012006  myersmi01  2006      1  NYA  AL  62   0  0   0    0    0   0   \n",
       "helliri012006  helliri01  2006      1  MIL  NL  20   3  0   0    0    0   0   \n",
       "johnsra052006  johnsra05  2006      1  NYA  AL  33   6  0   1    0    0   0   \n",
       "\n",
       "               rbi  sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "womacto012006    2   1   1   4   4    0    0   3   0     0  \n",
       "schilcu012006    0   0   0   0   1    0    0   0   0     0  \n",
       "myersmi012006    0   0   0   0   0    0    0   0   0     0  \n",
       "helliri012006    0   0   0   0   2    0    0   0   0     0  \n",
       "johnsra052006    0   0   0   0   4    0    0   0   0     0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_id = baseball.player + baseball.year.astype(str)\n",
    "baseball_newind = baseball.copy()\n",
    "baseball_newind.index = player_id\n",
    "baseball_newind.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks okay, but let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, indices need not be unique. Our choice is not unique because some players change teams within years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wickmbo012007    2\n",
       "gomezch022007    2\n",
       "sweenma012007    2\n",
       "claytro012007    2\n",
       "hernaro012007    2\n",
       "loftoke012007    2\n",
       "trachst012007    2\n",
       "wellsda012007    2\n",
       "...\n",
       "myersmi012007    1\n",
       "alomasa022007    1\n",
       "edmonji012007    1\n",
       "sheffga012007    1\n",
       "whiteri012007    1\n",
       "cormirh012007    1\n",
       "floydcl012007    1\n",
       "embreal012007    1\n",
       "Length: 88, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(baseball_newind.index).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important consequence of a non-unique index is that indexing by label will return multiple values for some labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  player  year  stint team  lg   g  ab  r  h  X2b  X3b  hr  \\\n",
       "wickmbo012007  wickmbo01  2007      2  ARI  NL   8   0  0  0    0    0   0   \n",
       "wickmbo012007  wickmbo01  2007      1  ATL  NL  47   0  0  0    0    0   0   \n",
       "\n",
       "               rbi  sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "wickmbo012007    0   0   0   0   0    0    0   0   0     0  \n",
       "wickmbo012007    0   0   0   0   0    0    0   0   0     0  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.ix['wickmbo012007']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn more about indexing below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a truly unique index by combining `player`, `team` and `year`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     player  year  stint team  lg   g  ab  r   h  X2b  X3b  \\\n",
       "womacto01CHN2006  womacto01  2006      2  CHN  NL  19  50  6  14    1    0   \n",
       "schilcu01BOS2006  schilcu01  2006      1  BOS  AL  31   2  0   1    0    0   \n",
       "myersmi01NYA2006  myersmi01  2006      1  NYA  AL  62   0  0   0    0    0   \n",
       "helliri01MIL2006  helliri01  2006      1  MIL  NL  20   3  0   0    0    0   \n",
       "johnsra05NYA2006  johnsra05  2006      1  NYA  AL  33   6  0   1    0    0   \n",
       "\n",
       "                  hr  rbi  sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "womacto01CHN2006   1    2   1   1   4   4    0    0   3   0     0  \n",
       "schilcu01BOS2006   0    0   0   0   0   1    0    0   0   0     0  \n",
       "myersmi01NYA2006   0    0   0   0   0   0    0    0   0   0     0  \n",
       "helliri01MIL2006   0    0   0   0   0   2    0    0   0   0     0  \n",
       "johnsra05NYA2006   0    0   0   0   0   4    0    0   0   0     0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_unique = baseball.player + baseball.team + baseball.year.astype(str)\n",
    "baseball_newind = baseball.copy()\n",
    "baseball_newind.index = player_unique\n",
    "baseball_newind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create meaningful indices more easily using a hierarchical index; for now, we will stick with the numeric `id` field as our index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating indices\n",
    "\n",
    "**Reindexing** allows users to manipulate the data labels in a DataFrame. It forces a DataFrame to conform to the new index, and optionally, fill in missing data if requested.\n",
    "\n",
    "A simple use of `reindex` is to alter the order of the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team  lg    g   ab   r    h  X2b  X3b  hr  rbi  \\\n",
       "id                                                                             \n",
       "89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0   0    0   \n",
       "89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1  13   49   \n",
       "89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3   3   25   \n",
       "89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0   0    0   \n",
       "89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0   0    0   \n",
       "\n",
       "       sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "id                                             \n",
       "89534   0   0   0   3    0    0   0   0     0  \n",
       "89533   3   0  27  30    5    2   0   3    13  \n",
       "89530   6   1  37  74    3    6   4   1    11  \n",
       "89526   0   0   0   0    0    0   0   0     0  \n",
       "89525   0   0   0   0    0    0   0   0     0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.reindex(baseball.index[::-1]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `id` index is not sequential. Say we wanted to populate the table with every `id` value. We could specify and index that is a sequence from the first to the last `id` numbers in the database, and Pandas would fill in the missing data with `NaN` values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team   lg   g  ab   r   h  X2b  X3b  hr  rbi  \\\n",
       "88641  womacto01  2006      2  CHN   NL  19  50   6  14    1    0   1    2   \n",
       "88642        NaN   NaN    NaN  NaN  NaN NaN NaN NaN NaN  NaN  NaN NaN  NaN   \n",
       "88643  schilcu01  2006      1  BOS   AL  31   2   0   1    0    0   0    0   \n",
       "88644        NaN   NaN    NaN  NaN  NaN NaN NaN NaN NaN  NaN  NaN NaN  NaN   \n",
       "88645  myersmi01  2006      1  NYA   AL  62   0   0   0    0    0   0    0   \n",
       "\n",
       "       sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "88641   1   1   4   4    0    0   3   0     0  \n",
       "88642 NaN NaN NaN NaN  NaN  NaN NaN NaN   NaN  \n",
       "88643   0   0   0   1    0    0   0   0     0  \n",
       "88644 NaN NaN NaN NaN  NaN  NaN NaN NaN   NaN  \n",
       "88645   0   0   0   0    0    0   0   0     0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_range = range(baseball.index.values.min(), baseball.index.values.max())\n",
    "baseball.reindex(id_range).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values can be filled as desired, either with selected values, or by rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year\n",
       "88641  womacto01  2006\n",
       "88642  womacto01  2006\n",
       "88643  schilcu01  2006\n",
       "88644  schilcu01  2006\n",
       "88645  myersmi01  2006"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.reindex(id_range, method='ffill', columns=['player','year']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player\n",
       "88641  womacto01\n",
       "88642  mr.nobody\n",
       "88643  schilcu01\n",
       "88644  mr.nobody\n",
       "88645  myersmi01"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.reindex(id_range, fill_value='mr.nobody', columns=['player']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that `reindex` does not work if we pass a non-unique index series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can remove rows or columns via the `drop` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 22)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team  lg    g   ab   r    h  X2b  X3b  hr  rbi  \\\n",
       "id                                                                             \n",
       "88641  womacto01  2006      2  CHN  NL   19   50   6   14    1    0   1    2   \n",
       "88643  schilcu01  2006      1  BOS  AL   31    2   0    1    0    0   0    0   \n",
       "88645  myersmi01  2006      1  NYA  AL   62    0   0    0    0    0   0    0   \n",
       "88649  helliri01  2006      1  MIL  NL   20    3   0    0    0    0   0    0   \n",
       "88650  johnsra05  2006      1  NYA  AL   33    6   0    1    0    0   0    0   \n",
       "88652  finlest01  2006      1  SFN  NL  139  426  66  105   21   12   6   40   \n",
       "88653  gonzalu01  2006      1  ARI  NL  153  586  93  159   52    2  15   73   \n",
       "88662   seleaa01  2006      1  LAN  NL   28   26   2    5    1    0   0    0   \n",
       "89177  francju01  2007      2  ATL  NL   15   40   1   10    3    0   0    8   \n",
       "89178  francju01  2007      1  NYN  NL   40   50   7   10    0    0   1    8   \n",
       "...          ...   ...    ...  ...  ..  ...  ...  ..  ...  ...  ...  ..  ...   \n",
       "89497  clemero02  2007      1  NYA  AL    2    2   0    1    0    0   0    0   \n",
       "89498  claytro01  2007      2  BOS  AL    8    6   1    0    0    0   0    0   \n",
       "89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0   1   12   \n",
       "89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0   0    6   \n",
       "89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2   2   21   \n",
       "89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0  28   66   \n",
       "89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3  10   50   \n",
       "89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3   3   25   \n",
       "89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1  13   49   \n",
       "89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0   0    0   \n",
       "\n",
       "       sb  cs   bb   so  ibb  hbp  sh  sf  gidp  \n",
       "id                                               \n",
       "88641   1   1    4    4    0    0   3   0     0  \n",
       "88643   0   0    0    1    0    0   0   0     0  \n",
       "88645   0   0    0    0    0    0   0   0     0  \n",
       "88649   0   0    0    2    0    0   0   0     0  \n",
       "88650   0   0    0    4    0    0   0   0     0  \n",
       "88652   7   0   46   55    2    2   3   4     6  \n",
       "88653   0   1   69   58   10    7   0   6    14  \n",
       "88662   0   0    1    7    0    0   6   0     1  \n",
       "89177   0   0    4   10    1    0   0   1     1  \n",
       "89178   2   1   10   13    0    0   0   1     1  \n",
       "...    ..  ..  ...  ...  ...  ...  ..  ..   ...  \n",
       "89497   0   0    0    0    0    0   0   0     0  \n",
       "89498   0   0    0    3    0    0   0   0     2  \n",
       "89499   2   1   14   50    0    1   3   3     8  \n",
       "89501   0   0    4    6    0    0   0   0     1  \n",
       "89502   2   0   15   13    0    1   3   2     9  \n",
       "89521   5   0  132   54   43    3   0   2    13  \n",
       "89523   4   3   23  112    0    3   7   5     5  \n",
       "89530   6   1   37   74    3    6   4   1    11  \n",
       "89533   3   0   27   30    5    2   0   3    13  \n",
       "89534   0   0    0    3    0    0   0   0     0  \n",
       "\n",
       "[98 rows x 22 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.drop([89525, 89526])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team  lg    g   ab   r    h  X2b  X3b  hr  rbi  \\\n",
       "id                                                                             \n",
       "88641  womacto01  2006      2  CHN  NL   19   50   6   14    1    0   1    2   \n",
       "88643  schilcu01  2006      1  BOS  AL   31    2   0    1    0    0   0    0   \n",
       "88645  myersmi01  2006      1  NYA  AL   62    0   0    0    0    0   0    0   \n",
       "88649  helliri01  2006      1  MIL  NL   20    3   0    0    0    0   0    0   \n",
       "88650  johnsra05  2006      1  NYA  AL   33    6   0    1    0    0   0    0   \n",
       "88652  finlest01  2006      1  SFN  NL  139  426  66  105   21   12   6   40   \n",
       "88653  gonzalu01  2006      1  ARI  NL  153  586  93  159   52    2  15   73   \n",
       "88662   seleaa01  2006      1  LAN  NL   28   26   2    5    1    0   0    0   \n",
       "89177  francju01  2007      2  ATL  NL   15   40   1   10    3    0   0    8   \n",
       "89178  francju01  2007      1  NYN  NL   40   50   7   10    0    0   1    8   \n",
       "...          ...   ...    ...  ...  ..  ...  ...  ..  ...  ...  ...  ..  ...   \n",
       "89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0   1   12   \n",
       "89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0   0    6   \n",
       "89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2   2   21   \n",
       "89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0  28   66   \n",
       "89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3  10   50   \n",
       "89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0   0    0   \n",
       "89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0   0    0   \n",
       "89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3   3   25   \n",
       "89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1  13   49   \n",
       "89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0   0    0   \n",
       "\n",
       "       sb  cs   bb   so  sh  sf  gidp  \n",
       "id                                     \n",
       "88641   1   1    4    4   3   0     0  \n",
       "88643   0   0    0    1   0   0     0  \n",
       "88645   0   0    0    0   0   0     0  \n",
       "88649   0   0    0    2   0   0     0  \n",
       "88650   0   0    0    4   0   0     0  \n",
       "88652   7   0   46   55   3   4     6  \n",
       "88653   0   1   69   58   0   6    14  \n",
       "88662   0   0    1    7   6   0     1  \n",
       "89177   0   0    4   10   0   1     1  \n",
       "89178   2   1   10   13   0   1     1  \n",
       "...    ..  ..  ...  ...  ..  ..   ...  \n",
       "89499   2   1   14   50   3   3     8  \n",
       "89501   0   0    4    6   0   0     1  \n",
       "89502   2   0   15   13   3   2     9  \n",
       "89521   5   0  132   54   0   2    13  \n",
       "89523   4   3   23  112   7   5     5  \n",
       "89525   0   0    0    0   0   0     0  \n",
       "89526   0   0    0    0   0   0     0  \n",
       "89530   6   1   37   74   4   1    11  \n",
       "89533   3   0   27   30   0   3    13  \n",
       "89534   0   0    0    3   0   0     0  \n",
       "\n",
       "[100 rows x 20 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.drop(['ibb','hbp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Selection\n",
    "\n",
    "Indexing works analogously to indexing in NumPy arrays, except we can use the labels in the `Index` object to extract values in addition to arrays of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006     14\n",
       "schilcu01BOS2006      1\n",
       "myersmi01NYA2006      0\n",
       "helliri01MIL2006      0\n",
       "johnsra05NYA2006      1\n",
       "finlest01SFN2006    105\n",
       "gonzalu01ARI2006    159\n",
       "seleaa01LAN2006       5\n",
       "...\n",
       "cirilje01MIN2007     40\n",
       "bondsba01SFN2007     94\n",
       "biggicr01HOU2007    130\n",
       "benitar01FLO2007      0\n",
       "benitar01SFN2007      0\n",
       "ausmubr01HOU2007     82\n",
       "aloumo01NYN2007     112\n",
       "alomasa02NYN2007      3\n",
       "Name: h, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample Series object\n",
    "hits = baseball_newind.h\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006    14\n",
       "schilcu01BOS2006     1\n",
       "myersmi01NYA2006     0\n",
       "Name: h, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy-style indexing\n",
    "hits[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006    14\n",
       "schilcu01BOS2006     1\n",
       "Name: h, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing by label\n",
    "hits[['womacto01CHN2006','schilcu01BOS2006']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also slice with data labels, since they have an intrinsic order within the Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006     14\n",
       "schilcu01BOS2006      1\n",
       "myersmi01NYA2006      0\n",
       "helliri01MIL2006      0\n",
       "johnsra05NYA2006      1\n",
       "finlest01SFN2006    105\n",
       "gonzalu01ARI2006    159\n",
       "Name: h, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits['womacto01CHN2006':'gonzalu01ARI2006']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006    5\n",
       "schilcu01BOS2006    5\n",
       "myersmi01NYA2006    5\n",
       "helliri01MIL2006    5\n",
       "johnsra05NYA2006    5\n",
       "finlest01SFN2006    5\n",
       "gonzalu01ARI2006    5\n",
       "seleaa01LAN2006     5\n",
       "...\n",
       "cirilje01MIN2007     40\n",
       "bondsba01SFN2007     94\n",
       "biggicr01HOU2007    130\n",
       "benitar01FLO2007      0\n",
       "benitar01SFN2007      0\n",
       "ausmubr01HOU2007     82\n",
       "aloumo01NYN2007     112\n",
       "alomasa02NYN2007      3\n",
       "Name: h, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits['womacto01CHN2006':'gonzalu01ARI2006'] = 5\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a `DataFrame` we can slice along either or both axes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    h   ab\n",
       "womacto01CHN2006    5   50\n",
       "schilcu01BOS2006    5    2\n",
       "myersmi01NYA2006    5    0\n",
       "helliri01MIL2006    5    3\n",
       "johnsra05NYA2006    5    6\n",
       "finlest01SFN2006    5  426\n",
       "gonzalu01ARI2006    5  586\n",
       "seleaa01LAN2006     5   26\n",
       "francju01ATL2007   10   40\n",
       "francju01NYN2007   10   50\n",
       "...               ...  ...\n",
       "claytro01TOR2007   48  189\n",
       "cirilje01ARI2007    8   40\n",
       "cirilje01MIN2007   40  153\n",
       "bondsba01SFN2007   94  340\n",
       "biggicr01HOU2007  130  517\n",
       "benitar01FLO2007    0    0\n",
       "benitar01SFN2007    0    0\n",
       "ausmubr01HOU2007   82  349\n",
       "aloumo01NYN2007   112  328\n",
       "alomasa02NYN2007    3   22\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind[['h','ab']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     player  year  stint team  lg    g   ab   r    h  X2b  \\\n",
       "gonzalu01ARI2006  gonzalu01  2006      1  ARI  NL  153  586  93    5   52   \n",
       "vizquom01SFN2007  vizquom01  2007      1  SFN  NL  145  513  54  126   18   \n",
       "thomafr04TOR2007  thomafr04  2007      1  TOR  AL  155  531  63  147   30   \n",
       "rodriiv01DET2007  rodriiv01  2007      1  DET  AL  129  502  50  141   31   \n",
       "griffke02CIN2007  griffke02  2007      1  CIN  NL  144  528  78  146   24   \n",
       "delgaca01NYN2007  delgaca01  2007      1  NYN  NL  139  538  71  139   30   \n",
       "biggicr01HOU2007  biggicr01  2007      1  HOU  NL  141  517  68  130   31   \n",
       "\n",
       "                  X3b  hr  rbi  sb  cs  bb   so  ibb  hbp  sh  sf  gidp  \n",
       "gonzalu01ARI2006    2  15   73   0   1  69   58   10    7   0   6    14  \n",
       "vizquom01SFN2007    3   4   51  14   6  44   48    6    1  14   3    14  \n",
       "thomafr04TOR2007    0  26   95   0   0  81   94    3    7   0   5    14  \n",
       "rodriiv01DET2007    3  11   63   2   2   9   96    1    1   1   2    16  \n",
       "griffke02CIN2007    1  30   93   6   1  85   99   14    1   0   9    14  \n",
       "delgaca01NYN2007    0  24   87   4   0  52  118    8   11   0   6    12  \n",
       "biggicr01HOU2007    3  10   50   4   3  23  112    0    3   7   5     5  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind[baseball_newind.ab>500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indexing field `ix` allows us to select subsets of rows and columns in an intuitive way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h       5\n",
       "X2b    52\n",
       "X3b     2\n",
       "hr     15\n",
       "Name: gonzalu01ARI2006, dtype: object"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.ix['gonzalu01ARI2006', ['h','X2b', 'X3b', 'hr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    g   ab   r\n",
       "gonzalu01ARI2006  153  586  93\n",
       "finlest01SFN2006  139  426  66"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.ix[['gonzalu01ARI2006','finlest01SFN2006'], 5:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "womacto01CHN2006    1\n",
       "schilcu01BOS2006    0\n",
       "myersmi01NYA2006    0\n",
       "Name: hr, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.ix[:'myersmi01NYA2006', 'hr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the cross-section method `xs` (not a field) extracts a single column or row *by label* and returns it as a `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player    myersmi01\n",
       "year           2006\n",
       "stint             1\n",
       "team            NYA\n",
       "lg               AL\n",
       "g                62\n",
       "ab                0\n",
       "r                 0\n",
       "...\n",
       "cs      0\n",
       "bb      0\n",
       "so      0\n",
       "ibb     0\n",
       "hbp     0\n",
       "sh      0\n",
       "sf      0\n",
       "gidp    0\n",
       "Name: myersmi01NYA2006, Length: 22, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.xs('myersmi01NYA2006')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "\n",
    "`DataFrame` and `Series` objects allow for several operations to take place either on a single object, or between two or more objects.\n",
    "\n",
    "For example, we can perform arithmetic on the elements of two objects, such as combining baseball statistics across years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hr2006 = baseball[baseball.year==2006].xs('hr', axis=1)\n",
    "hr2006.index = baseball.player[baseball.year==2006]\n",
    "\n",
    "hr2007 = baseball[baseball.year==2007].xs('hr', axis=1)\n",
    "hr2007.index = baseball.player[baseball.year==2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hr2006 = pd.Series(baseball.hr[baseball.year==2006].values, index=baseball.player[baseball.year==2006])\n",
    "hr2007 = pd.Series(baseball.hr[baseball.year==2007].values, index=baseball.player[baseball.year==2007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player\n",
       "alomasa02   NaN\n",
       "aloumo01    NaN\n",
       "ausmubr01   NaN\n",
       "benitar01   NaN\n",
       "benitar01   NaN\n",
       "biggicr01   NaN\n",
       "bondsba01   NaN\n",
       "cirilje01   NaN\n",
       "...\n",
       "whiteri01   NaN\n",
       "whitero02   NaN\n",
       "wickmbo01   NaN\n",
       "wickmbo01   NaN\n",
       "williwo02   NaN\n",
       "witasja01   NaN\n",
       "womacto01   NaN\n",
       "zaungr01    NaN\n",
       "Length: 94, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_total = hr2006 + hr2007\n",
    "hr_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas' data alignment places `NaN` values for labels that do not overlap in the two Series. In fact, there are only 6 players that occur in both years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player\n",
       "finlest01     7\n",
       "gonzalu01    30\n",
       "johnsra05     0\n",
       "myersmi01     0\n",
       "schilcu01     0\n",
       "seleaa01      0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_total[hr_total.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we do want the operation to honor the data labels in this way, we probably do not want the missing values to be filled with `NaN`. We can use the `add` method to calculate player home run totals by using the `fill_value` argument to insert a zero for home runs where labels do not overlap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player\n",
       "alomasa02     0\n",
       "aloumo01     13\n",
       "ausmubr01     3\n",
       "benitar01     0\n",
       "benitar01     0\n",
       "biggicr01    10\n",
       "bondsba01    28\n",
       "cirilje01     0\n",
       "...\n",
       "whiteri01     0\n",
       "whitero02     4\n",
       "wickmbo01     0\n",
       "wickmbo01     0\n",
       "williwo02     1\n",
       "witasja01     0\n",
       "womacto01     1\n",
       "zaungr01     10\n",
       "Length: 94, dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr2007.add(hr2006, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations can also be **broadcast** between rows or columns.\n",
    "\n",
    "For example, if we subtract the maximum number of home runs hit from the `hr` column, we get how many fewer than the maximum were hit by each player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "88641   -34\n",
       "88643   -35\n",
       "88645   -35\n",
       "88649   -35\n",
       "88650   -35\n",
       "88652   -29\n",
       "88653   -20\n",
       "88662   -35\n",
       "...\n",
       "89502   -33\n",
       "89521    -7\n",
       "89523   -25\n",
       "89525   -35\n",
       "89526   -35\n",
       "89530   -32\n",
       "89533   -22\n",
       "89534   -35\n",
       "Name: hr, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr - baseball.hr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, looking at things row-wise, we can see how a particular player compares with the rest of the group with respect to important statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bondsba01'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.ix[89521][\"player\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        h  X2b  X3b  hr\n",
       "id                     \n",
       "88641 -80  -13    0 -27\n",
       "88643 -93  -14    0 -28\n",
       "88645 -94  -14    0 -28\n",
       "88649 -94  -14    0 -28\n",
       "88650 -93  -14    0 -28\n",
       "88652  11    7   12 -22\n",
       "88653  65   38    2 -13\n",
       "88662 -89  -13    0 -28\n",
       "89177 -84  -11    0 -28\n",
       "89178 -84  -14    0 -27"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = baseball[['h','X2b', 'X3b', 'hr']]\n",
    "diff = stats - stats.xs(89521)\n",
    "diff[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply functions to each column or row of a `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h      8\n",
       "X2b    1\n",
       "X3b    0\n",
       "hr     0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.apply(np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h      159\n",
       "X2b     52\n",
       "X3b     12\n",
       "hr      35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_range = lambda x: x.max() - x.min()\n",
    "stats.apply(stat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use apply to calculate a meaningful baseball statistics, slugging percentage:\n",
    "\n",
    "$$SLG = \\frac{1B + (2 \\times 2B) + (3 \\times 3B) + (4 \\times HR)}{AB}$$\n",
    "\n",
    "And just for fun, we will format the resulting estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "88641    0.360\n",
       "88643    0.500\n",
       "88645    0.000\n",
       "88649    0.000\n",
       "88650    0.167\n",
       "88652    0.394\n",
       "88653    0.444\n",
       "88662    0.231\n",
       "...\n",
       "89502    0.386\n",
       "89521    0.565\n",
       "89523    0.381\n",
       "89525    0.000\n",
       "89526    0.000\n",
       "89530    0.324\n",
       "89533    0.524\n",
       "89534    0.182\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slg = lambda x: (x['h']-x['X2b']-x['X3b']-x['hr'] + 2*x['X2b'] + 3*x['X3b'] + 4*x['hr'])/(x['ab']+1e-6)\n",
    "baseball.apply(slg, axis=1).apply(lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting and Ranking\n",
    "\n",
    "Pandas objects include methods for re-ordering data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     player  year  stint team  lg    g   ab   r    h  X2b  \\\n",
       "alomasa02NYN2007  alomasa02  2007      1  NYN  NL    8   22   1    3    1   \n",
       "aloumo01NYN2007    aloumo01  2007      1  NYN  NL   87  328  51  112   19   \n",
       "ausmubr01HOU2007  ausmubr01  2007      1  HOU  NL  117  349  38   82   16   \n",
       "benitar01FLO2007  benitar01  2007      2  FLO  NL   34    0   0    0    0   \n",
       "benitar01SFN2007  benitar01  2007      1  SFN  NL   19    0   0    0    0   \n",
       "\n",
       "                  X3b  hr  rbi  sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "alomasa02NYN2007    0   0    0   0   0   0   3    0    0   0   0     0  \n",
       "aloumo01NYN2007     1  13   49   3   0  27  30    5    2   0   3    13  \n",
       "ausmubr01HOU2007    3   3   25   6   1  37  74    3    6   4   1    11  \n",
       "benitar01FLO2007    0   0    0   0   0   0   0    0    0   0   0     0  \n",
       "benitar01SFN2007    0   0    0   0   0   0   0    0    0   0   0     0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.sort_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     player  year  stint team  lg    g   ab   r   h  X2b  X3b  \\\n",
       "zaungr01TOR2007    zaungr01  2007      1  TOR  AL  110  331  43  80   24    1   \n",
       "womacto01CHN2006  womacto01  2006      2  CHN  NL   19   50   6   5    1    0   \n",
       "witasja01TBA2007  witasja01  2007      1  TBA  AL    3    0   0   0    0    0   \n",
       "williwo02HOU2007  williwo02  2007      1  HOU  NL   33   59   3   6    0    0   \n",
       "wickmbo01ATL2007  wickmbo01  2007      1  ATL  NL   47    0   0   0    0    0   \n",
       "\n",
       "                  hr  rbi  sb  cs  bb  so  ibb  hbp  sh  sf  gidp  \n",
       "zaungr01TOR2007   10   52   0   0  51  55    8    2   1   6     9  \n",
       "womacto01CHN2006   1    2   1   1   4   4    0    0   3   0     0  \n",
       "witasja01TBA2007   0    0   0   0   0   0    0    0   0   0     0  \n",
       "williwo02HOU2007   1    2   0   0   0  25    0    0   5   0     1  \n",
       "wickmbo01ATL2007   0    0   0   0   0   0    0    0   0   0     0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.sort_index(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  X2b  X3b  ab  bb  cs   g  gidp  h  hbp  hr  ibb  lg  \\\n",
       "womacto01CHN2006    1    0  50   4   1  19     0  5    0   1    0  NL   \n",
       "schilcu01BOS2006    0    0   2   0   0  31     0  5    0   0    0  AL   \n",
       "myersmi01NYA2006    0    0   0   0   0  62     0  5    0   0    0  AL   \n",
       "helliri01MIL2006    0    0   3   0   0  20     0  5    0   0    0  NL   \n",
       "johnsra05NYA2006    0    0   6   0   0  33     0  5    0   0    0  AL   \n",
       "\n",
       "                     player  r  rbi  sb  sf  sh  so  stint team  year  \n",
       "womacto01CHN2006  womacto01  6    2   1   0   3   4      2  CHN  2006  \n",
       "schilcu01BOS2006  schilcu01  0    0   0   0   0   1      1  BOS  2006  \n",
       "myersmi01NYA2006  myersmi01  0    0   0   0   0   0      1  NYA  2006  \n",
       "helliri01MIL2006  helliri01  0    0   0   0   0   2      1  MIL  2006  \n",
       "johnsra05NYA2006  johnsra05  0    0   0   0   0   4      1  NYA  2006  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_newind.sort_index(axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `order` to sort a `Series` by value, rather than by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "89360    35\n",
       "89462    30\n",
       "89521    28\n",
       "89361    26\n",
       "89378    25\n",
       "89489    24\n",
       "89371    21\n",
       "89374    21\n",
       "...\n",
       "89465    0\n",
       "89372    0\n",
       "89467    0\n",
       "89370    0\n",
       "89367    0\n",
       "89469    0\n",
       "89365    0\n",
       "89534    0\n",
       "Name: hr, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr.order(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a `DataFrame`, we can sort according to the values of one or more columns using the `by` argument of `sort_index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  sb  cs\n",
       "id                      \n",
       "89378  sheffga01  22   5\n",
       "89430  loftoke01  21   4\n",
       "89347  vizquom01  14   6\n",
       "89463  greensh01  11   1\n",
       "88652  finlest01   7   0\n",
       "89462  griffke02   6   1\n",
       "89530  ausmubr01   6   1\n",
       "89466  gonzalu01   6   2\n",
       "89521  bondsba01   5   0\n",
       "89438  kleskry01   5   1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball[['player','sb','cs']].sort_index(ascending=[False,True], by=['sb', 'cs']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ranking** does not re-arrange data, but instead returns an index that ranks each value relative to others in the Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "88641    62.5\n",
       "88643    29.0\n",
       "88645    29.0\n",
       "88649    29.0\n",
       "88650    29.0\n",
       "88652    76.0\n",
       "88653    89.5\n",
       "88662    29.0\n",
       "...\n",
       "89502    69.0\n",
       "89521    98.0\n",
       "89523    83.5\n",
       "89525    29.0\n",
       "89526    29.0\n",
       "89530    71.5\n",
       "89533    88.0\n",
       "89534    29.0\n",
       "Name: hr, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr.rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ties are assigned the mean value of the tied ranks, which may result in decimal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.5\n",
       "1    1.5\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([100,100]).rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can break ties via one of several methods, such as by the order in which they occur in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "88641    58\n",
       "88643     1\n",
       "88645     2\n",
       "88649     3\n",
       "88650     4\n",
       "88652    75\n",
       "88653    89\n",
       "88662     5\n",
       "...\n",
       "89502    70\n",
       "89521    98\n",
       "89523    85\n",
       "89525    55\n",
       "89526    56\n",
       "89530    72\n",
       "89533    88\n",
       "89534    57\n",
       "Name: hr, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr.rank(method='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `DataFrame`'s `rank` method results in the ranks of all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       player  year  stint  team    lg     g    ab     r     h   X2b   X3b  \\\n",
       "id                                                                           \n",
       "88641     2.0  96.5      7  82.0  31.5  70.0  47.5  40.5  39.0  50.5  63.5   \n",
       "88643    37.5  96.5     57  88.0  81.5  55.5  73.0  81.0  63.5  78.0  63.5   \n",
       "88645    47.5  96.5     57  40.5  81.5  36.0  91.0  81.0  84.5  78.0  63.5   \n",
       "88649    66.0  96.5     57  47.0  31.5  67.5  69.0  81.0  84.5  78.0  63.5   \n",
       "88650    61.5  96.5     57  40.5  81.5  51.0  64.5  81.0  63.5  78.0  63.5   \n",
       "\n",
       "         hr   rbi    sb    cs    bb  so  ibb   hbp    sh  sf  gidp  \n",
       "id                                                                  \n",
       "88641  38.5  51.0  24.5  17.5  44.5  59   66  65.5  16.0  70  76.5  \n",
       "88643  72.0  78.5  63.5  62.5  79.0  73   66  65.5  67.5  70  76.5  \n",
       "88645  72.0  78.5  63.5  62.5  79.0  89   66  65.5  67.5  70  76.5  \n",
       "88649  72.0  78.5  63.5  62.5  79.0  67   66  65.5  67.5  70  76.5  \n",
       "88650  72.0  78.5  63.5  62.5  79.0  59   66  65.5  67.5  70  76.5  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.rank(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          r     h    hr\n",
       "id                     \n",
       "88641  40.5  39.0  38.5\n",
       "88643  81.0  63.5  72.0\n",
       "88645  81.0  84.5  72.0\n",
       "88649  81.0  84.5  72.0\n",
       "88650  81.0  63.5  72.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball[['r','h','hr']].rank(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Calculate **on base percentage** for each player, and return the ordered series of estimates.\n",
    "\n",
    "$$OBP = \\frac{H + BB + HBP}{AB + BB + HBP + SF}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical indexing\n",
    "\n",
    "In the baseball example, I was forced to combine 3 fields to obtain a unique index that was not simply an integer value. A more elegant way to have done this would be to create a hierarchical index from the three fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     stint  lg    g   ab   r    h  X2b  X3b  hr  rbi  sb  cs  \\\n",
       "year team player                                                               \n",
       "2006 CHN  womacto01      2  NL   19   50   6   14    1    0   1    2   1   1   \n",
       "     BOS  schilcu01      1  AL   31    2   0    1    0    0   0    0   0   0   \n",
       "     NYA  myersmi01      1  AL   62    0   0    0    0    0   0    0   0   0   \n",
       "     MIL  helliri01      1  NL   20    3   0    0    0    0   0    0   0   0   \n",
       "     NYA  johnsra05      1  AL   33    6   0    1    0    0   0    0   0   0   \n",
       "     SFN  finlest01      1  NL  139  426  66  105   21   12   6   40   7   0   \n",
       "     ARI  gonzalu01      1  NL  153  586  93  159   52    2  15   73   0   1   \n",
       "     LAN  seleaa01       1  NL   28   26   2    5    1    0   0    0   0   0   \n",
       "2007 ATL  francju01      2  NL   15   40   1   10    3    0   0    8   0   0   \n",
       "     NYN  francju01      1  NL   40   50   7   10    0    0   1    8   2   1   \n",
       "\n",
       "                     bb  so  ibb  hbp  sh  sf  gidp  \n",
       "year team player                                     \n",
       "2006 CHN  womacto01   4   4    0    0   3   0     0  \n",
       "     BOS  schilcu01   0   1    0    0   0   0     0  \n",
       "     NYA  myersmi01   0   0    0    0   0   0     0  \n",
       "     MIL  helliri01   0   2    0    0   0   0     0  \n",
       "     NYA  johnsra05   0   4    0    0   0   0     0  \n",
       "     SFN  finlest01  46  55    2    2   3   4     6  \n",
       "     ARI  gonzalu01  69  58   10    7   0   6    14  \n",
       "     LAN  seleaa01    1   7    0    0   6   0     1  \n",
       "2007 ATL  francju01   4  10    1    0   0   1     1  \n",
       "     NYN  francju01  10  13    0    0   0   1     1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_h = baseball.set_index(['year', 'team', 'player'])\n",
    "baseball_h.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This index is a `MultiIndex` object that consists of a sequence of tuples, the elements of which is some combination of the three columns used to create the index. Where there are multiple repeated values, Pandas does not print the repeats, making it easy to identify groups of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[2006, 2007], [u'ARI', u'ATL', u'BAL', u'BOS', u'CHA', u'CHN', u'CIN', u'CLE', u'COL', u'DET', u'FLO', u'HOU', u'KCA', u'LAA', u'LAN', u'MIL', u'MIN', u'NYA', u'NYN', u'OAK', u'PHI', u'SDN', u'SFN', u'SLN', u'TBA', u'TEX', u'TOR'], [u'alomasa02', u'aloumo01', u'ausmubr01', u'benitar01', u'biggicr01', u'bondsba01', u'cirilje01', u'claytro01', u'clemero02', u'coninje01', u'cormirh01', u'delgaca01', u'easleda01', u'edmonji01', u'embreal01', u'finlest01', u'floydcl01', u'francju01', u'glavito02', u'gomezch02', u'gonzalu01', u'gordoto01', u'graffto01', u'greensh01', u'griffke02', u'guarded01', u'helliri01', u'hernaro01', u'hoffmtr01', u'johnsra05', u'jonesto02', u'kentje01', u'kleskry01', u'loaizes01', u'loftoke01', u'mabryjo01', u'maddugr01', u'martipe02', u'mesajo01', u'moyerja01', u'mussimi01', u'myersmi01', u'oliveda02', u'parkch01', u'perezne01', u'piazzmi01', u'ramirma02', u'rodriiv01', u'rogerke01', u'sandere02', u'schilcu01', u'schmija01', u'seaneru01', u'seleaa01', u'sheffga01', u'smoltjo01', u'sosasa01', u'sprinru01', u'stairma01', u'stantmi02', u'stinnke01', u'suppaje01', u'sweenma01', u'tavarju01', u'thomafr04', u'thomeji01', u'timlimi01', u'trachst01', u'valenjo03', u'villoro01', u'vizquom01', u'wakefti01', u'walketo04', u'weathda01', u'wellsda01', u'whiteri01', u'whitero02', u'wickmbo01', u'williwo02', u'witasja01', u'womacto01', u'zaungr01']],\n",
       "           labels=[[0, 0, 0, 0, 0, 0, 0, 0, 1, 1], [5, 3, 17, 15, 17, 22, 0, 14, 1, 18], [80, 50, 41, 26, 29, 15, 20, 53, 17, 17]],\n",
       "           names=[u'year', u'team', u'player'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_h.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_h.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stint     2\n",
       "lg       NL\n",
       "g        15\n",
       "ab       40\n",
       "r         1\n",
       "h        10\n",
       "X2b       3\n",
       "X3b       0\n",
       "hr        0\n",
       "rbi       8\n",
       "sb        0\n",
       "cs        0\n",
       "bb        4\n",
       "so       10\n",
       "ibb       1\n",
       "hbp       0\n",
       "sh        0\n",
       "sf        1\n",
       "gidp      1\n",
       "Name: (2007, ATL, francju01), dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball_h.ix[(2007, 'ATL', 'francju01')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall earlier we imported some microbiome data using two index columns. This created a 2-level hierarchical index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb = pd.read_csv(\"data/microbiome.csv\", index_col=['Taxon','Patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Tissue  Stool\n",
       "Taxon      Patient               \n",
       "Firmicutes 1           632    305\n",
       "           2           136   4182\n",
       "           3          1174    703\n",
       "           4           408   3946\n",
       "           5           831   8605\n",
       "           6           693     50\n",
       "           7           718    717\n",
       "           8           173     33\n",
       "           9           228     80\n",
       "           10          162   3196"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[[u'Actinobacteria', u'Bacteroidetes', u'Firmicutes', u'Other', u'Proteobacteria'], [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]],\n",
       "           labels=[[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]],\n",
       "           names=[u'Taxon', u'Patient'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a hierachical index, we can select subsets of the data based on a *partial* index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Tissue  Stool\n",
       "Patient               \n",
       "1          1638   3886\n",
       "2          2469   1821\n",
       "3           839    661\n",
       "4          4414     18\n",
       "5         12044     83\n",
       "6          2310     12\n",
       "7          3053    547\n",
       "8           395   2174\n",
       "9          2651    767\n",
       "10         1195     76\n",
       "11         6857    795\n",
       "12          483    666\n",
       "13         2950   3994\n",
       "14         1541    816\n",
       "15         1307     53"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.ix['Proteobacteria']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical indices can be created on either or both axes. Here is a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Ohio       Colorado\n",
       "     Green  Red     Green\n",
       "a 1      0    1         2\n",
       "  2      3    4         5\n",
       "b 1      6    7         8\n",
       "  2      9   10        11"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(np.arange(12).reshape(( 4, 3)), \n",
    "                  index =[['a', 'a', 'b', 'b'], [1, 2, 1, 2]], \n",
    "                  columns =[['Ohio', 'Ohio', 'Colorado'], ['Green', 'Red', 'Green']])\n",
    "\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get fancy, both the row and column indices themselves can be given names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state       Ohio       Colorado\n",
       "color      Green  Red     Green\n",
       "key1 key2                      \n",
       "a    1         0    1         2\n",
       "     2         3    4         5\n",
       "b    1         6    7         8\n",
       "     2         9   10        11"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.index.names = ['key1', 'key2']\n",
    "frame.columns.names = ['state', 'color']\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can do all sorts of custom indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color  Green  Red\n",
       "key2             \n",
       "1          0    1\n",
       "2          3    4"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.ix['a']['Ohio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color\n",
       "Green    11\n",
       "Name: (b, 2), dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.ix['b', 2]['Colorado']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the order of the set of indices in a hierarchical `MultiIndex` can be changed by swapping them pairwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Tissue  Stool\n",
       "Patient Taxon                    \n",
       "1       Firmicutes     632    305\n",
       "2       Firmicutes     136   4182\n",
       "3       Firmicutes    1174    703\n",
       "4       Firmicutes     408   3946\n",
       "5       Firmicutes     831   8605"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.swaplevel('Patient', 'Taxon').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be sorted by any index level, using `sortlevel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        Tissue  Stool\n",
       "Taxon          Patient               \n",
       "Proteobacteria 15         1307     53\n",
       "Other          15          305     32\n",
       "Firmicutes     15          281   2377\n",
       "Bacteroidetes  15          102     33\n",
       "Actinobacteria 15          310    204"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.sortlevel('Patient', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing data\n",
    "\n",
    "The occurence of missing data is so prevalent that it pays to use tools like Pandas, which seamlessly integrates missing data handling so that it can be dealt with easily, and in the manner required by the analysis at hand.\n",
    "\n",
    "Missing data are represented in `Series` and `DataFrame` objects by the `NaN` floating point value. However, `None` is also treated as missing, since it is commonly used as such in other contexts (*e.g.* NumPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1        -3\n",
       "2      None\n",
       "3    foobar\n",
       "dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo = pd.Series([np.nan, -3, None, 'foobar'])\n",
    "foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values may be dropped or indexed out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes         NaN\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2[bacteria2.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `dropna` drops entire rows in which one or more values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555  2013        NaN"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be overridden by passing the `how='all'` argument, which only drops a row when every field is a missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555  2013        NaN"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be customized further by specifying how many values need to be present before a row is dropped via the `thresh` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555   NaN        NaN"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.ix[7, 'year'] = np.nan\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is typically used in time series applications, where there are repeated measurements that are incomplete for some subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to drop missing values column-wise instead of row-wise, we use `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value\n",
       "0       1      Firmicutes   632\n",
       "1       1  Proteobacteria  1638\n",
       "2       1  Actinobacteria   569\n",
       "3       1   Bacteroidetes    14\n",
       "4       2      Firmicutes   433\n",
       "5       2  Proteobacteria     0\n",
       "6       2  Actinobacteria   754\n",
       "7       2   Bacteroidetes   555"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than omitting missing data from an analysis, in some cases it may be suitable to fill the missing value in, either with a default value (such as zero) or a value that is either imputed or carried forward/backward from similar data points. We can do this programmatically in Pandas with the `fillna` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes           0\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013          2\n",
       "7       2   Bacteroidetes   555  2013          2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fillna({'year': 2013, 'treatment':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `fillna` by default returns a new object with the desired filling behavior, rather than changing the `Series` or  `DataFrame` in place (**in general, we like to do this, by the way!**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555   NaN        NaN"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can alter values in-place using `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient          phylum value  year  treatment\n",
       "0       1      Firmicutes   632  2013          0\n",
       "1       1  Proteobacteria  1638  2013          0\n",
       "2       1  Actinobacteria   569  2013          0\n",
       "3       1   Bacteroidetes    14  2013          0\n",
       "4       2      Firmicutes   433  2013          1\n",
       "5       2  Proteobacteria     0  2013          1\n",
       "6       2  Actinobacteria   754  2013        NaN\n",
       "7       2   Bacteroidetes   555  2013        NaN"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = data.year.fillna(2013, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values can also be interpolated, using any one of a variety of methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes         632\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes         946.333333\n",
       "Proteobacteria     632.000000\n",
       "Actinobacteria    1638.000000\n",
       "Bacteroidetes      569.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.fillna(bacteria2.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summarization\n",
    "\n",
    "We often wish to summarize data in `Series` or `DataFrame` objects, so that they can more easily be understood or compared with similar data. The NumPy package contains several functions that are useful here, but several summarization or reduction methods are built into Pandas data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "player    womacto01schilcu01myersmi01helliri01johnsra05f...\n",
       "year                                                 200692\n",
       "stint                                                   113\n",
       "team      CHNBOSNYAMILNYASFNARILANATLNYNTORTBAHOUARIATLM...\n",
       "lg        NLALALNLALNLNLNLNLNLALALNLNLNLALNLNLNLNLALALNL...\n",
       "g                                                      5238\n",
       "ab                                                    13654\n",
       "r                                                      1869\n",
       "...\n",
       "cs        46\n",
       "bb      1549\n",
       "so      2408\n",
       "ibb      177\n",
       "hbp      112\n",
       "sh       138\n",
       "sf       120\n",
       "gidp     354\n",
       "Length: 22, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, `sum` is more meaningful for some columns than others. For methods like `mean` for which application to string variables is not just meaningless, but impossible, these columns are automatically exculded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year     2006.92\n",
       "stint       1.13\n",
       "g          52.38\n",
       "ab        136.54\n",
       "r          18.69\n",
       "h          35.82\n",
       "X2b         7.39\n",
       "X3b         0.55\n",
       "hr          4.37\n",
       "rbi        18.47\n",
       "sb          1.38\n",
       "cs          0.46\n",
       "bb         15.49\n",
       "so         24.08\n",
       "ibb         1.77\n",
       "hbp         1.12\n",
       "sh          1.38\n",
       "sf          1.20\n",
       "gidp        3.54\n",
       "dtype: float64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important difference between NumPy's functions and Pandas' methods is that the latter have built-in support for handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "phylum\n",
       "Firmicutes         NaN\n",
       "Proteobacteria     632\n",
       "Actinobacteria    1638\n",
       "Bacteroidetes      569\n",
       "dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "946.33333333333337"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we may not want to ignore missing values, and allow the `nan` to propagate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bacteria2.mean(skipna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `axis=1` will summarize over rows instead of columns, which only makes sense in certain situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "88653    69\n",
       "89439    57\n",
       "89361    56\n",
       "89462    55\n",
       "89396    54\n",
       "89489    54\n",
       "89360    54\n",
       "89371    50\n",
       "...\n",
       "89445    0\n",
       "89388    0\n",
       "89359    0\n",
       "89355    0\n",
       "89354    0\n",
       "89480    0\n",
       "89348    0\n",
       "89420    0\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_bases = baseball[['X2b','X3b','hr']].sum(axis=1)\n",
    "extra_bases.order(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful summarization that gives a quick snapshot of multiple statistics for a `Series` or `DataFrame` is `describe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             year       stint           g          ab          r           h  \\\n",
       "count   100.00000  100.000000  100.000000  100.000000  100.00000  100.000000   \n",
       "mean   2006.92000    1.130000   52.380000  136.540000   18.69000   35.820000   \n",
       "std       0.27266    0.337998   48.031299  181.936853   27.77496   50.221807   \n",
       "min    2006.00000    1.000000    1.000000    0.000000    0.00000    0.000000   \n",
       "25%    2007.00000    1.000000    9.500000    2.000000    0.00000    0.000000   \n",
       "50%    2007.00000    1.000000   33.000000   40.500000    2.00000    8.000000   \n",
       "75%    2007.00000    1.000000   83.250000  243.750000   33.25000   62.750000   \n",
       "max    2007.00000    2.000000  155.000000  586.000000  107.00000  159.000000   \n",
       "\n",
       "              X2b         X3b          hr        rbi          sb          cs  \\\n",
       "count  100.000000  100.000000  100.000000  100.00000  100.000000  100.000000   \n",
       "mean     7.390000    0.550000    4.370000   18.47000    1.380000    0.460000   \n",
       "std     11.117277    1.445124    7.975537   28.34793    3.694878    1.067613   \n",
       "min      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    2.00000    0.000000    0.000000   \n",
       "75%     11.750000    1.000000    6.000000   27.00000    1.000000    0.000000   \n",
       "max     52.000000   12.000000   35.000000   96.00000   22.000000    6.000000   \n",
       "\n",
       "               bb          so         ibb        hbp          sh          sf  \\\n",
       "count  100.000000  100.000000  100.000000  100.00000  100.000000  100.000000   \n",
       "mean    15.490000   24.080000    1.770000    1.12000    1.380000    1.200000   \n",
       "std     25.812649   32.804496    5.042957    2.23055    2.919042    2.035046   \n",
       "min      0.000000    0.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "25%      0.000000    1.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "50%      1.000000    7.000000    0.000000    0.00000    0.000000    0.000000   \n",
       "75%     19.250000   37.250000    1.250000    1.00000    1.000000    2.000000   \n",
       "max    132.000000  134.000000   43.000000   11.00000   14.000000    9.000000   \n",
       "\n",
       "             gidp  \n",
       "count  100.000000  \n",
       "mean     3.540000  \n",
       "std      5.201826  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      1.000000  \n",
       "75%      6.000000  \n",
       "max     21.000000  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`describe` can detect non-numeric data and sometimes yield useful information about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           100\n",
       "unique           82\n",
       "top       coninje01\n",
       "freq              2\n",
       "dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.player.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate summary statistics *across* multiple columns, for example, correlation and covariance.\n",
    "\n",
    "$$cov(x,y) = \\sum_i (x_i - \\bar{x})(y_i - \\bar{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.076464646464629"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr.cov(baseball.X2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$corr(x,y) = \\frac{cov(x,y)}{(n-1)s_x s_y} = \\frac{\\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_i (x_i - \\bar{x})^2 \\sum_i (y_i - \\bar{y})^2}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77906151825397507"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.hr.corr(baseball.X2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99421740362723787"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.ab.corr(baseball.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           year     stint         g        ab         r         h       X2b  \\\n",
       "year   1.000000  0.004384 -0.050874 -0.001360 -0.023315  0.001151 -0.052917   \n",
       "stint  0.004384  1.000000 -0.257552 -0.216333 -0.209781 -0.206878 -0.196423   \n",
       "g     -0.050874 -0.257552  1.000000  0.935910  0.910262  0.929292  0.885847   \n",
       "ab    -0.001360 -0.216333  0.935910  1.000000  0.965609  0.994217  0.952249   \n",
       "r     -0.023315 -0.209781  0.910262  0.965609  1.000000  0.970560  0.923508   \n",
       "h      0.001151 -0.206878  0.929292  0.994217  0.970560  1.000000  0.957275   \n",
       "X2b   -0.052917 -0.196423  0.885847  0.952249  0.923508  0.957275  1.000000   \n",
       "X3b   -0.246099 -0.085821  0.518663  0.535986  0.500807  0.514245  0.493267   \n",
       "hr     0.060199 -0.209124  0.802014  0.843308  0.890060  0.855163  0.779062   \n",
       "rbi    0.042812 -0.205688  0.891563  0.947911  0.941483  0.952320  0.901751   \n",
       "sb     0.030480 -0.120837  0.492362  0.533536  0.596343  0.530018  0.413655   \n",
       "cs     0.058296 -0.055425  0.520923  0.577192  0.576454  0.571629  0.477487   \n",
       "bb     0.005626 -0.190301  0.828572  0.850803  0.915010  0.853384  0.780012   \n",
       "so     0.069610 -0.214121  0.866499  0.923926  0.879375  0.906966  0.862149   \n",
       "ibb    0.015868 -0.118580  0.514423  0.506398  0.588882  0.513009  0.453301   \n",
       "hbp   -0.000664 -0.195074  0.730161  0.767210  0.806523  0.767449  0.738226   \n",
       "sh    -0.012184 -0.091527  0.079361  0.094537 -0.001273  0.045533  0.005659   \n",
       "sf    -0.007282 -0.155662  0.767543  0.840361  0.839592  0.839737  0.819361   \n",
       "gidp   0.052131 -0.224173  0.863041  0.926632  0.894724  0.935525  0.906860   \n",
       "\n",
       "            X3b        hr       rbi        sb        cs        bb        so  \\\n",
       "year  -0.246099  0.060199  0.042812  0.030480  0.058296  0.005626  0.069610   \n",
       "stint -0.085821 -0.209124 -0.205688 -0.120837 -0.055425 -0.190301 -0.214121   \n",
       "g      0.518663  0.802014  0.891563  0.492362  0.520923  0.828572  0.866499   \n",
       "ab     0.535986  0.843308  0.947911  0.533536  0.577192  0.850803  0.923926   \n",
       "r      0.500807  0.890060  0.941483  0.596343  0.576454  0.915010  0.879375   \n",
       "h      0.514245  0.855163  0.952320  0.530018  0.571629  0.853384  0.906966   \n",
       "X2b    0.493267  0.779062  0.901751  0.413655  0.477487  0.780012  0.862149   \n",
       "X3b    1.000000  0.210028  0.369890  0.450421  0.384312  0.350682  0.408800   \n",
       "hr     0.210028  1.000000  0.948787  0.364346  0.345187  0.916774  0.865929   \n",
       "rbi    0.369890  0.948787  1.000000  0.394633  0.435011  0.893945  0.929410   \n",
       "sb     0.450421  0.364346  0.394633  1.000000  0.743921  0.491351  0.365841   \n",
       "cs     0.384312  0.345187  0.435011  0.743921  1.000000  0.425352  0.426658   \n",
       "bb     0.350682  0.916774  0.893945  0.491351  0.425352  1.000000  0.795751   \n",
       "so     0.408800  0.865929  0.929410  0.365841  0.426658  0.795751  1.000000   \n",
       "ibb    0.090993  0.673691  0.582982  0.209110  0.106152  0.792057  0.476613   \n",
       "hbp    0.217474  0.767411  0.780899  0.413570  0.337129  0.742118  0.742547   \n",
       "sh     0.187012 -0.145374 -0.054670  0.171910  0.293397 -0.044992  0.073624   \n",
       "sf     0.394987  0.782038  0.855260  0.412947  0.422146  0.760932  0.782314   \n",
       "gidp   0.411577  0.798350  0.906908  0.431198  0.456820  0.823631  0.846629   \n",
       "\n",
       "            ibb       hbp        sh        sf      gidp  \n",
       "year   0.015868 -0.000664 -0.012184 -0.007282  0.052131  \n",
       "stint -0.118580 -0.195074 -0.091527 -0.155662 -0.224173  \n",
       "g      0.514423  0.730161  0.079361  0.767543  0.863041  \n",
       "ab     0.506398  0.767210  0.094537  0.840361  0.926632  \n",
       "r      0.588882  0.806523 -0.001273  0.839592  0.894724  \n",
       "h      0.513009  0.767449  0.045533  0.839737  0.935525  \n",
       "X2b    0.453301  0.738226  0.005659  0.819361  0.906860  \n",
       "X3b    0.090993  0.217474  0.187012  0.394987  0.411577  \n",
       "hr     0.673691  0.767411 -0.145374  0.782038  0.798350  \n",
       "rbi    0.582982  0.780899 -0.054670  0.855260  0.906908  \n",
       "sb     0.209110  0.413570  0.171910  0.412947  0.431198  \n",
       "cs     0.106152  0.337129  0.293397  0.422146  0.456820  \n",
       "bb     0.792057  0.742118 -0.044992  0.760932  0.823631  \n",
       "so     0.476613  0.742547  0.073624  0.782314  0.846629  \n",
       "ibb    1.000000  0.431714 -0.075658  0.451377  0.572355  \n",
       "hbp    0.431714  1.000000 -0.104810  0.648882  0.700380  \n",
       "sh    -0.075658 -0.104810  1.000000 -0.002721  0.028924  \n",
       "sf     0.451377  0.648882 -0.002721  1.000000  0.785489  \n",
       "gidp   0.572355  0.700380  0.028924  0.785489  1.000000  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a `DataFrame` with a hierarchical index (or indices), summary statistics can be applied with respect to any of the index levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                    Tissue  Stool\n",
       "Taxon      Patient               \n",
       "Firmicutes 1           632    305\n",
       "           2           136   4182\n",
       "           3          1174    703\n",
       "           4           408   3946\n",
       "           5           831   8605"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                Tissue  Stool\n",
       "Taxon                        \n",
       "Actinobacteria    6736   2263\n",
       "Bacteroidetes     8995   4656\n",
       "Firmicutes       10266  30477\n",
       "Other             2982    519\n",
       "Proteobacteria   44146  16369"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb.sum(level='Taxon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data to Files\n",
    "\n",
    "As well as being able to read several data input formats, Pandas can also export data to a variety of storage formats. We will bring your attention to just a couple of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb.to_csv(\"mb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `to_csv` method writes a `DataFrame` to a comma-separated values (csv) file. You can specify custom delimiters (via `sep` argument), how missing values are written (via `na_rep` argument), whether the index is writen (via `index` argument), whether the header is included (via `header` argument), among other options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An efficient way of storing data to disk is in binary format. Pandas supports this using Python’s built-in pickle serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseball.to_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The complement to `to_pickle` is the `read_pickle` function, which restores the pickle to a `DataFrame` or `Series`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          player  year  stint team  lg    g   ab   r    h  X2b  X3b  hr  rbi  \\\n",
       "id                                                                             \n",
       "88641  womacto01  2006      2  CHN  NL   19   50   6   14    1    0   1    2   \n",
       "88643  schilcu01  2006      1  BOS  AL   31    2   0    1    0    0   0    0   \n",
       "88645  myersmi01  2006      1  NYA  AL   62    0   0    0    0    0   0    0   \n",
       "88649  helliri01  2006      1  MIL  NL   20    3   0    0    0    0   0    0   \n",
       "88650  johnsra05  2006      1  NYA  AL   33    6   0    1    0    0   0    0   \n",
       "88652  finlest01  2006      1  SFN  NL  139  426  66  105   21   12   6   40   \n",
       "88653  gonzalu01  2006      1  ARI  NL  153  586  93  159   52    2  15   73   \n",
       "88662   seleaa01  2006      1  LAN  NL   28   26   2    5    1    0   0    0   \n",
       "89177  francju01  2007      2  ATL  NL   15   40   1   10    3    0   0    8   \n",
       "89178  francju01  2007      1  NYN  NL   40   50   7   10    0    0   1    8   \n",
       "...          ...   ...    ...  ...  ..  ...  ...  ..  ...  ...  ...  ..  ...   \n",
       "89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0   1   12   \n",
       "89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0   0    6   \n",
       "89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2   2   21   \n",
       "89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0  28   66   \n",
       "89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3  10   50   \n",
       "89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0   0    0   \n",
       "89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0   0    0   \n",
       "89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3   3   25   \n",
       "89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1  13   49   \n",
       "89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0   0    0   \n",
       "\n",
       "       sb  cs   bb   so  ibb  hbp  sh  sf  gidp  \n",
       "id                                               \n",
       "88641   1   1    4    4    0    0   3   0     0  \n",
       "88643   0   0    0    1    0    0   0   0     0  \n",
       "88645   0   0    0    0    0    0   0   0     0  \n",
       "88649   0   0    0    2    0    0   0   0     0  \n",
       "88650   0   0    0    4    0    0   0   0     0  \n",
       "88652   7   0   46   55    2    2   3   4     6  \n",
       "88653   0   1   69   58   10    7   0   6    14  \n",
       "88662   0   0    1    7    0    0   6   0     1  \n",
       "89177   0   0    4   10    1    0   0   1     1  \n",
       "89178   2   1   10   13    0    0   0   1     1  \n",
       "...    ..  ..  ...  ...  ...  ...  ..  ..   ...  \n",
       "89499   2   1   14   50    0    1   3   3     8  \n",
       "89501   0   0    4    6    0    0   0   0     1  \n",
       "89502   2   0   15   13    0    1   3   2     9  \n",
       "89521   5   0  132   54   43    3   0   2    13  \n",
       "89523   4   3   23  112    0    3   7   5     5  \n",
       "89525   0   0    0    0    0    0   0   0     0  \n",
       "89526   0   0    0    0    0    0   0   0     0  \n",
       "89530   6   1   37   74    3    6   4   1    11  \n",
       "89533   3   0   27   30    5    2   0   3    13  \n",
       "89534   0   0    0    3    0    0   0   0     0  \n",
       "\n",
       "[100 rows x 22 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"baseball_pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Wes warns in his book, it is recommended that binary storage of data via pickle only be used as a temporary storage format, in situations where speed is relevant. This is because there is no guarantee that the pickle format will not change with future versions of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Pandas\n",
    "\n",
    "Now that we have been exposed to the basic functionality of Pandas, lets explore some more advanced features that will be useful when addressing more complex data management tasks.\n",
    "\n",
    "As most statisticians/data analysts will admit, often the lion's share of the time spent implementing an analysis is devoted to preparing the data itself, rather than to coding or running a particular model that uses the data. This is where Pandas and  Python's standard library are beneficial, providing high-level, flexible, and efficient tools for manipulating your data as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set some Pandas options\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date/Time data handling\n",
    "\n",
    "Date and time data are inherently problematic. There are an unequal number of days in every month, an unequal number of days in a year (due to leap years), and time zones that vary over space. Yet information about time is essential in many analyses, particularly in the case of time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `datetime` built-in library handles temporal information down to the nanosecond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 6, 18, 10, 40, 0, 248479)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.weekday()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to `datetime` there are simpler objects for date and time information only, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import date, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.time(3, 24)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time(3, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(1970, 9, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date(1970, 9, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a custom data type for dates and times is convenient because we can perform operations on them easily. For example, we may want to calculate the difference between two times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(15994, 38400, 248479)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_age = now - datetime(1970, 9, 3)\n",
    "my_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.81917808219178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_age.days/365."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will manipulate data collected from ocean-going vessels on the eastern seaboard. Vessel operations are monitored using the Automatic Identification System (AIS), a safety at sea navigation technology which vessels are required to maintain and that uses transponders to transmit very high frequency (VHF) radio signals containing static information including ship name, call sign, and country of origin, as well as dynamic information unique to a particular voyage such as vessel location, heading, and speed. \n",
    "\n",
    "The International Maritime Organization’s (IMO) International Convention for the Safety of Life at Sea requires functioning AIS capabilities on all vessels 300 gross tons or greater and the US Coast Guard requires AIS on nearly all vessels sailing in U.S. waters. The Coast Guard has established a national network of AIS receivers that provides coverage of nearly all U.S. waters. AIS signals are transmitted several times each minute and the network is capable of handling thousands of reports per minute and updates as often as every two seconds. Therefore, a typical voyage in our study might include the transmission of hundreds or thousands of AIS encoded signals. This provides a rich source of spatial data that includes both spatial and temporal information.\n",
    "\n",
    "For our purposes, we will use summarized data that describes the transit of a given vessel through a particular administrative area. The data includes the start and end time of the transit segment, as well as information about the speed of the vessel, how far it travelled, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mmsi               name  transit  segment  seg_length  avg_sog  min_sog  \\\n",
       "0     1        Us Govt Ves        1        1         5.1     13.2      9.2   \n",
       "1     1  Dredge Capt Frank        1        1        13.5     18.6     10.4   \n",
       "2     1      Us Gov Vessel        1        1         4.3     16.2     10.3   \n",
       "3     1      Us Gov Vessel        2        1         9.2     15.4     14.5   \n",
       "4     1  Dredge Capt Frank        2        1         9.2     15.4     14.6   \n",
       "\n",
       "   max_sog  pdgt10        st_time       end_time  \n",
       "0     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
       "1     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
       "2     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
       "3     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
       "4     16.2   100.0  4/10/09 17:59  4/10/09 18:35  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = pd.read_csv(\"data/AIS/transit_segments.csv\")\n",
    "segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we might be interested in the distribution of transit lengths, so we can plot them as a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x117716bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1104583d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments.seg_length.hist(bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though most of the transits appear to be short, there are a few longer distances that make the plot difficult to read. This is where a transformation is useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11382bb90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGGBJREFUeJzt3W2MXGd5xvH/lZhAAilLWsl5hY2KU+KKyuAIR7Rptm2I\nDCpJPlR5UaEY3EpVaBP3FZsPeP2FAlKV0FZJ1YawDg0pBgoFEUxM8JailjhAXALGJUFsG5vaQQSH\nvkhVTO5+mGfj6XpmvDt7dp9z71w/aeRzzpzZufbx7Ln3PPeZWUUEZmY2mk6rHcDMzOpxETAzG2Eu\nAmZmI8xFwMxshLkImJmNMBcBM7MRNrAISLpb0lFJj3ZtO0fSHknflvSApLGu+7ZJekzSQUlXd21f\nL+nRct/7u7Y/X9JHyvYvS3pZ09+gmZn1d6ozgQ8CG+ds2wrsiYhLgAfLOpLWAjcAa8tj7pCk8pg7\ngc0RsQZYI2n2a24GflC23wa8d5Hfj5mZLcDAIhAR/wj8cM7ma4CdZXkncF1Zvha4LyKeiYgZ4HFg\ng6TzgLMjYl/Z756ux3R/rY8DvzLk92FmZkMYpiewOiKOluWjwOqyfD5wqGu/Q8AFPbYfLtsp/z4B\nEBHHgaclnTNEJjMzG8KiGsPR+cwJf+6EmVlSq4Z4zFFJ50bEkTLV82TZfhi4qGu/C+mcARwuy3O3\nzz7mpcD3JK0CXhwRT819QkkuNGZmQ4gIDbp/mDOBTwFvKctvAT7Ztf1GSWdIuhhYA+yLiCPAjyRt\nKI3iNwN/3+Nr/RqdRnO/b6T1t+3bt1fP4JzOmTWjczZ/m4+BZwKS7gOuBH5K0hPAu4D3ALskbQZm\ngOvLQfqApF3AAeA4cHOcSHEzMAWcCdwfEbvL9g8AH5L0GPAD4MZ5pW6pmZmZ2hHmxTmblSFnhozg\nnDUMLAIRcVOfu67qs/+7gXf32P5V4JU9tv8vpYiYmdny8zuGG7Rp06baEebFOZuVIWeGjOCcNWi+\n80Y1SYoMOc3M2kQSsQSNYetjenq6doR5cc5mZciZISM4Zw0uAmZmI8zTQWZmK5Sng8zMbCAXgQZl\nmSd0zmZlyJkhIzhnDS4CZmYjzD0BM7MVyj0BS0sSJ/4mkZktFReBBmWZJ8ySM4sM45khIzhnDS4C\nZmYjzD0Ba6XZqSD/v5sNzz0BMzMbyEWgQVnmCbPkzCLDeGbICM5Zg4uAmdkIc0/AWsk9AbPFc0/A\nzMwGchFoUJZ5wiw5s8gwnhkygnPW4CJgZjbC3BOwVnJPwGzx3BMwM7OBXAQalGWeMEvOLDKMZ4aM\n4Jw1uAiYmY0w9wSsldwTMFs89wTMzGwgF4EGZZknzJIziwzjmSEjOGcNLgJmZiPMPQFrJfcEzBbP\nPQEzMxvIRaBBWeYJs+Ts1uY/PJ9hPDNkBOeswUXAzGyEuSdgrTS3J+AegdnCuSdgZmYDuQg0KMs8\nYZacWWQYzwwZwTlrcBEwMxthQ/cEJG0D3gQ8CzwKvBV4IfAR4GXADHB9RBzr2v9twI+BWyLigbJ9\nPTAFvAC4PyJu7fFc7gmMGPcEzBZvyXoCksaB3wJeHRGvBE4HbgS2Ansi4hLgwbKOpLXADcBaYCNw\nh05c73cnsDki1gBrJG0cJpOZmS3csNNBPwKeAc6StAo4C/gecA2ws+yzE7iuLF8L3BcRz0TEDPA4\nsEHSecDZEbGv7HdP12PSyTJPmCVnFhnGM0NGcM4ahioCEfEU8KfAv9M5+B+LiD3A6og4WnY7Cqwu\ny+cDh7q+xCHggh7bD5ftZma2DFYN8yBJPw1sAcaBp4GPSnpT9z4REZIam8DdtGkT4+PjAIyNjbFu\n3TomJiaAE1XZ6/Nbn93Wljz91ruz9lqvnS/7eNbO02t9YmKiVXkGrc9qS57ZsZuamgJ47nh5KkM1\nhiXdALwuIn6zrL8ZuBz4ZeCXIuJImerZGxGvkLQVICLeU/bfDWwH/q3sc2nZfhNwZUT89pznc2N4\nxLgxbLZ4S/lmsYPA5ZLOLA3eq4ADwKeBt5R93gJ8six/CrhR0hmSLgbWAPsi4gjwI0kbytd5c9dj\n0pn7G0JbZcmZRYbxzJARnLOGoaaDIuJfJN0DfIXOJaJfA/4KOBvYJWkz5RLRsv8BSbvoFIrjwM1d\nv9rfTOcS0TPpXCK6e+jvxszMFsSfHWSt5Okgs8XzZweZmdlALgINyjJPmCVnFhnGM0NGcM4aXATM\nzEaYewLWSu4JmC2eewJmZjaQi0CDsswTZsmZRYbxzJARnLMGFwFrnbb+QXmzlcg9AWud7iLgnoDZ\n8NwTMDOzgVwEGpRlnjBLziwyjGeGjOCcNbgImJmNMPcErHXcEzBrhnsCZmY2kItAg7LME2bJmUWG\n8cyQEZyzBhcBM7MR5p6AtY57AmbNcE/AzMwGchFoUJZ5wiw5s8gwnhkygnPW4CJgZjbC3BOw1uj1\nwXHuCZgNzz0BMzMbyEWgQVnmCbPkzCLDeGbICM5Zg4uAmdkIc0/AWsM9AbNmuSdgZmYDuQg0KMs8\nYZacWWQYzwwZwTlrcBEwMxth7glYa7gnYNYs9wTMzGwgF4EGZZknzJIziwzjmSEjOGcNLgK2IkxO\nTtaOYJaSewLWGovpCZS5z6ULZ5bQfHoCq5YrjNkwehUGM2uOp4MalGWeMEvOLDKMZ4aM4Jw1uAiY\nmY2woXsCksaAu4CfBQJ4K/AY8BHgZcAMcH1EHCv7bwPeBvwYuCUiHijb1wNTwAuA+yPi1h7P5Z7A\nCJjP1I97Ambzt9TvE3g/nYP2pcDPAQeBrcCeiLgEeLCsI2ktcAOwFtgI3KETP/F3ApsjYg2wRtLG\nRWQyM7MFGKoISHoxcEVE3A0QEccj4mngGmBn2W0ncF1Zvha4LyKeiYgZ4HFgg6TzgLMjYl/Z756u\nx6STZZ4wS84sMoxnhozgnDUMeyZwMfB9SR+U9DVJfy3phcDqiDha9jkKrC7L5wOHuh5/CLigx/bD\nZbuZmS2DoXoCki4D/hl4bUQ8LOl24D+B34mIl3Tt91REnCPpz4EvR8S9ZftdwGfp9A3eExGvK9uv\nAP44It445/ncExgB7gmYNWsp3ydwCDgUEQ+X9Y8B24Ajks6NiCNlqufJcv9h4KKux19Yvsbhsty9\n/XCvJ9y0aRPj4+MAjI2NsW7dOiYmJoATp2Zez70+X6d6fFu+H697fbnXp6enmZqaAnjueHlKETHU\nDfgicElZngTeV27vKNu20vktHzoN4f3AGXSmkr7DibOQh4ANgID7gY09nisy2Lt3b+0I89LWnHSu\nMht4G/TYWto6nt0yZIxwzqaVn4uBx/LFvGP4d4F7JZ1RDupvBU4HdknaTLlEtBzBD0jaBRwAjgM3\nl4AAN9O5RPRMOlcb7V5EJjMzWwB/dpC1hnsCZs3y3xMwM7OBXAQatNAGZy1ZcmaRYTwzZATnrMFF\nwMxshLknYK3hnoBZs9wTMDOzgVwEGpRlnjBLziwyjGeGjOCcNbgIWCr+W8JmzXJPwFpjvn9Kstdr\nwT0Bs5O5J2BmZgO5CDQoyzxhlpxZZBjPDBnBOWtwETAzG2HuCVhruCdg1iz3BGykzLeImNkJLgIN\nyjJPmCVnFhnGM0NGcM4aXASsFfxbvFkd7glYKyykCPTrCfS7z2xUuSdgZmYDuQg0KMs8YZacWWQY\nzwwZwTlrcBEwMxth7glYK7gnYNY89wTMzGwgF4EGZZknzJIziwzjmSEjOGcNLgJmZiPMPQFrBfcE\nzJrnnoCZmQ3kItCgLPOEWXJmkWE8M2QE56zBRcDMbIS5J2Ct4J6AWfPcEzAzs4FcBBqUZZ4wS84s\nMoxnhozgnDW4CJiZjTD3BKwV3BMwa557AmZmNpCLQIOyzBNmyZlFhvHMkBGcswYXATOzEeaegLWC\newJmzVvynoCk0yU9IunTZf0cSXskfVvSA5LGuvbdJukxSQclXd21fb2kR8t9719MHjMzW5jFTgfd\nChwAZn/92grsiYhLgAfLOpLWAjcAa4GNwB068avfncDmiFgDrJG0cZGZqskyT5glZxYZxjNDRnDO\nGoYuApIuBN4A3AXMHtCvAXaW5Z3AdWX5WuC+iHgmImaAx4ENks4Dzo6IfWW/e7oeYzYv3VNJkhY0\ntWQ26obuCUj6KPBu4CeAP4yIN0r6YUS8pNwv4KmIeImkPwe+HBH3lvvuAj4LzADviYjXle1XAH8c\nEW+c81zuCaxwi+kJ9HqsXy9mS9gTkPSrwJMR8QgnzgL+n3LU9k+imVmLrRryca8FrpH0BuAFwE9I\n+hBwVNK5EXGkTPU8WfY/DFzU9fgLgUNl+4Vzth/u9YSbNm1ifHwcgLGxMdatW8fExARwYn6u9vrs\ntrbk6bd+++23t3b85mM+VwJNT0+P/Hh2r+/fv58tW7a0Jk+/9bk/S7Xz9Ftv63hOT08zNTUF8Nzx\n8pQiYlE34Erg02X5fcA7yvJWOlM90GkI7wfOAC4GvsOJqaiHgA10zijuBzb2eI7IYO/evbUjzEsb\nc9I5a1zQbdBjl1Mbx3OuDBkjnLNp5Wdh4DF80e8TkHQl8AcRcY2kc4BdwEvpzPdfHxHHyn7vBN4G\nHAdujYjPle3rgSngTOD+iLilx3PEYnNauw3TzJ19TbgnYNbbfHoCfrOYtYKLgFnz/AFyy2yhc9u1\nZMmZRYbxzJARnLMGFwEzsxHm6SBrBU8HmTXP00FmZjaQi0CDsswTZsmZRYbxzJARnLMGFwEzsxHm\nnoC1gnsCZs1zT8DMzAZyEWhQlnnCLDmzyDCeGTKCc9bgImCpTU5O1o5glpp7AtYKTf8hGL9ezNwT\nMDOzU3ARaFCWecIsObPIMJ4ZMoJz1uAiYGY2wtwTsFZwT8Csee4JmJnZQC4CDcoyT5glZxYZxjND\nRnDOGlwEzMxGmHsC1gruCZg1zz0BMzMbyEWgQVnmCbPkzCLDeGbICM5Zg4uAmdkIc0/AWmEpegKz\nX9OvHRtV7gmYmdlALgINyjJPmCVnFhnGM0NGcM4aXASsuqangsxs/twTsOqWowj49WOjyD0BMzMb\nyEWgQVnmCbPkzCLDeGbICM5Zg4uAmdkIc0/AqnNPwGxpuCdgVvgKJLPeXAQalGWeMEvOLDKMZ4aM\n4Jw1uAiYmY0w9wSsuuWaqvFryEaNewJmZjbQUEVA0kWS9kr6pqRvSLqlbD9H0h5J35b0gKSxrsds\nk/SYpIOSru7avl7So+W+9y/+W6onyzxhlpxNk7QkZx0ZxjNDRnDOGoY9E3gG+L2I+FngcuDtki4F\ntgJ7IuIS4MGyjqS1wA3AWmAjcIdO/DTeCWyOiDXAGkkbh/5uLB1ftWNWVyM9AUmfBP6i3K6MiKOS\nzgWmI+IVkrYBz0bEe8v+u4FJ4N+AL0TEpWX7jcBERPz2nK/vnsAKVaMI+LVko2JZegKSxoFXAQ8B\nqyPiaLnrKLC6LJ8PHOp62CHggh7bD5ftZma2DFYt5sGSXgR8HLg1Iv6z+7e6iAhJjf3KtWnTJsbH\nxwEYGxtj3bp1TExMACfm52qvz25rS55+67fffnurxm+5rfTx7LW+f/9+tmzZ0po8/dbn/izVztNv\nva3jOT09zdTUFMBzx8tTioihbsDzgM8BW7q2HQTOLcvnAQfL8lZga9d+u4ENwLnAt7q23wT8ZY/n\nigz27t1bO8K8tCknsOy3prVpPPvJkDHCOZtWXu8Dj+VD9QRKU3cn8IOI+L2u7e8r294raSswFhFb\nS2P4w8Br6Ez3fB54eUSEpIeAW4B9wGeAP4uI3XOeL4bJae3nnoDZ0plPT2DYIvALwBeBr9P57Qpg\nG50D+S7gpcAMcH1EHCuPeSfwNuA4nemjz5Xt64Ep4Ezg/oi4pcfzuQisULWuDvLryUbBkjWGI+JL\nEXFaRKyLiFeV2+6IeCoiroqISyLi6tkCUB7z7oh4eUS8YrYAlO1fjYhXlvtOKgCZdM9ntlmWnEtp\ncnKysa+VYTwzZATnrMHvGLaRtGPHjtoRzFrBnx1kVdV8s5hfU7bS+bODrNX8bmGz+lwEGpRlnjBL\nziwyjGeGjOCcNbgImJmNMPcErJra00F+TdlK556AmZkN5CLQoCzzhFlyZpFhPDNkBOeswUXAqqg9\nFWRmHe4JWBVtKAJ+TdlK556AmZkN5CLQoCzzhFlyZpFhPDNkBOeswUXAll2TH95mZovjnoAtuzb0\nA2b5dWUrmXsCZmY2kItAg7LME2bJ2Tb9prEyjGeGjOCcNbgI2LLJ3AuYnJz03yCwFck9AVs2ZX4y\nZU9gNrNfh5aJewJmZjaQi0CDsswTZsm5HCQt+swkw3hmyAjOWYOLgJnZCHNPwJbU5OTkcw3hNvYE\nug16jbknYBnNpyfgImBLavbA373sImC2PNwYXmZZ5glr5mxrAYD+2U6VOcP/e4aM4Jw1uAiYdZlt\nFGd+T4PZQng6yBrTa8pk7nRQJr1y+3VomXg6yFojWwEwGxUuAg3KMk/YdM5e19p3b8tcAOaTPcP/\ne4aM4Jw1uAhY4zIf9Lv1+j5WyvdmNss9AVu0UTsw+rVoWbgnYEtu1AqA2UqTsgjMnYNuy+V8WeYJ\n55tz7rx+95g38Zk7K0WG//cMGcE5a0hZBObq/px3H5z6G1Qsex3k+y17fM1WjpQ9gbnXo/e6Fr37\n4wki4v99hs2o6h6nWbPj4gP7wmT4uTFbUZ8d9PDDD3PZZZfNrgMLKwLd+/Q78GUYi8XoVQTa/nk+\nbdbr9eLPGLI2SdMYlrRR0kFJj0l6R699vvvd7zb2fIP+TODs2UK/s4ZB18Q3eSA9VY6Ffq3ubNPT\n0yN/VtSEuf/v/abQ2iDLHLZzVhARVW/A6cDjwDjwPGA/cOmcfWLXrl0xC4hO9BPrve6buzx3/9n7\ne+3Xb5/Z2/bt2/ve171PRMT27dufWx72a/mW+1bbbbfdVjvCvDhns8prb+AxuA1nAq8BHo+ImYh4\nBvhb4NrKmU5pPn90fHafHTt2sGPHjr6/HfoPmK98vc4a5r4eZs/YejXiF3tmcezYsUU9frk45/Jb\nVTsAcAHwRNf6IWBDpSxmS24+00anerdyuOdgDWlDEfCr2WyBhjkzGHTGGXMupBg2z2KL08zMzJJ9\n7Sb1yplV9auDJF0OTEbExrK+DXg2It7btU97/vfNzBKJtl8iKmkV8K/ArwDfA/YBN0XEt6oGMzMb\nAdWngyLiuKTfAT5H50qhD7gAmJktj+pnAmZmVk8bLhEdaD5vJKtN0t2Sjkp6tHaWQSRdJGmvpG9K\n+oakW2pnmkvSCyQ9JGm/pAOS/qR2pkEknS7pEUmfrp2lH0kzkr5ecu6rnacfSWOSPibpW+X//vLa\nmeaS9DNlHGdvT7fx5wg6/dXys/6opA9Len7P/dp8JiDpdDr9gquAw8DDtLBfIOkK4L+AeyLilbXz\n9CPpXODciNgv6UXAV4HrWjieZ0XE/5R+0ZeAP4yIL9XO1Yuk3wfWA2dHxDW18/Qi6bvA+oh4qnaW\nQSTtBP4hIu4u//cvjIina+fqR9JpdI5Lr4mIJ061/3KSNA58gc4bb/9X0keA+yNi59x9234mkOKN\nZBHxj8APa+c4lYg4EhH7y/J/Ad8Czq+b6mQR8T9l8Qw6faJWHrwkXQi8AbgLaNfnRJys1fkkvRi4\nIiLuhk6vsM0FoLgK+E7bCkDxI+AZ4KxSUM+iU7BO0vYi0OuNZBdUyrKilN8UXgU8VDfJySSdJmk/\ncBTYGxEHamfq4zbgj4Bnawc5hQA+L+krkn6rdpg+Lga+L+mDkr4m6a8lnVU71CncCHy4doheylnf\nnwL/Tueqy2MR8fle+7a9CLR3riqxMhX0MeDWckbQKhHxbESsAy4EflHSROVIJ5H0q8CTEfEILf8t\nG/j5iHgV8Hrg7WX6sm1WAa8G7oiIVwP/DWytG6k/SWcAbwQ+WjtLL5J+GthC5zPZzgdeJOnXe+3b\n9iJwGLioa/0iOmcDNiRJzwM+DvxNRHyydp5BynTAZ4DLamfp4bXANWW+/T7glyXdUzlTTxHxH+Xf\n7wOfoDPN2jaHgEMR8XBZ/xidotBWrwe+Wsa0jS4D/ikifhARx4G/o/OaPUnbi8BXgDWSxkvlvQH4\nVOVMaanz/vsPAAci4vbaeXqR9FOSxsrymcDrgEfqpjpZRLwzIi6KiIvpTAt8ISJ+o3auuSSdJens\nsvxC4GqgdVexRcQR4AlJl5RNVwHfrBjpVG6iU/zb6iBwuaQzy8/9VUDPadXqbxYbJMsbySTdB1wJ\n/KSkJ4B3RcQHK8fq5eeBNwFflzR7YN0WEbsrZprrPGBnufLiNOBDEfFg5Uzz0dapy9XAJ8rn76wC\n7o2IB+pG6ut3gXvLL3zfAd5aOU9PpZheBbS1v0JE/Es5M/0KnZ7V14C/6rVvqy8RNTOzpdX26SAz\nM1tCLgJmZiPMRcDMbIS5CJiZjTAXATOzEeYiYGY2wlwEzMxGmIuAmdkI+z9v8LeJ3GwnTgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11382b510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments.seg_length.apply(np.log).hist(bins=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although there are date/time fields in the dataset, they are not in any specialized format, such as `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.st_time.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first order of business will be to convert these data to `datetime`. The `strptime` method parses a string representation of a date and/or time field, according to the expected format of this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2009, 2, 10, 16, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strptime(segments.st_time.ix[0], '%m/%d/%y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dateutil` package includes a parser that attempts to detect the format of the date strings, and convert them automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2009, 2, 10, 16, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(segments.st_time.ix[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert all the dates in a particular column by using the `apply` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2009-02-10 16:03:00\n",
       "1   2009-04-06 14:31:00\n",
       "2   2009-04-06 14:36:00\n",
       "3   2009-04-10 17:58:00\n",
       "4   2009-04-10 17:59:00\n",
       "5   2010-03-20 16:06:00\n",
       "6   2010-03-20 18:05:00\n",
       "7   2011-05-04 11:28:00\n",
       "8   2010-06-05 11:23:00\n",
       "9   2010-06-08 11:03:00\n",
       "...\n",
       "262515   2010-05-31 14:27:00\n",
       "262516   2010-06-05 05:25:00\n",
       "262517   2010-06-27 02:35:00\n",
       "262518   2010-07-01 03:49:00\n",
       "262519   2010-07-02 03:30:00\n",
       "262520   2010-06-13 10:32:00\n",
       "262521   2010-06-15 12:49:00\n",
       "262522   2010-06-15 21:32:00\n",
       "262523   2010-06-17 19:16:00\n",
       "262524   2010-06-18 02:52:00\n",
       "262525   2010-06-18 10:19:00\n",
       "Name: st_time, Length: 262526, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.st_time.apply(lambda d: datetime.strptime(d, '%m/%d/%y %H:%M'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a convenience, Pandas has a `to_datetime` method that will parse and convert an entire Series of formatted strings into `datetime` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2009-02-10 16:03:00\n",
       "1   2009-04-06 14:31:00\n",
       "2   2009-04-06 14:36:00\n",
       "3   2009-04-10 17:58:00\n",
       "4   2009-04-10 17:59:00\n",
       "5   2010-03-20 16:06:00\n",
       "6   2010-03-20 18:05:00\n",
       "7   2011-05-04 11:28:00\n",
       "8   2010-06-05 11:23:00\n",
       "9   2010-06-08 11:03:00\n",
       "...\n",
       "262515   2010-05-31 14:27:00\n",
       "262516   2010-06-05 05:25:00\n",
       "262517   2010-06-27 02:35:00\n",
       "262518   2010-07-01 03:49:00\n",
       "262519   2010-07-02 03:30:00\n",
       "262520   2010-06-13 10:32:00\n",
       "262521   2010-06-15 12:49:00\n",
       "262522   2010-06-15 21:32:00\n",
       "262523   2010-06-17 19:16:00\n",
       "262524   2010-06-18 02:52:00\n",
       "262525   2010-06-18 10:19:00\n",
       "Name: st_time, Length: 262526, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(segments.st_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also has a custom NA value for missing datetime objects, `NaT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.tseries.index.DatetimeIndex'>\n",
       "[NaT]\n",
       "Length: 1, Freq: None, Timezone: None"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime([None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, if `to_datetime()` has problems parsing any particular date/time format, you can pass the spec in using the `format=` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and joining DataFrame objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the vessel transit information as we need it, we may want a little more information regarding the vessels themselves. In the `data/AIS` folder there is a second table that contains information about each of the ships that traveled the segments in the `segments` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      num_names                                              names sov  \\\n",
       "mmsi                                                                     \n",
       "1             8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
       "9             3                         000000009/Raven/Shearwater   N   \n",
       "21            1                                      Us Gov Vessel   Y   \n",
       "74            2                                  Mcfaul/Sarah Bell   N   \n",
       "103           3           Ron G/Us Navy Warship 103/Us Warship 103   Y   \n",
       "\n",
       "         flag flag_type  num_loas                                    loa  \\\n",
       "mmsi                                                                       \n",
       "1     Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
       "9     Unknown   Unknown         2                              50.0/62.0   \n",
       "21    Unknown   Unknown         1                                  208.0   \n",
       "74    Unknown   Unknown         1                                  155.0   \n",
       "103   Unknown   Unknown         2                             26.0/155.0   \n",
       "\n",
       "      max_loa  num_types                             type  \n",
       "mmsi                                                       \n",
       "1         156          4  Dredging/MilOps/Reserved/Towing  \n",
       "9          62          2                     Pleasure/Tug  \n",
       "21        208          1                          Unknown  \n",
       "74        155          1                          Unknown  \n",
       "103       155          2                   Tanker/Unknown  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels = pd.read_csv(\"data/AIS/vessel_information.csv\", index_col='mmsi')\n",
    "vessels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unknown',\n",
       " 'Other',\n",
       " 'Tug',\n",
       " 'Towing',\n",
       " 'Pleasure',\n",
       " 'Cargo',\n",
       " 'WIG',\n",
       " 'Fishing',\n",
       " 'BigTow',\n",
       " 'MilOps',\n",
       " 'Tanker',\n",
       " 'Passenger',\n",
       " 'SAR',\n",
       " 'Sailing',\n",
       " 'Reserved',\n",
       " 'Law',\n",
       " 'Dredging',\n",
       " 'AntiPol',\n",
       " 'Pilot',\n",
       " 'HSC',\n",
       " 'Diving',\n",
       " 'Resol-18',\n",
       " 'Tender',\n",
       " 'Spare',\n",
       " 'Medical']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for v in vessels.type.unique() if v.find('/')==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cargo        5622\n",
       "Tanker       2440\n",
       "Pleasure      601\n",
       "Tug           221\n",
       "Sailing       205\n",
       "Fishing       200\n",
       "Other         178\n",
       "Passenger     150\n",
       "Towing        117\n",
       "Unknown       106\n",
       "...\n",
       "BigTow/Tanker/Towing/Tug          1\n",
       "Fishing/SAR/Unknown               1\n",
       "BigTow/Reserved/Towing/Tug/WIG    1\n",
       "Reserved/Tanker/Towing/Tug        1\n",
       "Cargo/Reserved/Unknown            1\n",
       "Reserved/Towing/Tug               1\n",
       "BigTow/Unknown                    1\n",
       "Fishing/Law                       1\n",
       "BigTow/Towing/WIG                 1\n",
       "Towing/Unknown/WIG                1\n",
       "AntiPol/Fishing/Pleasure          1\n",
       "Length: 206, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge, however, is that several ships have travelled multiple segments, so there is not a one-to-one relationship between the rows of the two tables. The table of vessel information has a *one-to-many* relationship with the segments.\n",
    "\n",
    "In Pandas, we can combine tables according to the value of one or more *keys* that are used to identify rows, much like an index. Using a trivial example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   age  id\n",
       " 0   24   0\n",
       " 1   25   1\n",
       " 2   25   2\n",
       " 3   30   3,    id     score\n",
       " 0   0  0.068840\n",
       " 1   1  0.784715\n",
       " 2   2  0.590726\n",
       " 3   0  0.892117\n",
       " 4   1  0.506912\n",
       " 5   2  0.721110)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(dict(id=range(4), age=np.random.randint(18, 31, size=4)))\n",
    "df2 = pd.DataFrame(dict(id=range(3)+range(3), score=np.random.random(size=6)))\n",
    "\n",
    "df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  id     score\n",
       "0   24   0  0.068840\n",
       "1   24   0  0.892117\n",
       "2   25   1  0.784715\n",
       "3   25   1  0.506912\n",
       "4   25   2  0.590726\n",
       "5   25   2  0.721110"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that without any information about which column to use as a key, Pandas did the right thing and used the `id` column in both tables. Unless specified otherwise, `merge` will used any common column names as keys for merging the tables. \n",
    "\n",
    "Notice also that `id=3` from `df1` was omitted from the merged table. This is because, by default, `merge` performs an **inner join** on the tables, meaning that the merged table represents an intersection of the two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   age  id     score\n",
       "0   24   0  0.068840\n",
       "1   24   0  0.892117\n",
       "2   25   1  0.784715\n",
       "3   25   1  0.506912\n",
       "4   25   2  0.590726\n",
       "5   25   2  0.721110\n",
       "6   30   3       NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df1, df2, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **outer join** above yields the union of the two tables, so all rows are represented, with missing values inserted as appropriate. One can also perform **right** and **left** joins to include all rows of the right or left table (*i.e.* first or second argument to `merge`), but not necessarily the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the two datasets that we wish to merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mmsi         name  transit  segment  seg_length  avg_sog  min_sog  max_sog  \\\n",
       "0     1  Us Govt Ves        1        1         5.1     13.2      9.2     14.5   \n",
       "\n",
       "   pdgt10        st_time       end_time  \n",
       "0    96.5  2/10/09 16:03  2/10/09 16:27  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      num_names                                              names sov  \\\n",
       "mmsi                                                                     \n",
       "1             8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
       "\n",
       "         flag flag_type  num_loas                                    loa  \\\n",
       "mmsi                                                                       \n",
       "1     Unknown   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0   \n",
       "\n",
       "      max_loa  num_types                             type  \n",
       "mmsi                                                       \n",
       "1         156          4  Dredging/MilOps/Reserved/Towing  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that there is a `mmsi` value (a vessel identifier) in each table, but it is used as an index for the `vessels` table. In this case, we have to specify to join on the index for this table, and on the `mmsi` column for the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "segments_merged = pd.merge(vessels, segments, left_index=True, right_on='mmsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   num_names                                              names sov     flag  \\\n",
       "0          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "2          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "3          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "4          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "\n",
       "  flag_type  num_loas                                    loa  max_loa  \\\n",
       "0   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "1   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "2   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "3   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "4   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "\n",
       "   num_types                             type  \\\n",
       "0          4  Dredging/MilOps/Reserved/Towing   \n",
       "1          4  Dredging/MilOps/Reserved/Towing   \n",
       "2          4  Dredging/MilOps/Reserved/Towing   \n",
       "3          4  Dredging/MilOps/Reserved/Towing   \n",
       "4          4  Dredging/MilOps/Reserved/Towing   \n",
       "\n",
       "                ...                              name transit  segment  \\\n",
       "0               ...                       Us Govt Ves       1        1   \n",
       "1               ...                 Dredge Capt Frank       1        1   \n",
       "2               ...                     Us Gov Vessel       1        1   \n",
       "3               ...                     Us Gov Vessel       2        1   \n",
       "4               ...                 Dredge Capt Frank       2        1   \n",
       "\n",
       "   seg_length  avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
       "0         5.1     13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
       "1        13.5     18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
       "2         4.3     16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
       "3         9.2     15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
       "4         9.2     15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the default inner join is suitable; we are not interested in observations from either table that do not have corresponding entries in the other. \n",
    "\n",
    "Notice that `mmsi` field that was an index on the `vessels` table is no longer an index on the merged table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used the `merge` function to perform the merge; we could also have used the `merge` method for either of the tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   num_names                                              names sov     flag  \\\n",
       "0          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "2          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "3          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "4          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "\n",
       "  flag_type  num_loas                                    loa  max_loa  \\\n",
       "0   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "1   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "2   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "3   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "4   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "\n",
       "   num_types                             type  \\\n",
       "0          4  Dredging/MilOps/Reserved/Towing   \n",
       "1          4  Dredging/MilOps/Reserved/Towing   \n",
       "2          4  Dredging/MilOps/Reserved/Towing   \n",
       "3          4  Dredging/MilOps/Reserved/Towing   \n",
       "4          4  Dredging/MilOps/Reserved/Towing   \n",
       "\n",
       "                ...                              name transit  segment  \\\n",
       "0               ...                       Us Govt Ves       1        1   \n",
       "1               ...                 Dredge Capt Frank       1        1   \n",
       "2               ...                     Us Gov Vessel       1        1   \n",
       "3               ...                     Us Gov Vessel       2        1   \n",
       "4               ...                 Dredge Capt Frank       2        1   \n",
       "\n",
       "   seg_length  avg_sog  min_sog  max_sog  pdgt10        st_time       end_time  \n",
       "0         5.1     13.2      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27  \n",
       "1        13.5     18.6     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20  \n",
       "2         4.3     16.2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55  \n",
       "3         9.2     15.4     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34  \n",
       "4         9.2     15.4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.merge(segments, left_index=True, right_on='mmsi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Occasionally, there will be fields with the same in both tables that we do not wish to use to join the tables; they may contain different information, despite having the same name. In this case, Pandas will by default append suffixes `_x` and `_y` to the columns to uniquely identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   num_names                                              names sov     flag  \\\n",
       "0          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "1          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "2          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "3          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "4          8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y  Unknown   \n",
       "\n",
       "  flag_type  num_loas                                    loa  max_loa  \\\n",
       "0   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "1   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "2   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "3   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "4   Unknown         7  42.0/48.0/57.0/90.0/138.0/154.0/156.0      156   \n",
       "\n",
       "   num_types                           type_x  \\\n",
       "0          4  Dredging/MilOps/Reserved/Towing   \n",
       "1          4  Dredging/MilOps/Reserved/Towing   \n",
       "2          4  Dredging/MilOps/Reserved/Towing   \n",
       "3          4  Dredging/MilOps/Reserved/Towing   \n",
       "4          4  Dredging/MilOps/Reserved/Towing   \n",
       "\n",
       "                ...                 transit segment  seg_length  avg_sog  \\\n",
       "0               ...                       1       1         5.1     13.2   \n",
       "1               ...                       1       1        13.5     18.6   \n",
       "2               ...                       1       1         4.3     16.2   \n",
       "3               ...                       2       1         9.2     15.4   \n",
       "4               ...                       2       1         9.2     15.4   \n",
       "\n",
       "   min_sog  max_sog  pdgt10        st_time       end_time type_y  \n",
       "0      9.2     14.5    96.5  2/10/09 16:03  2/10/09 16:27    foo  \n",
       "1     10.4     20.6   100.0   4/6/09 14:31   4/6/09 15:20    foo  \n",
       "2     10.3     20.5   100.0   4/6/09 14:36   4/6/09 14:55    foo  \n",
       "3     14.5     16.1   100.0  4/10/09 17:58  4/10/09 18:34    foo  \n",
       "4     14.6     16.2   100.0  4/10/09 17:59  4/10/09 18:35    foo  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments['type'] = 'foo'\n",
    "pd.merge(vessels, segments, left_index=True, right_on='mmsi').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior can be overridden by specifying a `suffixes` argument, containing a list of the suffixes to be used for the columns of the left and right columns, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation\n",
    "\n",
    "A common data manipulation is appending rows or columns to a dataset that already conform to the dimensions of the exsiting rows or colums, respectively. In NumPy, this is done either with `concatenate` or the convenience functions `c_` and `r_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.95922038,  0.39563796,  0.13163705,  0.94429727,  0.01549658,\n",
       "        0.12911028,  0.75731272,  0.01583536,  0.56940704,  0.34045001])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.random.random(5), np.random.random(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.80586099,  0.34971419,  0.39173205,  0.61992008,  0.64169057,\n",
       "        0.31249921,  0.97907553,  0.18102001,  0.67703841,  0.25629399])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[np.random.random(5), np.random.random(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40759603,  0.66875812],\n",
       "       [ 0.75010699,  0.64254533],\n",
       "       [ 0.19492038,  0.04028105],\n",
       "       [ 0.139481  ,  0.96799951],\n",
       "       [ 0.81245418,  0.83274143]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[np.random.random(5), np.random.random(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation is also called *binding* or *stacking*.\n",
    "\n",
    "With Pandas' indexed data structures, there are additional considerations as the overlap in index values between two data structures affects how they are concatenate.\n",
    "\n",
    "Lets import two microbiome datasets, each consisting of counts of microorganiams from a particular patient. We will use the first column of each dataset as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((272, 1), (288, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1 = pd.read_excel('data/microbiome/MID1.xls', 'Sheet 1', index_col=0, header=None)\n",
    "mb2 = pd.read_excel('data/microbiome/MID2.xls', 'Sheet 1', index_col=0, header=None)\n",
    "mb1.shape, mb2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                         1\n",
       "0                                                                                         \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera    7\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus          2\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus              3\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum          3\n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella  7"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give the index and columns meaningful labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.columns = mb2.columns = ['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb1.index.name = mb2.index.name = 'Taxon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                         Count\n",
       "Taxon                                                                                         \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera        7\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus              2\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus                  3\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum              3\n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella      7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index of these data is the unique biological classification of each organism, beginning with *domain*, *phylum*, *class*, and for some organisms, going all the way down to the genus level.\n",
    "\n",
    "![classification](http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/Biological_classification_L_Pengo_vflip.svg/150px-Biological_classification_L_Pengo_vflip.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera', u'Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus', u'Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.index[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we concatenate along `axis=0` (the default), we will obtain another data frame with the the rows concatenated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the index is no longer unique, due to overlap between the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=0).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating along `axis=1` will concatenate column-wise, but respecting the indices of the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                            Count  \\\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Acidilobaceae Acidilobus                    NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Caldisphaeraceae Caldisphaera               NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera           7   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Sulfophobococcus    NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Thermosphaera       NaN   \n",
       "\n",
       "                                                                                            Count  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Acidilobaceae Acidilobus                      2  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Caldisphaeraceae Caldisphaera                14  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera          23  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Sulfophobococcus      1  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Thermosphaera         2  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,   2.],\n",
       "       [ nan,  14.],\n",
       "       [  7.,  23.],\n",
       "       [ nan,   1.],\n",
       "       [ nan,   2.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=1).values[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are only interested in taxa that are included in both DataFrames, we can specify a `join=inner` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                         Count  \\\n",
       "Taxon                                                                                            \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera        7   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus              2   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus                  3   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum              3   \n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella      7   \n",
       "\n",
       "                                                                                         Count  \n",
       "Taxon                                                                                           \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera       23  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus              2  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus                 10  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum              9  \n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella      9  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], axis=1, join='inner').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to use the second table to fill values absent from the first table, we could use `combine_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                            Count\n",
       "Taxon                                                                                            \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Acidilobaceae Acidilobus                      2\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Caldisphaeraceae Caldisphaera                14\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera           7\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Sulfophobococcus      1\n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Thermosphaera         2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.combine_first(mb2).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create a hierarchical index based on keys identifying the original tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                                  Count\n",
       "         Taxon                                                                                         \n",
       "patient1 Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera        7\n",
       "         Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus              2\n",
       "         Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus                  3\n",
       "         Archaea \"Crenarchaeota\" Thermoprotei Thermoproteales Thermofilaceae Thermofilum              3\n",
       "         Archaea \"Euryarchaeota\" \"Methanomicrobia\" Methanocellales Methanocellaceae Methanocella      7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], keys=['patient1', 'patient2']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([mb1, mb2], keys=['patient1', 'patient2']).index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can pass keys to the concatenation by supplying the DataFrames (or Series) as a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                                                            patient1  \\\n",
       "                                                                                               Count   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Acidilobaceae Acidilobus                       NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Caldisphaeraceae Caldisphaera                  NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera              7   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Sulfophobococcus       NaN   \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Thermosphaera          NaN   \n",
       "\n",
       "                                                                                            patient2  \n",
       "                                                                                               Count  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Acidilobaceae Acidilobus                         2  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Acidilobales Caldisphaeraceae Caldisphaera                   14  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera             23  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Sulfophobococcus         1  \n",
       "Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Thermosphaera            2  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(dict(patient1=mb1, patient2=mb2), axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want `concat` to work like `numpy.concatanate`, you may provide the `ignore_index=True` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "In the *data/microbiome* subdirectory, there are 9 spreadsheets of microbiome data that was acquired from high-throughput RNA sequencing procedures, along with a 10th file that describes the content of each. Write code that imports each of the data spreadsheets and combines them into a single `DataFrame`, adding the identifying information from the metadata spreadsheet as columns in the combined `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping DataFrame objects\n",
    "\n",
    "In the context of a single DataFrame, we are often interested in re-arranging the layout of our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset in from Table 6.9 of [Statistical Methods for the Analysis of Repeated Measurements](http://www.amazon.com/Statistical-Methods-Analysis-Repeated-Measurements/dp/0387953701) by Charles S. Davis, pp. 161-163 (Springer, 2002). These data are from a multicenter, randomized controlled trial of botulinum toxin type B (BotB) in patients with cervical dystonia from nine U.S. sites.\n",
    "\n",
    "* Randomized to placebo (N=36), 5000 units of BotB (N=36), 10,000 units of BotB (N=37)\n",
    "* Response variable: total score on Toronto Western Spasmodic Torticollis Rating Scale (TWSTRS), measuring severity, pain, and disability of cervical dystonia (high scores mean more impairment)\n",
    "* TWSTRS measured at baseline (week 0) and weeks 2, 4, 8, 12, 16 after treatment began"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   patient  obs  week  site  id  treat  age sex  twstrs\n",
       "0        1    1     0     1   1  5000U   65   F      32\n",
       "1        1    2     2     1   1  5000U   65   F      30\n",
       "2        1    3     4     1   1  5000U   65   F      24\n",
       "3        1    4     8     1   1  5000U   65   F      37\n",
       "4        1    5    12     1   1  5000U   65   F      39"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia = pd.read_csv(\"data/cdystonia.csv\", index_col=None)\n",
    "cdystonia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset includes repeated measurements of the same individuals (longitudinal data). Its possible to present such information in (at least) two ways: showing each repeated measurement in their own row, or in multiple columns representing mutliple measurements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack` method rotates the data frame so that columns are represented in rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0  patient        1\n",
       "   obs            1\n",
       "   week           0\n",
       "   site           1\n",
       "   id             1\n",
       "   treat      5000U\n",
       "   age           65\n",
       "   sex            F\n",
       "   twstrs        32\n",
       "1  patient        1\n",
       "...\n",
       "629  sex            M\n",
       "     twstrs        36\n",
       "630  patient      109\n",
       "     obs            6\n",
       "     week          16\n",
       "     site           9\n",
       "     id            11\n",
       "     treat      5000U\n",
       "     age           57\n",
       "     sex            M\n",
       "     twstrs        51\n",
       "Length: 5679, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = cdystonia.stack()\n",
    "stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement this, `unstack` pivots from rows back to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  patient obs week site id  treat age sex twstrs\n",
       "0       1   1    0    1  1  5000U  65   F     32\n",
       "1       1   2    2    1  1  5000U  65   F     30\n",
       "2       1   3    4    1  1  5000U  65   F     24\n",
       "3       1   4    8    1  1  5000U  65   F     37\n",
       "4       1   5   12    1  1  5000U  65   F     39"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.unstack().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, it makes sense to create a hierarchical index based on the patient and observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             week  site  id  treat  age sex  twstrs\n",
       "patient obs                                        \n",
       "1       1       0     1   1  5000U   65   F      32\n",
       "        2       2     1   1  5000U   65   F      30\n",
       "        3       4     1   1  5000U   65   F      24\n",
       "        4       8     1   1  5000U   65   F      37\n",
       "        5      12     1   1  5000U   65   F      39"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia2 = cdystonia.set_index(['patient','obs'])\n",
    "cdystonia2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia2.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to transform this data so that repeated measurements are in columns, we can `unstack` the `twstrs` measurements according to `obs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obs       1   2   3   4   5   6\n",
       "patient                        \n",
       "1        32  30  24  37  39  36\n",
       "2        60  26  27  41  65  67\n",
       "3        44  20  23  26  35  35\n",
       "4        53  61  64  62 NaN NaN\n",
       "5        53  35  48  49  41  51"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twstrs_wide = cdystonia2['twstrs'].unstack('obs')\n",
    "twstrs_wide.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    patient  site  id    treat  age sex   1   2   3   4   5   6\n",
       "0         1     1   1    5000U   65   F  32  30  24  37  39  36\n",
       "6         2     1   2   10000U   70   F  60  26  27  41  65  67\n",
       "12        3     1   3    5000U   64   F  44  20  23  26  35  35\n",
       "18        4     1   4  Placebo   59   F  53  61  64  62 NaN NaN\n",
       "22        5     1   5   10000U   76   F  53  35  48  49  41  51"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_long = cdystonia[['patient','site','id','treat','age','sex']].drop_duplicates().merge(\n",
    "                    twstrs_wide, right_index=True, left_on='patient', how='inner').head()\n",
    "cdystonia_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slightly cleaner way of doing this is to set the patient-level information as an index before unstacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "week                             0   2   4   8   12  16\n",
       "patient site id treat   age sex                        \n",
       "1       1    1  5000U   65  F    32  30  24  37  39  36\n",
       "2       1    2  10000U  70  F    60  26  27  41  65  67\n",
       "3       1    3  5000U   64  F    44  20  23  26  35  35\n",
       "4       1    4  Placebo 59  F    53  61  64  62 NaN NaN\n",
       "5       1    5  10000U  76  F    53  35  48  49  41  51"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.set_index(['patient','site','id','treat','age','sex','week'])['twstrs'].unstack('week').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our \"wide\" format back to long, we can use the `melt` function, appropriately parameterized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   patient  site  id    treat  age sex obs  twsters\n",
       "0        1     1   1    5000U   65   F   1       32\n",
       "1        2     1   2   10000U   70   F   1       60\n",
       "2        3     1   3    5000U   64   F   1       44\n",
       "3        4     1   4  Placebo   59   F   1       53\n",
       "4        5     1   5   10000U   76   F   1       53"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.melt(cdystonia_long, id_vars=['patient','site','id','treat','age','sex'], \n",
    "        var_name='obs', value_name='twsters').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This illustrates the two formats for longitudinal data: **long** and **wide** formats. Its typically better to store data in long format because additional data can be included as additional rows in the database, while wide format requires that the entire database schema be altered by adding columns to every row as data are collected.\n",
    "\n",
    "The preferable format for analysis depends entirely on what is planned for the data, so it is imporant to be able to move easily between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "The `pivot` method allows a DataFrame to be transformed easily between long and wide formats in the same way as a pivot table is created in a spreadsheet. It takes three arguments: `index`, `columns` and `values`, corresponding to the DataFrame index (the row headers), columns and cell values, respectively.\n",
    "\n",
    "For example, we may want the `twstrs` variable (the response variable) in wide format according to patient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obs       1   2   3   4   5   6\n",
       "patient                        \n",
       "1        32  30  24  37  39  36\n",
       "2        60  26  27  41  65  67\n",
       "3        44  20  23  26  35  35\n",
       "4        53  61  64  62 NaN NaN\n",
       "5        53  35  48  49  41  51"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.pivot(index='patient', columns='obs', values='twstrs').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we omit the `values` argument, we get a `DataFrame` with hierarchical columns, just as when we applied `unstack` to the hierarchically-indexed table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         week                      site             ...  sex                 \\\n",
       "obs         1   2   3   4   5   6     1   2   3   4 ...    3    4    5    6   \n",
       "patient                                             ...                       \n",
       "1           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "2           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "3           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "4           0   2   4   8 NaN NaN     1   1   1   1 ...    F    F  NaN  NaN   \n",
       "5           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "6           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "7           0   2   4   8  12  16     1   1   1   1 ...    M    M    M    M   \n",
       "8           0   2   4   8  12  16     1   1   1   1 ...    M    M    M    M   \n",
       "9           0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "10          0   2   4   8  12  16     1   1   1   1 ...    M    M    M    M   \n",
       "11          0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "12          0   2   4   8  12  16     1   1   1   1 ...    F    F    F    F   \n",
       "...       ...  ..  ..  ..  ..  ..   ...  ..  ..  .. ...  ...  ...  ...  ...   \n",
       "98          0   2   4   8  12  16     8   8   8   8 ...    F    F    F    F   \n",
       "99          0   2   4   8  12  16     9   9   9   9 ...    M    M    M    M   \n",
       "100         0   2   4   8  12  16     9   9   9   9 ...    M    M    M    M   \n",
       "101         0   2   4   8  12  16     9   9   9   9 ...    M    M    M    M   \n",
       "102         0   2   4   8  12  16     9   9   9   9 ...    F    F    F    F   \n",
       "103         0   2   4 NaN  12  16     9   9   9 NaN ...    F  NaN    F    F   \n",
       "104         0   2   4 NaN  12  16     9   9   9 NaN ...    F  NaN    F    F   \n",
       "105         0   2   4   8  12  16     9   9   9   9 ...    F    F    F    F   \n",
       "106         0   2   4   8  12  16     9   9   9   9 ...    M    M    M    M   \n",
       "107         0 NaN   4   8 NaN  16     9 NaN   9   9 ...    M    M  NaN    M   \n",
       "108         0   2   4   8  12  16     9   9   9   9 ...    F    F    F    F   \n",
       "109         0   2 NaN   8  12  16     9   9 NaN   9 ...  NaN    M    M    M   \n",
       "\n",
       "         twstrs             twstrs      \n",
       "obs           1   2   3   4      5   6  \n",
       "patient                                 \n",
       "1            32  30  24  37     39  36  \n",
       "2            60  26  27  41     65  67  \n",
       "3            44  20  23  26     35  35  \n",
       "4            53  61  64  62    NaN NaN  \n",
       "5            53  35  48  49     41  51  \n",
       "6            49  34  43  48     48  51  \n",
       "7            42  32  32  43     42  46  \n",
       "8            34  33  21  27     32  38  \n",
       "9            41  32  34  35     37  36  \n",
       "10           27  10  31  32      6  14  \n",
       "11           48  41  32  35     57  51  \n",
       "12           34  19  21  24     28  28  \n",
       "...         ...  ..  ..  ..    ...  ..  \n",
       "98           40  28  29  30     37  44  \n",
       "99           40  16  18  25     33  48  \n",
       "100          61  52  61  68     59  71  \n",
       "101          35  21  29  30     35  48  \n",
       "102          58  38  50  53     47  59  \n",
       "103          49  45  36 NaN     40  52  \n",
       "104          52  46  36 NaN     45  54  \n",
       "105          45  46  33  44     46  48  \n",
       "106          67  63  71  66     68  71  \n",
       "107          57 NaN  36  23    NaN  52  \n",
       "108          63  51  46  50     50  54  \n",
       "109          53  38 NaN  33     36  51  \n",
       "\n",
       "[109 rows x 42 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.pivot('patient', 'obs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related method, `pivot_table`, creates a spreadsheet-like table with a hierarchical index, and allows the values of the table to be populated using an arbitrary aggregation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/util/decorators.py:53: FutureWarning: cols is deprecated, use columns instead\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/lib/python2.7/site-packages/pandas/util/decorators.py:53: FutureWarning: rows is deprecated, use index instead\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "week          0   2   4   8   12  16\n",
       "site treat                          \n",
       "1    10000U   60  41  48  49  65  67\n",
       "     5000U    44  32  34  43  42  46\n",
       "     Placebo  53  61  64  62  32  38\n",
       "2    10000U   65  60  60  64  67  66\n",
       "     5000U    67  64  65  64  62  64\n",
       "     Placebo  53  56  52  57  61  54\n",
       "3    10000U   50  43  51  46  49  56\n",
       "     5000U    52  44  47  50  50  49\n",
       "     Placebo  43  38  40  48  49  44\n",
       "4    10000U   54  52  52  54  51  57\n",
       "     5000U    52  34  43  45  47  46\n",
       "     Placebo  52  55  51  52  54  57\n",
       "5    10000U   50  50  32  46  54  57\n",
       "     5000U    60  53  55  62  67  26\n",
       "     Placebo  60  57  53  52  53  58\n",
       "6    10000U   55  56  47  53  51  51\n",
       "     5000U    59  55  50  56  59  53\n",
       "     Placebo  54  53  51  57  57  57\n",
       "7    10000U   53  47  45  45  50  53\n",
       "     5000U    53  45  52  51  52  53"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.pivot_table(rows=['site', 'treat'], cols='week', values='twstrs', aggfunc=max).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple cross-tabulation of group frequencies, the `crosstab` function (not a method) aggregates counts of data according to factors in rows and columns. The factors may be hierarchical if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "site   1   2   3   4   5   6   7   8   9\n",
       "sex                                     \n",
       "F     52  53  42  30  22  54  66  48  28\n",
       "M     18  29  30  18  11  33   6  58  33"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cdystonia.sex, cdystonia.site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation\n",
    "\n",
    "There are a slew of additional operations for DataFrames that we would collectively refer to as \"transformations\" that include tasks such as removing duplicate values, replacing values, and grouping values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicates\n",
    "\n",
    "We can easily identify and remove duplicate values from `DataFrame` objects. For example, say we want to removed ships from our `vessels` dataset that have the same name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/pandas/util/decorators.py:53: FutureWarning: cols is deprecated, use subset instead\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mmsi\n",
       "1        False\n",
       "9        False\n",
       "21       False\n",
       "74       False\n",
       "103      False\n",
       "310      False\n",
       "3011     False\n",
       "4731     False\n",
       "15151    False\n",
       "46809    False\n",
       "...\n",
       "812719000    False\n",
       "857632392    False\n",
       "866946820     True\n",
       "888888882     True\n",
       "888888888    False\n",
       "900000000    False\n",
       "919191919    False\n",
       "967191190     True\n",
       "975318642     True\n",
       "987654321    False\n",
       "999999999     True\n",
       "Length: 10771, dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.duplicated(cols='names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           num_names                                              names sov  \\\n",
       "mmsi                                                                          \n",
       "1                  8  Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   Y   \n",
       "9                  3                         000000009/Raven/Shearwater   N   \n",
       "21                 1                                      Us Gov Vessel   Y   \n",
       "74                 2                                  Mcfaul/Sarah Bell   N   \n",
       "103                3           Ron G/Us Navy Warship 103/Us Warship 103   Y   \n",
       "310                1                                           Arabella   N   \n",
       "3011               1                                         Charleston   N   \n",
       "4731               1                                          000004731   N   \n",
       "15151              2                             R L Enterkin/Us Vessel   N   \n",
       "46809              1                                      Island Trader   N   \n",
       "80404              1                                         Donnamarie   N   \n",
       "82003              1                                             Alexis   N   \n",
       "...              ...                                                ...  ..   \n",
       "730026000          1                                        Pensilvania   N   \n",
       "730031000          1                                            Macondo   N   \n",
       "735057548          1                                         Chimborazo   N   \n",
       "735059037          1                                         B.e Guayas   N   \n",
       "760101000          1                                          Yacu Puma   N   \n",
       "770576100          1                                    Capitan Miranda   N   \n",
       "812719000          1                                   Ocean     Trader   N   \n",
       "857632392          1                                           Ct Pilot   N   \n",
       "888888888          1                                         Earl Jones   N   \n",
       "900000000          3      Capt.webster      Pc/Elk River/Roger Binsfeld   N   \n",
       "919191919          1                                                 Oi   N   \n",
       "987654321          2                         Island Lookout/Island Tide   N   \n",
       "\n",
       "                                     flag flag_type  num_loas  \\\n",
       "mmsi                                                            \n",
       "1                                 Unknown   Unknown         7   \n",
       "9                                 Unknown   Unknown         2   \n",
       "21                                Unknown   Unknown         1   \n",
       "74                                Unknown   Unknown         1   \n",
       "103                               Unknown   Unknown         2   \n",
       "310                              Bermuda    Foreign         1   \n",
       "3011                            Anguilla    Foreign         1   \n",
       "4731                 Yemen (Republic of)    Foreign         1   \n",
       "15151                             Unknown   Unknown         2   \n",
       "46809               Syrian Arab Republic    Foreign         1   \n",
       "80404                             Unknown   Unknown         1   \n",
       "82003                             Unknown   Unknown         1   \n",
       "...                                   ...       ...       ...   \n",
       "730026000         Colombia (Republic of)    Foreign         1   \n",
       "730031000         Colombia (Republic of)    Foreign         1   \n",
       "735057548                        Ecuador    Foreign         1   \n",
       "735059037                        Ecuador    Foreign         2   \n",
       "760101000                           Peru    Foreign         2   \n",
       "770576100  Uruguay (Eastern Republic of)    Foreign         1   \n",
       "812719000                         Unknown   Unknown         1   \n",
       "857632392                         Unknown   Unknown         1   \n",
       "888888888                         Unknown   Unknown         1   \n",
       "900000000                         Unknown   Unknown         3   \n",
       "919191919                         Unknown   Unknown         1   \n",
       "987654321                         Unknown   Unknown         2   \n",
       "\n",
       "                                             loa  max_loa  num_types  \\\n",
       "mmsi                                                                   \n",
       "1          42.0/48.0/57.0/90.0/138.0/154.0/156.0      156          4   \n",
       "9                                      50.0/62.0       62          2   \n",
       "21                                         208.0      208          1   \n",
       "74                                         155.0      155          1   \n",
       "103                                   26.0/155.0      155          2   \n",
       "310                                         47.0       47          1   \n",
       "3011                                       160.0      160          1   \n",
       "4731                                        30.0       30          1   \n",
       "15151                                 60.0/175.0      175          1   \n",
       "46809                                       22.0       22          1   \n",
       "80404                                       29.0       29          1   \n",
       "82003                                       29.0       29          2   \n",
       "...                                          ...      ...        ...   \n",
       "730026000                                  119.0      119          1   \n",
       "730031000                                  120.0      120          1   \n",
       "735057548                                  228.0      228          1   \n",
       "735059037                              44.0/78.0       78          1   \n",
       "760101000                            142.0/148.0      148          1   \n",
       "770576100                                   60.0       60          1   \n",
       "812719000                                   52.0       52          1   \n",
       "857632392                                   20.0       20          1   \n",
       "888888888                                   40.0       40          1   \n",
       "900000000                        22.0/38.0/351.0      351          3   \n",
       "919191919                                   20.0       20          1   \n",
       "987654321                              22.0/23.0       23          2   \n",
       "\n",
       "                                      type  \n",
       "mmsi                                        \n",
       "1          Dredging/MilOps/Reserved/Towing  \n",
       "9                             Pleasure/Tug  \n",
       "21                                 Unknown  \n",
       "74                                 Unknown  \n",
       "103                         Tanker/Unknown  \n",
       "310                                Unknown  \n",
       "3011                                 Other  \n",
       "4731                               Unknown  \n",
       "15151                                  Tug  \n",
       "46809                               Towing  \n",
       "80404                             Pleasure  \n",
       "82003                     Fishing/Pleasure  \n",
       "...                                    ...  \n",
       "730026000                            Cargo  \n",
       "730031000                            Cargo  \n",
       "735057548                           Tanker  \n",
       "735059037                          Sailing  \n",
       "760101000                            Cargo  \n",
       "770576100                          Sailing  \n",
       "812719000                           Tanker  \n",
       "857632392                           Diving  \n",
       "888888888                           Towing  \n",
       "900000000          Fishing/Reserved/Towing  \n",
       "919191919                         Pleasure  \n",
       "987654321                   Fishing/Towing  \n",
       "\n",
       "[10253 rows x 10 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels.drop_duplicates(['names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value replacement\n",
    "\n",
    "Frequently, we get data columns that are encoded as strings that we wish to represent numerically for the purposes of including it in a quantitative analysis. For example, consider the treatment variable in the cervical dystonia dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000U     213\n",
       "5000U      211\n",
       "Placebo    207\n",
       "dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.treat.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logical way to specify these numerically is to change them to integer values, perhaps using \"Placebo\" as a baseline value. If we create a dict with the original values as keys and the replacements as values, we can pass it to the `map` method to implement the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "treatment_map = {'Placebo': 0, '5000U': 1, '10000U': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    2\n",
       "7    2\n",
       "8    2\n",
       "9    2\n",
       "...\n",
       "620    2\n",
       "621    2\n",
       "622    2\n",
       "623    2\n",
       "624    2\n",
       "625    2\n",
       "626    1\n",
       "627    1\n",
       "628    1\n",
       "629    1\n",
       "630    1\n",
       "Name: treatment, Length: 631, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia['treatment'] = cdystonia.treat.map(treatment_map)\n",
    "cdystonia.treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, if we simply want to replace particular values in a `Series` or `DataFrame`, we can use the `replace` method. \n",
    "\n",
    "An example where replacement is useful is dealing with zeros in certain transformations. For example, if we try to take the log of a set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             0\n",
       "1             1\n",
       "2          1024\n",
       "3         59049\n",
       "4       1048576\n",
       "5       9765625\n",
       "6      60466176\n",
       "7     282475249\n",
       "8    1073741824\n",
       "9    3486784401\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = pd.Series([float(i)**10 for i in range(10)])\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -inf\n",
       "1     0.000000\n",
       "2     6.931472\n",
       "3    10.986123\n",
       "4    13.862944\n",
       "5    16.094379\n",
       "6    17.917595\n",
       "7    19.459101\n",
       "8    20.794415\n",
       "9    21.972246\n",
       "dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In such situations, we can replace the zero with a value so small that it makes no difference to the ensuing analysis. We can do this with `replace`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -13.815511\n",
       "1     0.000000\n",
       "2     6.931472\n",
       "3    10.986123\n",
       "4    13.862944\n",
       "5    16.094379\n",
       "6    17.917595\n",
       "7    19.459101\n",
       "8    20.794415\n",
       "9    21.972246\n",
       "dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals = vals.replace(0, 1e-6)\n",
    "np.log(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform the same replacement that we used `map` for with `replace`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient  obs\n",
       "1        1      1\n",
       "         2      1\n",
       "         3      1\n",
       "         4      1\n",
       "         5      1\n",
       "         6      1\n",
       "2        1      2\n",
       "         2      2\n",
       "         3      2\n",
       "         4      2\n",
       "...\n",
       "108      1      2\n",
       "         2      2\n",
       "         3      2\n",
       "         4      2\n",
       "         5      2\n",
       "         6      2\n",
       "109      1      1\n",
       "         2      1\n",
       "         4      1\n",
       "         5      1\n",
       "         6      1\n",
       "Name: treat, Length: 631, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia2.treat.replace({'Placebo': 0, '5000U': 1, '10000U': 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inidcator variables\n",
    "\n",
    "For some statistical analyses (*e.g.* regression models or analyses of variance), categorical or group variables need to be converted into columns of indicators--zeros and ones--to create a so-called **design matrix**. The Pandas function `get_dummies` (indicator variables are also known as *dummy variables*) makes this transformation straightforward.\n",
    "\n",
    "Let's consider the DataFrame containing the ships corresponding to the transit segments on the eastern seaboard. The `type` variable denotes the class of vessel; we can create a matrix of indicators for this. For simplicity, lets filter out the 5 most common types of ships:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5 = vessels.type.apply(lambda s: s in vessels.type.value_counts().index[:5])\n",
    "vessels5 = vessels[top5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Cargo  Pleasure  Sailing  Tanker  Tug\n",
       "mmsi                                          \n",
       "15151        0         0        0       0    1\n",
       "80404        0         1        0       0    0\n",
       "366235       1         0        0       0    0\n",
       "587370       0         0        0       0    1\n",
       "693559       0         0        0       0    1\n",
       "1233916      0         1        0       0    0\n",
       "3041300      1         0        0       0    0\n",
       "3663760      1         0        0       0    0\n",
       "3688360      1         0        0       0    0\n",
       "7718175      1         0        0       0    0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(vessels5.type).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretization\n",
    "\n",
    "Pandas' `cut` function can be used to group continuous or countable data in to bins. Discretization is generally a very **bad idea** for statistical analysis, so use this function responsibly!\n",
    "\n",
    "Lets say we want to bin the ages of the cervical dystonia patients into a smaller number of groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    631.000000\n",
       "mean      55.616482\n",
       "std       12.123910\n",
       "min       26.000000\n",
       "25%       46.000000\n",
       "50%       56.000000\n",
       "75%       65.000000\n",
       "max       83.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.age.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's transform these data into decades, beginnnig with individuals in their 20's and ending with those in their 90's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       " (60, 70]\n",
       "...\n",
       " (50, 60]\n",
       " (50, 60]\n",
       " (50, 60]\n",
       " (70, 80]\n",
       " (70, 80]\n",
       " (70, 80]\n",
       " (70, 80]\n",
       " (70, 80]\n",
       " (70, 80]\n",
       " (50, 60]\n",
       " (50, 60]\n",
       "Levels (7): Index(['(20, 30]', '(30, 40]', '(40, 50]', '(50, 60]',\n",
       "                   '(60, 70]', '(70, 80]', '(80, 90]'], dtype=object)\n",
       "Length: 30"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(cdystonia.age, [20,30,40,50,60,70,80,90])[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parentheses indicate an open interval, meaning that the interval includes values up to but *not including* the endpoint, whereas the square bracket is a closed interval, where the endpoint is included in the interval. We can switch the closure to the left side by setting the `right` flag to `False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " [60, 70)\n",
       " [60, 70)\n",
       " [60, 70)\n",
       " [60, 70)\n",
       " [60, 70)\n",
       " [60, 70)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       "...\n",
       " [50, 60)\n",
       " [50, 60)\n",
       " [50, 60)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [70, 80)\n",
       " [50, 60)\n",
       " [50, 60)\n",
       "Levels (7): Index(['[20, 30)', '[30, 40)', '[40, 50)', '[50, 60)',\n",
       "                   '[60, 70)', '[70, 80)', '[80, 90)'], dtype=object)\n",
       "Length: 30"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(cdystonia.age, [20,30,40,50,60,70,80,90], right=False)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data are now **ordinal**, rather than numeric, we can give them labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       " old\n",
       "...\n",
       " middle-aged\n",
       " middle-aged\n",
       " middle-aged\n",
       "         old\n",
       "         old\n",
       "         old\n",
       "         old\n",
       "         old\n",
       "         old\n",
       " middle-aged\n",
       " middle-aged\n",
       "Levels (4): Index(['young', 'middle-aged', 'old', 'ancient'], dtype=object)\n",
       "Length: 30"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(cdystonia.age, [20,40,60,80,90], labels=['young','middle-aged','old','ancient'])[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A related function `qcut` uses empirical quantiles to divide the data. If, for example, we want the quartiles -- (0-25%], (25-50%], (50-70%], (75-100%] -- we can just specify 4 intervals, which will be equally-spaced by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " (56, 65]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       "...\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (65, 83]\n",
       " (56, 65]\n",
       " (56, 65]\n",
       "Levels (4): Index(['[26, 46]', '(46, 56]', '(56, 65]', '(65, 83]'], dtype=object)\n",
       "Length: 30"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(cdystonia.age, 4)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, one can specify custom quantiles to act as cut points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   (1.8, 7.8]\n",
       "  (7.8, 45.4]\n",
       "   (1.8, 7.8]\n",
       "  (7.8, 45.4]\n",
       "  (7.8, 45.4]\n",
       "  (7.8, 45.4]\n",
       " (45.4, 89.7]\n",
       "  (7.8, 45.4]\n",
       "  (7.8, 45.4]\n",
       "  (7.8, 45.4]\n",
       "...\n",
       " (7.8, 45.4]\n",
       "  (1.8, 7.8]\n",
       "  (1.8, 7.8]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       " (7.8, 45.4]\n",
       "Levels (5): Index(['[1, 1.8]', '(1.8, 7.8]', '(7.8, 45.4]',\n",
       "                   '(45.4, 89.7]', '(89.7, 1882]'], dtype=object)\n",
       "Length: 30"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles = pd.qcut(segments.seg_length, [0, 0.01, 0.05, 0.95, 0.99, 1])\n",
    "quantiles[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can easily combine discretiztion with the generation of indicator variables shown above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   (1.8, 7.8]  (45.4, 89.7]  (7.8, 45.4]  (89.7, 1882]  [1, 1.8]\n",
       "0           1             0            0             0         0\n",
       "1           0             0            1             0         0\n",
       "2           1             0            0             0         0\n",
       "3           0             0            1             0         0\n",
       "4           0             0            1             0         0\n",
       "5           0             0            1             0         0\n",
       "6           0             1            0             0         0\n",
       "7           0             0            1             0         0\n",
       "8           0             0            1             0         0\n",
       "9           0             0            1             0         0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(quantiles).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation and sampling\n",
    "\n",
    "For some data analysis tasks, such as simulation, we need to be able to randomly reorder our data, or draw random values from it. Calling NumPy's `permutation` function with the length of the sequence you want to permute generates an array with a permuted sequence of integers, which can be used to re-order the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([183316, 108225,  92326,  60611, 134460, 170622, 117439,  13979,\n",
       "       243115,  69470,  13594, 160103,  73039, 158974, 220079,  20341,\n",
       "        87882,   4430, 139083,  23082,  18110, 169543, 169578, 119516,\n",
       "       227857, 123216, 252938,  52744,  88292, 208914])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_order = np.random.permutation(len(segments))\n",
    "new_order[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sequence as an argument to the `take` method results in a reordered DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             mmsi           name  transit  segment  seg_length  avg_sog  \\\n",
       "183316  367839000    Us Epa Bold       14        1        17.9      6.0   \n",
       "108225  366739960       Mckinley      135        1        26.9      8.1   \n",
       "92326   354591000   Pyxis Leader       30        1        30.3     14.9   \n",
       "60611   309942000     Dole Chile      178        1        18.5     19.0   \n",
       "134460  366997360  Norwegian Sea      201        1        25.9      6.9   \n",
       "\n",
       "        min_sog  max_sog  pdgt10         st_time       end_time type  \n",
       "183316      5.3      7.1     0.0    7/19/09 7:00   7/19/09 9:23  foo  \n",
       "108225      7.7      8.7     0.0  10/13/10 22:06  10/14/10 1:23  foo  \n",
       "92326       7.2     17.2    94.4    8/3/10 22:58    8/4/10 0:59  foo  \n",
       "60611      15.5     19.8   100.0     5/8/12 4:27    5/8/12 5:26  foo  \n",
       "134460      6.5      7.1     0.0    4/3/12 10:40   4/3/12 14:26  foo  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.take(new_order).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this ordering with the original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   mmsi               name  transit  segment  seg_length  avg_sog  min_sog  \\\n",
       "0     1        Us Govt Ves        1        1         5.1     13.2      9.2   \n",
       "1     1  Dredge Capt Frank        1        1        13.5     18.6     10.4   \n",
       "2     1      Us Gov Vessel        1        1         4.3     16.2     10.3   \n",
       "3     1      Us Gov Vessel        2        1         9.2     15.4     14.5   \n",
       "4     1  Dredge Capt Frank        2        1         9.2     15.4     14.6   \n",
       "\n",
       "   max_sog  pdgt10        st_time       end_time type  \n",
       "0     14.5    96.5  2/10/09 16:03  2/10/09 16:27  foo  \n",
       "1     20.6   100.0   4/6/09 14:31   4/6/09 15:20  foo  \n",
       "2     20.5   100.0   4/6/09 14:36   4/6/09 14:55  foo  \n",
       "3     16.1   100.0  4/10/09 17:58  4/10/09 18:34  foo  \n",
       "4     16.2   100.0  4/10/09 17:59  4/10/09 18:35  foo  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Its easy to see how this permutation approach allows us to draw a random sample **without replacement**. How would you sample **with replacement**? Generate a random sample of 5 ships from the `vessels` DataFrame using this scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aggregation and GroupBy operations\n",
    "\n",
    "One of the most powerful features of Pandas is its **GroupBy** functionality. On occasion we may want to perform operations on *groups* of observations within a dataset. For exmaple:\n",
    "\n",
    "* **aggregation**, such as computing the sum of mean of each group, which involves applying a function to each group and returning the aggregated results\n",
    "* **slicing** the DataFrame into groups and then doing something with the resulting slices (*e.g.* plotting)\n",
    "* group-wise **transformation**, such as standardization/normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cdystonia_grouped = cdystonia.groupby(cdystonia.patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *grouped* dataset is hard to visualize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.DataFrameGroupBy object at 0x118e293d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the grouping is only an intermediate step; for example, we may want to **iterate** over each of the patient groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "0        1    1     0     1   1  5000U   65   F      32          1\n",
      "1        1    2     2     1   1  5000U   65   F      30          1\n",
      "2        1    3     4     1   1  5000U   65   F      24          1\n",
      "3        1    4     8     1   1  5000U   65   F      37          1\n",
      "4        1    5    12     1   1  5000U   65   F      39          1\n",
      "5        1    6    16     1   1  5000U   65   F      36          1\n",
      "\n",
      "2\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "6         2    1     0     1   2  10000U   70   F      60          2\n",
      "7         2    2     2     1   2  10000U   70   F      26          2\n",
      "8         2    3     4     1   2  10000U   70   F      27          2\n",
      "9         2    4     8     1   2  10000U   70   F      41          2\n",
      "10        2    5    12     1   2  10000U   70   F      65          2\n",
      "11        2    6    16     1   2  10000U   70   F      67          2\n",
      "\n",
      "3\n",
      "    patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "12        3    1     0     1   3  5000U   64   F      44          1\n",
      "13        3    2     2     1   3  5000U   64   F      20          1\n",
      "14        3    3     4     1   3  5000U   64   F      23          1\n",
      "15        3    4     8     1   3  5000U   64   F      26          1\n",
      "16        3    5    12     1   3  5000U   64   F      35          1\n",
      "17        3    6    16     1   3  5000U   64   F      35          1\n",
      "\n",
      "4\n",
      "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "18        4    1     0     1   4  Placebo   59   F      53          0\n",
      "19        4    2     2     1   4  Placebo   59   F      61          0\n",
      "20        4    3     4     1   4  Placebo   59   F      64          0\n",
      "21        4    4     8     1   4  Placebo   59   F      62          0\n",
      "\n",
      "5\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "22        5    1     0     1   5  10000U   76   F      53          2\n",
      "23        5    2     2     1   5  10000U   76   F      35          2\n",
      "24        5    3     4     1   5  10000U   76   F      48          2\n",
      "25        5    4     8     1   5  10000U   76   F      49          2\n",
      "26        5    5    12     1   5  10000U   76   F      41          2\n",
      "27        5    6    16     1   5  10000U   76   F      51          2\n",
      "\n",
      "6\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "28        6    1     0     1   6  10000U   59   F      49          2\n",
      "29        6    2     2     1   6  10000U   59   F      34          2\n",
      "30        6    3     4     1   6  10000U   59   F      43          2\n",
      "31        6    4     8     1   6  10000U   59   F      48          2\n",
      "32        6    5    12     1   6  10000U   59   F      48          2\n",
      "33        6    6    16     1   6  10000U   59   F      51          2\n",
      "\n",
      "7\n",
      "    patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "34        7    1     0     1   7  5000U   72   M      42          1\n",
      "35        7    2     2     1   7  5000U   72   M      32          1\n",
      "36        7    3     4     1   7  5000U   72   M      32          1\n",
      "37        7    4     8     1   7  5000U   72   M      43          1\n",
      "38        7    5    12     1   7  5000U   72   M      42          1\n",
      "39        7    6    16     1   7  5000U   72   M      46          1\n",
      "\n",
      "8\n",
      "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "40        8    1     0     1   8  Placebo   40   M      34          0\n",
      "41        8    2     2     1   8  Placebo   40   M      33          0\n",
      "42        8    3     4     1   8  Placebo   40   M      21          0\n",
      "43        8    4     8     1   8  Placebo   40   M      27          0\n",
      "44        8    5    12     1   8  Placebo   40   M      32          0\n",
      "45        8    6    16     1   8  Placebo   40   M      38          0\n",
      "\n",
      "9\n",
      "    patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "46        9    1     0     1   9  5000U   52   F      41          1\n",
      "47        9    2     2     1   9  5000U   52   F      32          1\n",
      "48        9    3     4     1   9  5000U   52   F      34          1\n",
      "49        9    4     8     1   9  5000U   52   F      35          1\n",
      "50        9    5    12     1   9  5000U   52   F      37          1\n",
      "51        9    6    16     1   9  5000U   52   F      36          1\n",
      "\n",
      "10\n",
      "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "52       10    1     0     1  10  Placebo   47   M      27          0\n",
      "53       10    2     2     1  10  Placebo   47   M      10          0\n",
      "54       10    3     4     1  10  Placebo   47   M      31          0\n",
      "55       10    4     8     1  10  Placebo   47   M      32          0\n",
      "56       10    5    12     1  10  Placebo   47   M       6          0\n",
      "57       10    6    16     1  10  Placebo   47   M      14          0\n",
      "\n",
      "11\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "58       11    1     0     1  11  10000U   57   F      48          2\n",
      "59       11    2     2     1  11  10000U   57   F      41          2\n",
      "60       11    3     4     1  11  10000U   57   F      32          2\n",
      "61       11    4     8     1  11  10000U   57   F      35          2\n",
      "62       11    5    12     1  11  10000U   57   F      57          2\n",
      "63       11    6    16     1  11  10000U   57   F      51          2\n",
      "\n",
      "12\n",
      "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "64       12    1     0     1  12  Placebo   47   F      34          0\n",
      "65       12    2     2     1  12  Placebo   47   F      19          0\n",
      "66       12    3     4     1  12  Placebo   47   F      21          0\n",
      "67       12    4     8     1  12  Placebo   47   F      24          0\n",
      "68       12    5    12     1  12  Placebo   47   F      28          0\n",
      "69       12    6    16     1  12  Placebo   47   F      28          0\n",
      "\n",
      "13\n",
      "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "70       13    1     0     2   1  Placebo   70   F      49          0\n",
      "71       13    2     2     2   1  Placebo   70   F      47          0\n",
      "72       13    3     4     2   1  Placebo   70   F      44          0\n",
      "73       13    4     8     2   1  Placebo   70   F      48          0\n",
      "74       13    5    12     2   1  Placebo   70   F      44          0\n",
      "75       13    6    16     2   1  Placebo   70   F      44          0\n",
      "\n",
      "14\n",
      "    patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "76       14    1     0     2   2  5000U   49   F      46          1\n",
      "77       14    2     2     2   2  5000U   49   F      35          1\n",
      "78       14    3     4     2   2  5000U   49   F      45          1\n",
      "79       14    4     8     2   2  5000U   49   F      49          1\n",
      "80       14    5    12     2   2  5000U   49   F      53          1\n",
      "81       14    6    16     2   2  5000U   49   F      56          1\n",
      "\n",
      "15\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "82       15    1     0     2   3  10000U   59   F      56          2\n",
      "83       15    2     2     2   3  10000U   59   F      44          2\n",
      "84       15    3     4     2   3  10000U   59   F      48          2\n",
      "85       15    4     8     2   3  10000U   59   F      54          2\n",
      "86       15    5    12     2   3  10000U   59   F      49          2\n",
      "87       15    6    16     2   3  10000U   59   F      60          2\n",
      "\n",
      "16\n",
      "    patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "88       16    1     0     2   4  5000U   64   M      59          1\n",
      "89       16    2     2     2   4  5000U   64   M      48          1\n",
      "90       16    3     4     2   4  5000U   64   M      56          1\n",
      "91       16    4     8     2   4  5000U   64   M      55          1\n",
      "92       16    5    12     2   4  5000U   64   M      57          1\n",
      "93       16    6    16     2   4  5000U   64   M      58          1\n",
      "\n",
      "17\n",
      "    patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "94       17    1     0     2   5  10000U   45   F      62          2\n",
      "95       17    2     2     2   5  10000U   45   F      60          2\n",
      "96       17    3     4     2   5  10000U   45   F      60          2\n",
      "97       17    4     8     2   5  10000U   45   F      64          2\n",
      "98       17    5    12     2   5  10000U   45   F      67          2\n",
      "99       17    6    16     2   5  10000U   45   F      66          2\n",
      "\n",
      "18\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "100       18    1     0     2   6  Placebo   66   F      50          0\n",
      "101       18    2     2     2   6  Placebo   66   F      53          0\n",
      "102       18    3     4     2   6  Placebo   66   F      52          0\n",
      "103       18    4     8     2   6  Placebo   66   F      57          0\n",
      "104       18    5    12     2   6  Placebo   66   F      61          0\n",
      "105       18    6    16     2   6  Placebo   66   F      54          0\n",
      "\n",
      "19\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "106       19    1     0     2   7  10000U   49   F      42          2\n",
      "107       19    2     2     2   7  10000U   49   F      42          2\n",
      "108       19    3     4     2   7  10000U   49   F      43          2\n",
      "109       19    4     8     2   7  10000U   49   F      33          2\n",
      "110       19    5    12     2   7  10000U   49   F      37          2\n",
      "111       19    6    16     2   7  10000U   49   F      43          2\n",
      "\n",
      "20\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "112       20    1     0     2   8  Placebo   54   F      53          0\n",
      "113       20    2     2     2   8  Placebo   54   F      56          0\n",
      "114       20    3     4     2   8  Placebo   54   F      52          0\n",
      "115       20    4     8     2   8  Placebo   54   F      54          0\n",
      "116       20    5    12     2   8  Placebo   54   F      55          0\n",
      "117       20    6    16     2   8  Placebo   54   F      51          0\n",
      "\n",
      "21\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "118       21    1     0     2   9  5000U   47   F      67          1\n",
      "119       21    2     2     2   9  5000U   47   F      64          1\n",
      "120       21    3     4     2   9  5000U   47   F      65          1\n",
      "121       21    4     8     2   9  5000U   47   F      64          1\n",
      "122       21    5    12     2   9  5000U   47   F      62          1\n",
      "123       21    6    16     2   9  5000U   47   F      64          1\n",
      "\n",
      "22\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "124       22    1     0     2  10  Placebo   31   M      44          0\n",
      "125       22    2     2     2  10  Placebo   31   M      40          0\n",
      "126       22    3     4     2  10  Placebo   31   M      32          0\n",
      "127       22    4     8     2  10  Placebo   31   M      36          0\n",
      "128       22    5    12     2  10  Placebo   31   M      42          0\n",
      "129       22    6    16     2  10  Placebo   31   M      43          0\n",
      "\n",
      "23\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "130       23    1     0     2  11  10000U   53   F      65          2\n",
      "131       23    2     2     2  11  10000U   53   F      58          2\n",
      "132       23    3     4     2  11  10000U   53   F      55          2\n",
      "133       23    5    12     2  11  10000U   53   F      56          2\n",
      "134       23    6    16     2  11  10000U   53   F      60          2\n",
      "\n",
      "24\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "135       24    1     0     2  12  5000U   61   M      56          1\n",
      "136       24    2     2     2  12  5000U   61   M      54          1\n",
      "137       24    3     4     2  12  5000U   61   M      52          1\n",
      "138       24    4     8     2  12  5000U   61   M      48          1\n",
      "139       24    5    12     2  12  5000U   61   M      52          1\n",
      "140       24    6    16     2  12  5000U   61   M      53          1\n",
      "\n",
      "25\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "141       25    1     0     2  13  Placebo   40   M      30          0\n",
      "142       25    2     2     2  13  Placebo   40   M      33          0\n",
      "143       25    3     4     2  13  Placebo   40   M      25          0\n",
      "144       25    4     8     2  13  Placebo   40   M      29          0\n",
      "145       25    5    12     2  13  Placebo   40   M      32          0\n",
      "146       25    6    16     2  13  Placebo   40   M      32          0\n",
      "\n",
      "26\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "147       26    1     0     2  14  5000U   67   M      47          1\n",
      "148       26    3     4     2  14  5000U   67   M      54          1\n",
      "149       26    4     8     2  14  5000U   67   M      43          1\n",
      "150       26    5    12     2  14  5000U   67   M      46          1\n",
      "151       26    6    16     2  14  5000U   67   M      50          1\n",
      "\n",
      "27\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "152       27    1     0     3   1  10000U   54   F      50          2\n",
      "153       27    2     2     3   1  10000U   54   F      43          2\n",
      "154       27    3     4     3   1  10000U   54   F      51          2\n",
      "155       27    4     8     3   1  10000U   54   F      46          2\n",
      "156       27    5    12     3   1  10000U   54   F      49          2\n",
      "157       27    6    16     3   1  10000U   54   F      53          2\n",
      "\n",
      "28\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "158       28    1     0     3   2  Placebo   41   F      34          0\n",
      "159       28    2     2     3   2  Placebo   41   F      29          0\n",
      "160       28    3     4     3   2  Placebo   41   F      27          0\n",
      "161       28    4     8     3   2  Placebo   41   F      21          0\n",
      "162       28    5    12     3   2  Placebo   41   F      22          0\n",
      "163       28    6    16     3   2  Placebo   41   F      22          0\n",
      "\n",
      "29\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "164       29    1     0     3   3  5000U   66   M      39          1\n",
      "165       29    2     2     3   3  5000U   66   M      41          1\n",
      "166       29    3     4     3   3  5000U   66   M      33          1\n",
      "167       29    4     8     3   3  5000U   66   M      39          1\n",
      "168       29    5    12     3   3  5000U   66   M      37          1\n",
      "169       29    6    16     3   3  5000U   66   M      37          1\n",
      "\n",
      "30\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "170       30    1     0     3   4  Placebo   68   F      43          0\n",
      "171       30    2     2     3   4  Placebo   68   F      31          0\n",
      "172       30    3     4     3   4  Placebo   68   F      29          0\n",
      "173       30    4     8     3   4  Placebo   68   F      28          0\n",
      "174       30    5    12     3   4  Placebo   68   F      33          0\n",
      "175       30    6    16     3   4  Placebo   68   F      38          0\n",
      "\n",
      "31\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "176       31    1     0     3   5  10000U   41   F      46          2\n",
      "177       31    2     2     3   5  10000U   41   F      26          2\n",
      "178       31    3     4     3   5  10000U   41   F      29          2\n",
      "179       31    4     8     3   5  10000U   41   F      33          2\n",
      "180       31    5    12     3   5  10000U   41   F      45          2\n",
      "181       31    6    16     3   5  10000U   41   F      56          2\n",
      "\n",
      "32\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "182       32    1     0     3   6  5000U   77   M      52          1\n",
      "183       32    2     2     3   6  5000U   77   M      44          1\n",
      "184       32    3     4     3   6  5000U   77   M      47          1\n",
      "185       32    4     8     3   6  5000U   77   M      50          1\n",
      "186       32    5    12     3   6  5000U   77   M      50          1\n",
      "187       32    6    16     3   6  5000U   77   M      49          1\n",
      "\n",
      "33\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "188       33    1     0     3   7  10000U   41   M      38          2\n",
      "189       33    2     2     3   7  10000U   41   M      19          2\n",
      "190       33    3     4     3   7  10000U   41   M      20          2\n",
      "191       33    4     8     3   7  10000U   41   M      27          2\n",
      "192       33    5    12     3   7  10000U   41   M      29          2\n",
      "193       33    6    16     3   7  10000U   41   M      32          2\n",
      "\n",
      "34\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "194       34    1     0     3   8  Placebo   56   M      33          0\n",
      "195       34    2     2     3   8  Placebo   56   M      38          0\n",
      "196       34    3     4     3   8  Placebo   56   M      40          0\n",
      "197       34    4     8     3   8  Placebo   56   M      48          0\n",
      "198       34    5    12     3   8  Placebo   56   M      49          0\n",
      "199       34    6    16     3   8  Placebo   56   M      44          0\n",
      "\n",
      "35\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "200       35    1     0     3   9  5000U   46   F      28          1\n",
      "201       35    2     2     3   9  5000U   46   F      16          1\n",
      "202       35    3     4     3   9  5000U   46   F      11          1\n",
      "203       35    4     8     3   9  5000U   46   F       7          1\n",
      "204       35    5    12     3   9  5000U   46   F      13          1\n",
      "205       35    6    16     3   9  5000U   46   F      21          1\n",
      "\n",
      "36\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "206       36    1     0     3  10  10000U   46   F      34          2\n",
      "207       36    2     2     3  10  10000U   46   F      23          2\n",
      "208       36    3     4     3  10  10000U   46   F      16          2\n",
      "209       36    4     8     3  10  10000U   46   F      15          2\n",
      "210       36    5    12     3  10  10000U   46   F      17          2\n",
      "211       36    6    16     3  10  10000U   46   F      29          2\n",
      "\n",
      "37\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "212       37    1     0     3  11  Placebo   47   F      39          0\n",
      "213       37    2     2     3  11  Placebo   47   F      37          0\n",
      "214       37    3     4     3  11  Placebo   47   F      39          0\n",
      "215       37    4     8     3  11  Placebo   47   F      39          0\n",
      "216       37    5    12     3  11  Placebo   47   F      45          0\n",
      "217       37    6    16     3  11  Placebo   47   F      43          0\n",
      "\n",
      "38\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "218       38    1     0     3  12  5000U   35   M      29          1\n",
      "219       38    2     2     3  12  5000U   35   M      42          1\n",
      "220       38    3     4     3  12  5000U   35   M      35          1\n",
      "221       38    4     8     3  12  5000U   35   M      24          1\n",
      "222       38    5    12     3  12  5000U   35   M      29          1\n",
      "223       38    6    16     3  12  5000U   35   M      42          1\n",
      "\n",
      "39\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "224       39    1     0     4   1  Placebo   58   M      52          0\n",
      "225       39    2     2     4   1  Placebo   58   M      55          0\n",
      "226       39    3     4     4   1  Placebo   58   M      51          0\n",
      "227       39    4     8     4   1  Placebo   58   M      52          0\n",
      "228       39    5    12     4   1  Placebo   58   M      54          0\n",
      "229       39    6    16     4   1  Placebo   58   M      57          0\n",
      "\n",
      "40\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "230       40    1     0     4   2  5000U   62   F      52          1\n",
      "231       40    2     2     4   2  5000U   62   F      30          1\n",
      "232       40    3     4     4   2  5000U   62   F      43          1\n",
      "233       40    4     8     4   2  5000U   62   F      45          1\n",
      "234       40    5    12     4   2  5000U   62   F      47          1\n",
      "235       40    6    16     4   2  5000U   62   F      46          1\n",
      "\n",
      "41\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "236       41    1     0     4   3  10000U   73   F      54          2\n",
      "237       41    2     2     4   3  10000U   73   F      52          2\n",
      "238       41    3     4     4   3  10000U   73   F      52          2\n",
      "239       41    4     8     4   3  10000U   73   F      54          2\n",
      "240       41    5    12     4   3  10000U   73   F      51          2\n",
      "241       41    6    16     4   3  10000U   73   F      57          2\n",
      "\n",
      "42\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "242       42    1     0     4   4  10000U   52   F      52          2\n",
      "243       42    2     2     4   4  10000U   52   F      44          2\n",
      "244       42    3     4     4   4  10000U   52   F      33          2\n",
      "245       42    4     8     4   4  10000U   52   F      54          2\n",
      "246       42    5    12     4   4  10000U   52   F      46          2\n",
      "247       42    6    16     4   4  10000U   52   F      47          2\n",
      "\n",
      "43\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "248       43    1     0     4   5  Placebo   53   F      47          0\n",
      "249       43    2     2     4   5  Placebo   53   F      45          0\n",
      "250       43    3     4     4   5  Placebo   53   F      41          0\n",
      "251       43    4     8     4   5  Placebo   53   F      45          0\n",
      "252       43    5    12     4   5  Placebo   53   F      43          0\n",
      "253       43    6    16     4   5  Placebo   53   F      41          0\n",
      "\n",
      "44\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "254       44    1     0     4   6  5000U   69   M      44          1\n",
      "255       44    2     2     4   6  5000U   69   M      34          1\n",
      "256       44    3     4     4   6  5000U   69   M      29          1\n",
      "257       44    4     8     4   6  5000U   69   M      28          1\n",
      "258       44    5    12     4   6  5000U   69   M      35          1\n",
      "259       44    6    16     4   6  5000U   69   M      41          1\n",
      "\n",
      "45\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "260       45    1     0     4   7  Placebo   55   M      42          0\n",
      "261       45    2     2     4   7  Placebo   55   M      39          0\n",
      "262       45    3     4     4   7  Placebo   55   M      38          0\n",
      "263       45    4     8     4   7  Placebo   55   M      47          0\n",
      "264       45    5    12     4   7  Placebo   55   M      39          0\n",
      "265       45    6    16     4   7  Placebo   55   M      39          0\n",
      "\n",
      "46\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "266       46    1     0     4   8  10000U   52   F      42          2\n",
      "267       46    2     2     4   8  10000U   52   F      14          2\n",
      "268       46    3     4     4   8  10000U   52   F       9          2\n",
      "269       46    4     8     4   8  10000U   52   F       9          2\n",
      "270       46    5    12     4   8  10000U   52   F      16          2\n",
      "271       46    6    16     4   8  10000U   52   F      33          2\n",
      "\n",
      "47\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "272       47    1     0     5   1  10000U   51   F      44          2\n",
      "273       47    2     2     5   1  10000U   51   F      34          2\n",
      "274       47    3     4     5   1  10000U   51   F      32          2\n",
      "275       47    4     8     5   1  10000U   51   F      35          2\n",
      "276       47    5    12     5   1  10000U   51   F      54          2\n",
      "277       47    6    16     5   1  10000U   51   F      53          2\n",
      "\n",
      "48\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "278       48    1     0     5   2  Placebo   56   F      60          0\n",
      "279       48    2     2     5   2  Placebo   56   F      57          0\n",
      "280       48    3     4     5   2  Placebo   56   F      53          0\n",
      "281       48    4     8     5   2  Placebo   56   F      52          0\n",
      "282       48    5    12     5   2  Placebo   56   F      53          0\n",
      "283       48    6    16     5   2  Placebo   56   F      58          0\n",
      "\n",
      "49\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "284       49    1     0     5   3  5000U   65   F      60          1\n",
      "285       49    2     2     5   3  5000U   65   F      53          1\n",
      "286       49    3     4     5   3  5000U   65   F      55          1\n",
      "287       49    4     8     5   3  5000U   65   F      62          1\n",
      "288       49    5    12     5   3  5000U   65   F      67          1\n",
      "\n",
      "50\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "289       50    1     0     5   4  10000U   35   F      50          2\n",
      "290       50    2     2     5   4  10000U   35   F      50          2\n",
      "291       50    4     8     5   4  10000U   35   F      46          2\n",
      "292       50    5    12     5   4  10000U   35   F      50          2\n",
      "293       50    6    16     5   4  10000U   35   F      57          2\n",
      "\n",
      "51\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "294       51    1     0     5   5  5000U   43   M      38          1\n",
      "295       51    2     2     5   5  5000U   43   M      27          1\n",
      "296       51    3     4     5   5  5000U   43   M      16          1\n",
      "297       51    4     8     5   5  5000U   43   M      19          1\n",
      "298       51    5    12     5   5  5000U   43   M      23          1\n",
      "299       51    6    16     5   5  5000U   43   M      26          1\n",
      "\n",
      "52\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "300       52    1     0     5   6  Placebo   61   M      44          0\n",
      "301       52    3     4     5   6  Placebo   61   M      46          0\n",
      "302       52    4     8     5   6  Placebo   61   M      26          0\n",
      "303       52    5    12     5   6  Placebo   61   M      30          0\n",
      "304       52    6    16     5   6  Placebo   61   M      34          0\n",
      "\n",
      "53\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "305       53    1     0     6   1  Placebo   43   M      54          0\n",
      "306       53    2     2     6   1  Placebo   43   M      53          0\n",
      "307       53    3     4     6   1  Placebo   43   M      51          0\n",
      "308       53    4     8     6   1  Placebo   43   M      56          0\n",
      "309       53    5    12     6   1  Placebo   43   M      39          0\n",
      "310       53    6    16     6   1  Placebo   43   M       9          0\n",
      "\n",
      "54\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "311       54    1     0     6   2  10000U   64   F      54          2\n",
      "312       54    2     2     6   2  10000U   64   F      32          2\n",
      "313       54    3     4     6   2  10000U   64   F      40          2\n",
      "314       54    4     8     6   2  10000U   64   F      52          2\n",
      "315       54    5    12     6   2  10000U   64   F      42          2\n",
      "316       54    6    16     6   2  10000U   64   F      47          2\n",
      "\n",
      "55\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "317       55    1     0     6   3  5000U   57   M      56          1\n",
      "318       55    2     2     6   3  5000U   57   M      55          1\n",
      "319       55    3     4     6   3  5000U   57   M      44          1\n",
      "320       55    4     8     6   3  5000U   57   M      50          1\n",
      "321       55    5    12     6   3  5000U   57   M      53          1\n",
      "322       55    6    16     6   3  5000U   57   M      52          1\n",
      "\n",
      "56\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "323       56    1     0     6   4  5000U   60   F      51          1\n",
      "324       56    2     2     6   4  5000U   60   F      50          1\n",
      "325       56    3     4     6   4  5000U   60   F      50          1\n",
      "326       56    4     8     6   4  5000U   60   F      56          1\n",
      "327       56    5    12     6   4  5000U   60   F      59          1\n",
      "328       56    6    16     6   4  5000U   60   F      53          1\n",
      "\n",
      "57\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "329       57    1     0     6   5  10000U   44   F      53          2\n",
      "330       57    2     2     6   5  10000U   44   F      56          2\n",
      "331       57    3     4     6   5  10000U   44   F      47          2\n",
      "332       57    4     8     6   5  10000U   44   F      53          2\n",
      "333       57    5    12     6   5  10000U   44   F      51          2\n",
      "334       57    6    16     6   5  10000U   44   F      51          2\n",
      "\n",
      "58\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "335       58    1     0     6   6  Placebo   41   F      36          0\n",
      "336       58    2     2     6   6  Placebo   41   F      29          0\n",
      "337       58    3     4     6   6  Placebo   41   F      24          0\n",
      "338       58    4     8     6   6  Placebo   41   F      32          0\n",
      "339       58    5    12     6   6  Placebo   41   F      45          0\n",
      "340       58    6    16     6   6  Placebo   41   F      36          0\n",
      "\n",
      "59\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "341       59    1     0     6   7  5000U   51   F      59          1\n",
      "342       59    2     2     6   7  5000U   51   F      53          1\n",
      "343       59    3     4     6   7  5000U   51   F      45          1\n",
      "344       59    4     8     6   7  5000U   51   F      44          1\n",
      "345       59    5    12     6   7  5000U   51   F      50          1\n",
      "346       59    6    16     6   7  5000U   51   F      48          1\n",
      "\n",
      "60\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "347       60    1     0     6   8  Placebo   57   F      49          0\n",
      "348       60    2     2     6   8  Placebo   57   F      50          0\n",
      "349       60    3     4     6   8  Placebo   57   F      48          0\n",
      "350       60    4     8     6   8  Placebo   57   F      56          0\n",
      "351       60    5    12     6   8  Placebo   57   F      49          0\n",
      "352       60    6    16     6   8  Placebo   57   F      57          0\n",
      "\n",
      "61\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "353       61    1     0     6   9  10000U   42   F      50          2\n",
      "354       61    2     2     6   9  10000U   42   F      38          2\n",
      "355       61    3     4     6   9  10000U   42   F      42          2\n",
      "356       61    4     8     6   9  10000U   42   F      43          2\n",
      "357       61    5    12     6   9  10000U   42   F      42          2\n",
      "358       61    6    16     6   9  10000U   42   F      46          2\n",
      "\n",
      "62\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "359       62    1     0     6  10  Placebo   48   F      46          0\n",
      "360       62    2     2     6  10  Placebo   48   F      48          0\n",
      "361       62    3     4     6  10  Placebo   48   F      46          0\n",
      "362       62    4     8     6  10  Placebo   48   F      57          0\n",
      "363       62    5    12     6  10  Placebo   48   F      57          0\n",
      "364       62    6    16     6  10  Placebo   48   F      49          0\n",
      "\n",
      "63\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "365       63    1     0     6  11  10000U   57   M      55          2\n",
      "366       63    2     2     6  11  10000U   57   M      34          2\n",
      "367       63    3     4     6  11  10000U   57   M      26          2\n",
      "368       63    4     8     6  11  10000U   57   M      40          2\n",
      "369       63    5    12     6  11  10000U   57   M      49          2\n",
      "370       63    6    16     6  11  10000U   57   M      47          2\n",
      "\n",
      "64\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "371       64    1     0     6  12  5000U   39   M      46          1\n",
      "372       64    2     2     6  12  5000U   39   M      44          1\n",
      "373       64    3     4     6  12  5000U   39   M      47          1\n",
      "374       64    4     8     6  12  5000U   39   M      50          1\n",
      "375       64    5    12     6  12  5000U   39   M      46          1\n",
      "376       64    6    16     6  12  5000U   39   M      51          1\n",
      "\n",
      "65\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "377       65    1     0     6  13  10000U   67   M      34          2\n",
      "378       65    2     2     6  13  10000U   67   M      31          2\n",
      "379       65    3     4     6  13  10000U   67   M      25          2\n",
      "\n",
      "66\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "380       66    1     0     6  14  5000U   39   F      57          1\n",
      "381       66    2     2     6  14  5000U   39   F      48          1\n",
      "382       66    3     4     6  14  5000U   39   F      50          1\n",
      "383       66    4     8     6  14  5000U   39   F      50          1\n",
      "384       66    5    12     6  14  5000U   39   F      50          1\n",
      "385       66    6    16     6  14  5000U   39   F      49          1\n",
      "\n",
      "67\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "386       67    1     0     6  15  Placebo   69   M      41          0\n",
      "387       67    2     2     6  15  Placebo   69   M      40          0\n",
      "388       67    3     4     6  15  Placebo   69   M      42          0\n",
      "389       67    4     8     6  15  Placebo   69   M      38          0\n",
      "390       67    5    12     6  15  Placebo   69   M      50          0\n",
      "391       67    6    16     6  15  Placebo   69   M      56          0\n",
      "\n",
      "68\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "392       68    1     0     7   1  5000U   54   F      49          1\n",
      "393       68    2     2     7   1  5000U   54   F      25          1\n",
      "394       68    3     4     7   1  5000U   54   F      30          1\n",
      "395       68    4     8     7   1  5000U   54   F      41          1\n",
      "396       68    5    12     7   1  5000U   54   F      41          1\n",
      "397       68    6    16     7   1  5000U   54   F      31          1\n",
      "\n",
      "69\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "398       69    1     0     7   2  Placebo   67   F      42          0\n",
      "399       69    2     2     7   2  Placebo   67   F      30          0\n",
      "400       69    3     4     7   2  Placebo   67   F      40          0\n",
      "401       69    4     8     7   2  Placebo   67   F      43          0\n",
      "402       69    5    12     7   2  Placebo   67   F      36          0\n",
      "403       69    6    16     7   2  Placebo   67   F      45          0\n",
      "\n",
      "70\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "404       70    1     0     7   3  10000U   58   F      31          2\n",
      "405       70    2     2     7   3  10000U   58   F      18          2\n",
      "406       70    3     4     7   3  10000U   58   F      23          2\n",
      "407       70    4     8     7   3  10000U   58   F      26          2\n",
      "408       70    5    12     7   3  10000U   58   F      33          2\n",
      "409       70    6    16     7   3  10000U   58   F      41          2\n",
      "\n",
      "71\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "410       71    1     0     7   4  Placebo   72   F      50          0\n",
      "411       71    2     2     7   4  Placebo   72   F      27          0\n",
      "412       71    3     4     7   4  Placebo   72   F      43          0\n",
      "413       71    4     8     7   4  Placebo   72   F      32          0\n",
      "414       71    5    12     7   4  Placebo   72   F      40          0\n",
      "415       71    6    16     7   4  Placebo   72   F      47          0\n",
      "\n",
      "72\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "416       72    1     0     7   5  10000U   65   F      35          2\n",
      "417       72    2     2     7   5  10000U   65   F      24          2\n",
      "418       72    3     4     7   5  10000U   65   F      34          2\n",
      "419       72    4     8     7   5  10000U   65   F      28          2\n",
      "420       72    5    12     7   5  10000U   65   F      34          2\n",
      "421       72    6    16     7   5  10000U   65   F      28          2\n",
      "\n",
      "73\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "422       73    1     0     7   6  5000U   68   F      38          1\n",
      "423       73    2     2     7   6  5000U   68   F      25          1\n",
      "424       73    3     4     7   6  5000U   68   F      21          1\n",
      "425       73    4     8     7   6  5000U   68   F      33          1\n",
      "426       73    5    12     7   6  5000U   68   F      42          1\n",
      "427       73    6    16     7   6  5000U   68   F      53          1\n",
      "\n",
      "74\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "428       74    1     0     7   7  10000U   75   F      53          2\n",
      "429       74    2     2     7   7  10000U   75   F      40          2\n",
      "430       74    3     4     7   7  10000U   75   F      38          2\n",
      "431       74    4     8     7   7  10000U   75   F      44          2\n",
      "432       74    5    12     7   7  10000U   75   F      47          2\n",
      "433       74    6    16     7   7  10000U   75   F      53          2\n",
      "\n",
      "75\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "434       75    1     0     7   8  Placebo   26   F      42          0\n",
      "435       75    2     2     7   8  Placebo   26   F      48          0\n",
      "436       75    3     4     7   8  Placebo   26   F      26          0\n",
      "437       75    4     8     7   8  Placebo   26   F      37          0\n",
      "438       75    5    12     7   8  Placebo   26   F      37          0\n",
      "439       75    6    16     7   8  Placebo   26   F      43          0\n",
      "\n",
      "76\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "440       76    1     0     7   9  5000U   36   F      53          1\n",
      "441       76    2     2     7   9  5000U   36   F      45          1\n",
      "442       76    3     4     7   9  5000U   36   F      52          1\n",
      "443       76    4     8     7   9  5000U   36   F      51          1\n",
      "444       76    5    12     7   9  5000U   36   F      52          1\n",
      "445       76    6    16     7   9  5000U   36   F      53          1\n",
      "\n",
      "77\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "446       77    1     0     7  10  10000U   72   M      46          2\n",
      "447       77    2     2     7  10  10000U   72   M      47          2\n",
      "448       77    3     4     7  10  10000U   72   M      45          2\n",
      "449       77    4     8     7  10  10000U   72   M      45          2\n",
      "450       77    5    12     7  10  10000U   72   M      50          2\n",
      "451       77    6    16     7  10  10000U   72   M      52          2\n",
      "\n",
      "78\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "452       78    1     0     7  11  Placebo   54   F      50          0\n",
      "453       78    2     2     7  11  Placebo   54   F      42          0\n",
      "454       78    3     4     7  11  Placebo   54   F      52          0\n",
      "455       78    4     8     7  11  Placebo   54   F      60          0\n",
      "456       78    5    12     7  11  Placebo   54   F      54          0\n",
      "457       78    6    16     7  11  Placebo   54   F      59          0\n",
      "\n",
      "79\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "458       79    1     0     7  12  5000U   64   F      43          1\n",
      "459       79    2     2     7  12  5000U   64   F      24          1\n",
      "460       79    3     4     7  12  5000U   64   F      17          1\n",
      "461       79    4     8     7  12  5000U   64   F      37          1\n",
      "462       79    5    12     7  12  5000U   64   F      36          1\n",
      "463       79    6    16     7  12  5000U   64   F      38          1\n",
      "\n",
      "80\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "464       80    1     0     8   1  Placebo   39   F      46          0\n",
      "465       80    2     2     8   1  Placebo   39   F      39          0\n",
      "466       80    3     4     8   1  Placebo   39   F      25          0\n",
      "467       80    4     8     8   1  Placebo   39   F      15          0\n",
      "468       80    5    12     8   1  Placebo   39   F      21          0\n",
      "469       80    6    16     8   1  Placebo   39   F      25          0\n",
      "\n",
      "81\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "470       81    1     0     8   2  10000U   54   M      41          2\n",
      "471       81    2     2     8   2  10000U   54   M      30          2\n",
      "472       81    3     4     8   2  10000U   54   M      44          2\n",
      "473       81    4     8     8   2  10000U   54   M      46          2\n",
      "474       81    5    12     8   2  10000U   54   M      46          2\n",
      "475       81    6    16     8   2  10000U   54   M      44          2\n",
      "\n",
      "82\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "476       82    1     0     8   3  5000U   48   M      33          1\n",
      "477       82    2     2     8   3  5000U   48   M      27          1\n",
      "478       82    3     4     8   3  5000U   48   M      25          1\n",
      "479       82    4     8     8   3  5000U   48   M      30          1\n",
      "480       82    5    12     8   3  5000U   48   M      28          1\n",
      "481       82    6    16     8   3  5000U   48   M      30          1\n",
      "\n",
      "83\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "482       83    1     0     8   4  5000U   83   F      36          1\n",
      "483       83    2     2     8   4  5000U   83   F      15          1\n",
      "484       83    3     4     8   4  5000U   83   F      16          1\n",
      "485       83    4     8     8   4  5000U   83   F      17          1\n",
      "486       83    5    12     8   4  5000U   83   F      22          1\n",
      "487       83    6    16     8   4  5000U   83   F      41          1\n",
      "\n",
      "84\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "488       84    1     0     8   5  10000U   74   M      33          2\n",
      "489       84    2     2     8   5  10000U   74   M      32          2\n",
      "490       84    3     4     8   5  10000U   74   M      31          2\n",
      "491       84    4     8     8   5  10000U   74   M      27          2\n",
      "492       84    5    12     8   5  10000U   74   M      49          2\n",
      "493       84    6    16     8   5  10000U   74   M      60          2\n",
      "\n",
      "85\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "494       85    1     0     8   6  Placebo   41   M      37          0\n",
      "\n",
      "86\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "495       86    1     0     8   7  10000U   65   F      24          2\n",
      "496       86    2     2     8   7  10000U   65   F      29          2\n",
      "497       86    3     4     8   7  10000U   65   F      18          2\n",
      "498       86    4     8     8   7  10000U   65   F      20          2\n",
      "499       86    5    12     8   7  10000U   65   F      25          2\n",
      "500       86    6    16     8   7  10000U   65   F      41          2\n",
      "\n",
      "87\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "501       87    1     0     8   8  5000U   79   M      42          1\n",
      "502       87    2     2     8   8  5000U   79   M      23          1\n",
      "503       87    3     4     8   8  5000U   79   M      30          1\n",
      "504       87    4     8     8   8  5000U   79   M      36          1\n",
      "505       87    5    12     8   8  5000U   79   M      41          1\n",
      "506       87    6    16     8   8  5000U   79   M      43          1\n",
      "\n",
      "88\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "507       88    1     0     8   9  Placebo   63   M      30          0\n",
      "508       88    2     2     8   9  Placebo   63   M      22          0\n",
      "509       88    3     4     8   9  Placebo   63   M      21          0\n",
      "510       88    4     8     8   9  Placebo   63   M      25          0\n",
      "511       88    5    12     8   9  Placebo   63   M      26          0\n",
      "512       88    6    16     8   9  Placebo   63   M      33          0\n",
      "\n",
      "89\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "513       89    1     0     8  10  Placebo   63   F      42          0\n",
      "514       89    2     2     8  10  Placebo   63   F      46          0\n",
      "515       89    3     4     8  10  Placebo   63   F      41          0\n",
      "516       89    4     8     8  10  Placebo   63   F      43          0\n",
      "517       89    5    12     8  10  Placebo   63   F      49          0\n",
      "518       89    6    16     8  10  Placebo   63   F      54          0\n",
      "\n",
      "90\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "519       90    1     0     8  11  10000U   34   F      49          2\n",
      "520       90    2     2     8  11  10000U   34   F      25          2\n",
      "521       90    3     4     8  11  10000U   34   F      30          2\n",
      "522       90    4     8     8  11  10000U   34   F      49          2\n",
      "523       90    5    12     8  11  10000U   34   F      55          2\n",
      "524       90    6    16     8  11  10000U   34   F      58          2\n",
      "\n",
      "91\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "525       91    1     0     8  12  5000U   42   M      58          1\n",
      "526       91    2     2     8  12  5000U   42   M      46          1\n",
      "527       91    3     4     8  12  5000U   42   M      46          1\n",
      "528       91    4     8     8  12  5000U   42   M      50          1\n",
      "529       91    5    12     8  12  5000U   42   M      56          1\n",
      "530       91    6    16     8  12  5000U   42   M      60          1\n",
      "\n",
      "92\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "531       92    1     0     8  13  Placebo   57   M      26          0\n",
      "532       92    2     2     8  13  Placebo   57   M      26          0\n",
      "533       92    3     4     8  13  Placebo   57   M      27          0\n",
      "534       92    4     8     8  13  Placebo   57   M      22          0\n",
      "535       92    5    12     8  13  Placebo   57   M      38          0\n",
      "536       92    6    16     8  13  Placebo   57   M      35          0\n",
      "\n",
      "93\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "537       93    1     0     8  14  5000U   68   M      37          1\n",
      "538       93    3     4     8  14  5000U   68   M      23          1\n",
      "539       93    4     8     8  14  5000U   68   M      18          1\n",
      "540       93    5    12     8  14  5000U   68   M      34          1\n",
      "541       93    6    16     8  14  5000U   68   M      36          1\n",
      "\n",
      "94\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "542       94    1     0     8  15  10000U   51   M      40          2\n",
      "543       94    2     2     8  15  10000U   51   M      24          2\n",
      "544       94    3     4     8  15  10000U   51   M      25          2\n",
      "545       94    4     8     8  15  10000U   51   M      37          2\n",
      "546       94    6    16     8  15  10000U   51   M      38          2\n",
      "\n",
      "95\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "547       95    1     0     8  16  5000U   51   F      33          1\n",
      "548       95    2     2     8  16  5000U   51   F      10          1\n",
      "549       95    3     4     8  16  5000U   51   F      13          1\n",
      "550       95    4     8     8  16  5000U   51   F      16          1\n",
      "551       95    5    12     8  16  5000U   51   F      32          1\n",
      "552       95    6    16     8  16  5000U   51   F      16          1\n",
      "\n",
      "96\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "553       96    1     0     8  17  10000U   61   F      41          2\n",
      "554       96    2     2     8  17  10000U   61   F      50          2\n",
      "555       96    3     4     8  17  10000U   61   F      22          2\n",
      "556       96    4     8     8  17  10000U   61   F      28          2\n",
      "557       96    5    12     8  17  10000U   61   F      34          2\n",
      "558       96    6    16     8  17  10000U   61   F      36          2\n",
      "\n",
      "97\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "559       97    1     0     8  18  Placebo   42   M      46          0\n",
      "560       97    3     4     8  18  Placebo   42   M      41          0\n",
      "561       97    4     8     8  18  Placebo   42   M      41          0\n",
      "562       97    5    12     8  18  Placebo   42   M      58          0\n",
      "563       97    6    16     8  18  Placebo   42   M      53          0\n",
      "\n",
      "98\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "564       98    1     0     8  19  10000U   73   F      40          2\n",
      "565       98    2     2     8  19  10000U   73   F      28          2\n",
      "566       98    3     4     8  19  10000U   73   F      29          2\n",
      "567       98    4     8     8  19  10000U   73   F      30          2\n",
      "568       98    5    12     8  19  10000U   73   F      37          2\n",
      "569       98    6    16     8  19  10000U   73   F      44          2\n",
      "\n",
      "99\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "570       99    1     0     9   1  10000U   57   M      40          2\n",
      "571       99    2     2     9   1  10000U   57   M      16          2\n",
      "572       99    3     4     9   1  10000U   57   M      18          2\n",
      "573       99    4     8     9   1  10000U   57   M      25          2\n",
      "574       99    5    12     9   1  10000U   57   M      33          2\n",
      "575       99    6    16     9   1  10000U   57   M      48          2\n",
      "\n",
      "100\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "576      100    1     0     9   2  Placebo   59   M      61          0\n",
      "577      100    2     2     9   2  Placebo   59   M      52          0\n",
      "578      100    3     4     9   2  Placebo   59   M      61          0\n",
      "579      100    4     8     9   2  Placebo   59   M      68          0\n",
      "580      100    5    12     9   2  Placebo   59   M      59          0\n",
      "581      100    6    16     9   2  Placebo   59   M      71          0\n",
      "\n",
      "101\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "582      101    1     0     9   3  5000U   57   M      35          1\n",
      "583      101    2     2     9   3  5000U   57   M      21          1\n",
      "584      101    3     4     9   3  5000U   57   M      29          1\n",
      "585      101    4     8     9   3  5000U   57   M      30          1\n",
      "586      101    5    12     9   3  5000U   57   M      35          1\n",
      "587      101    6    16     9   3  5000U   57   M      48          1\n",
      "\n",
      "102\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "588      102    1     0     9   4  Placebo   68   F      58          0\n",
      "589      102    2     2     9   4  Placebo   68   F      38          0\n",
      "590      102    3     4     9   4  Placebo   68   F      50          0\n",
      "591      102    4     8     9   4  Placebo   68   F      53          0\n",
      "592      102    5    12     9   4  Placebo   68   F      47          0\n",
      "593      102    6    16     9   4  Placebo   68   F      59          0\n",
      "\n",
      "103\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "594      103    1     0     9   5  5000U   55   F      49          1\n",
      "595      103    2     2     9   5  5000U   55   F      45          1\n",
      "596      103    3     4     9   5  5000U   55   F      36          1\n",
      "597      103    5    12     9   5  5000U   55   F      40          1\n",
      "598      103    6    16     9   5  5000U   55   F      52          1\n",
      "\n",
      "104\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "599      104    1     0     9   6  10000U   46   F      52          2\n",
      "600      104    2     2     9   6  10000U   46   F      46          2\n",
      "601      104    3     4     9   6  10000U   46   F      36          2\n",
      "602      104    5    12     9   6  10000U   46   F      45          2\n",
      "603      104    6    16     9   6  10000U   46   F      54          2\n",
      "\n",
      "105\n",
      "     patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
      "604      105    1     0     9   7  Placebo   79   F      45          0\n",
      "605      105    2     2     9   7  Placebo   79   F      46          0\n",
      "606      105    3     4     9   7  Placebo   79   F      33          0\n",
      "607      105    4     8     9   7  Placebo   79   F      44          0\n",
      "608      105    5    12     9   7  Placebo   79   F      46          0\n",
      "609      105    6    16     9   7  Placebo   79   F      48          0\n",
      "\n",
      "106\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "610      106    1     0     9   8  5000U   43   M      67          1\n",
      "611      106    2     2     9   8  5000U   43   M      63          1\n",
      "612      106    3     4     9   8  5000U   43   M      71          1\n",
      "613      106    4     8     9   8  5000U   43   M      66          1\n",
      "614      106    5    12     9   8  5000U   43   M      68          1\n",
      "615      106    6    16     9   8  5000U   43   M      71          1\n",
      "\n",
      "107\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "616      107    1     0     9   9  10000U   50   M      57          2\n",
      "617      107    3     4     9   9  10000U   50   M      36          2\n",
      "618      107    4     8     9   9  10000U   50   M      23          2\n",
      "619      107    6    16     9   9  10000U   50   M      52          2\n",
      "\n",
      "108\n",
      "     patient  obs  week  site  id   treat  age sex  twstrs  treatment\n",
      "620      108    1     0     9  10  10000U   39   F      63          2\n",
      "621      108    2     2     9  10  10000U   39   F      51          2\n",
      "622      108    3     4     9  10  10000U   39   F      46          2\n",
      "623      108    4     8     9  10  10000U   39   F      50          2\n",
      "624      108    5    12     9  10  10000U   39   F      50          2\n",
      "625      108    6    16     9  10  10000U   39   F      54          2\n",
      "\n",
      "109\n",
      "     patient  obs  week  site  id  treat  age sex  twstrs  treatment\n",
      "626      109    1     0     9  11  5000U   57   M      53          1\n",
      "627      109    2     2     9  11  5000U   57   M      38          1\n",
      "628      109    4     8     9  11  5000U   57   M      33          1\n",
      "629      109    5    12     9  11  5000U   57   M      36          1\n",
      "630      109    6    16     9  11  5000U   57   M      51          1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for patient, group in cdystonia_grouped:\n",
    "    print patient\n",
    "    print group\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common data analysis procedure is the **split-apply-combine** operation, which groups subsets of data together, applies a function to each of the groups, then recombines them into a new data table.\n",
    "\n",
    "For example, we may want to aggregate our data with with some function.\n",
    "\n",
    "![split-apply-combine](http://f.cl.ly/items/0s0Z252j0X0c3k3P1M47/Screen%20Shot%202013-06-02%20at%203.04.04%20PM.png)\n",
    "\n",
    "<div align=\"right\">*(figure taken from \"Python for Data Analysis\", p.251)*</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can aggregate in Pandas using the `aggregate` (or `agg`, for short) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         patient  obs  week  site  id  age     twstrs  treatment\n",
       "patient                                                         \n",
       "1              1  3.5   7.0     1   1   65  33.000000          1\n",
       "2              2  3.5   7.0     1   2   70  47.666667          2\n",
       "3              3  3.5   7.0     1   3   64  30.500000          1\n",
       "4              4  2.5   3.5     1   4   59  60.000000          0\n",
       "5              5  3.5   7.0     1   5   76  46.166667          2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_grouped.agg(np.mean).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `treat` and `sex` variables are not included in the aggregation. Since it does not make sense to aggregate non-string variables, these columns are simply ignored by the method.\n",
    "\n",
    "Some aggregation functions are so common that Pandas has a convenience method for them, such as `mean`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         patient  obs  week  site  id  age     twstrs  treatment\n",
       "patient                                                         \n",
       "1              1  3.5   7.0     1   1   65  33.000000          1\n",
       "2              2  3.5   7.0     1   2   70  47.666667          2\n",
       "3              3  3.5   7.0     1   3   64  30.500000          1\n",
       "4              4  2.5   3.5     1   4   59  60.000000          0\n",
       "5              5  3.5   7.0     1   5   76  46.166667          2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_grouped.mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `add_prefix` and `add_suffix` methods can be used to give the columns of the resulting table labels that reflect the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         patient_mean  obs_mean  week_mean  site_mean  id_mean  age_mean  \\\n",
       "patient                                                                    \n",
       "1                   1       3.5        7.0          1        1        65   \n",
       "2                   2       3.5        7.0          1        2        70   \n",
       "3                   3       3.5        7.0          1        3        64   \n",
       "4                   4       2.5        3.5          1        4        59   \n",
       "5                   5       3.5        7.0          1        5        76   \n",
       "\n",
       "         twstrs_mean  treatment_mean  \n",
       "patient                               \n",
       "1          33.000000               1  \n",
       "2          47.666667               2  \n",
       "3          30.500000               1  \n",
       "4          60.000000               0  \n",
       "5          46.166667               2  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_grouped.mean().add_suffix('_mean').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient\n",
       "1          34.0\n",
       "2          50.5\n",
       "3          30.5\n",
       "4          61.5\n",
       "5          48.5\n",
       "6          48.0\n",
       "7          42.0\n",
       "8          32.5\n",
       "9          35.5\n",
       "10         20.5\n",
       "...\n",
       "99         29.0\n",
       "100        61.0\n",
       "101        32.5\n",
       "102        51.5\n",
       "103        45.0\n",
       "104        46.0\n",
       "105        45.5\n",
       "106        67.5\n",
       "107        44.0\n",
       "108        50.5\n",
       "109        38.0\n",
       "Name: twstrs, Length: 109, dtype: float64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The median of the `twstrs` variable\n",
    "cdystonia_grouped['twstrs'].quantile(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wish, we can easily aggregate according to multiple keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           patient  obs   id        age     twstrs  treatment\n",
       "week site                                                    \n",
       "0    1         6.5    1  6.5  59.000000  43.083333   1.000000\n",
       "     2        19.5    1  7.5  53.928571  51.857143   0.928571\n",
       "     3        32.5    1  6.5  51.500000  38.750000   1.000000\n",
       "     4        42.5    1  4.5  59.250000  48.125000   1.000000\n",
       "     5        49.5    1  3.5  51.833333  49.333333   1.000000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia.groupby(['week','site']).mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we can **transform** the data, using a function of our choice with the `transform` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   patient       obs      week  site  id  age    twstrs  treatment\n",
       "0      NaN -1.336306 -1.135550   NaN NaN  NaN -0.181369        NaN\n",
       "1      NaN -0.801784 -0.811107   NaN NaN  NaN -0.544107        NaN\n",
       "2      NaN -0.267261 -0.486664   NaN NaN  NaN -1.632322        NaN\n",
       "3      NaN  0.267261  0.162221   NaN NaN  NaN  0.725476        NaN\n",
       "4      NaN  0.801784  0.811107   NaN NaN  NaN  1.088214        NaN"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = lambda x: (x - x.mean())/x.std()\n",
    "\n",
    "cdystonia_grouped.transform(normalize).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to do column selection within `groupby` operations, if we are only interested split-apply-combine operations on a subset of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient\n",
       "1          33.000000\n",
       "2          47.666667\n",
       "3          30.500000\n",
       "4          60.000000\n",
       "5          46.166667\n",
       "Name: twstrs, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia_grouped['twstrs'].mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            twstrs\n",
       "patient           \n",
       "1        33.000000\n",
       "2        47.666667\n",
       "3        30.500000\n",
       "4        60.000000\n",
       "5        46.166667"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This gives the same result as a DataFrame\n",
    "cdystonia_grouped[['twstrs']].mean().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you simply want to divide your DataFrame into chunks for later use, its easy to convert them into a dict so that they can be easily indexed out as needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = dict(list(cdystonia_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    patient  obs  week  site  id    treat  age sex  twstrs  treatment\n",
       "18        4    1     0     1   4  Placebo   59   F      53          0\n",
       "19        4    2     2     1   4  Placebo   59   F      61          0\n",
       "20        4    3     4     1   4  Placebo   59   F      64          0\n",
       "21        4    4     8     1   4  Placebo   59   F      62          0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `groupby` groups by row, but we can specify the `axis` argument to change this. For example, we can group our columns by type this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'):      patient  obs  week  site  id  age  twstrs  treatment\n",
       " 0          1    1     0     1   1   65      32          1\n",
       " 1          1    2     2     1   1   65      30          1\n",
       " 2          1    3     4     1   1   65      24          1\n",
       " 3          1    4     8     1   1   65      37          1\n",
       " 4          1    5    12     1   1   65      39          1\n",
       " 5          1    6    16     1   1   65      36          1\n",
       " 6          2    1     0     1   2   70      60          2\n",
       " 7          2    2     2     1   2   70      26          2\n",
       " 8          2    3     4     1   2   70      27          2\n",
       " 9          2    4     8     1   2   70      41          2\n",
       " 10         2    5    12     1   2   70      65          2\n",
       " 11         2    6    16     1   2   70      67          2\n",
       " ..       ...  ...   ...   ...  ..  ...     ...        ...\n",
       " 619      107    6    16     9   9   50      52          2\n",
       " 620      108    1     0     9  10   39      63          2\n",
       " 621      108    2     2     9  10   39      51          2\n",
       " 622      108    3     4     9  10   39      46          2\n",
       " 623      108    4     8     9  10   39      50          2\n",
       " 624      108    5    12     9  10   39      50          2\n",
       " 625      108    6    16     9  10   39      54          2\n",
       " 626      109    1     0     9  11   57      53          1\n",
       " 627      109    2     2     9  11   57      38          1\n",
       " 628      109    4     8     9  11   57      33          1\n",
       " 629      109    5    12     9  11   57      36          1\n",
       " 630      109    6    16     9  11   57      51          1\n",
       " \n",
       " [631 rows x 8 columns], dtype('O'):       treat sex\n",
       " 0     5000U   F\n",
       " 1     5000U   F\n",
       " 2     5000U   F\n",
       " 3     5000U   F\n",
       " 4     5000U   F\n",
       " 5     5000U   F\n",
       " 6    10000U   F\n",
       " 7    10000U   F\n",
       " 8    10000U   F\n",
       " 9    10000U   F\n",
       " 10   10000U   F\n",
       " 11   10000U   F\n",
       " ..      ...  ..\n",
       " 619  10000U   M\n",
       " 620  10000U   F\n",
       " 621  10000U   F\n",
       " 622  10000U   F\n",
       " 623  10000U   F\n",
       " 624  10000U   F\n",
       " 625  10000U   F\n",
       " 626   5000U   M\n",
       " 627   5000U   M\n",
       " 628   5000U   M\n",
       " 629   5000U   M\n",
       " 630   5000U   M\n",
       " \n",
       " [631 rows x 2 columns]}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(cdystonia.groupby(cdystonia.dtypes, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its also possible to group by one or more levels of a hierarchical index. Recall `cdystonia2`, which we created with a hierarchical index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             week  site  id   treat  age sex  twstrs\n",
       "patient obs                                         \n",
       "1       1       0     1   1   5000U   65   F      32\n",
       "        2       2     1   1   5000U   65   F      30\n",
       "        3       4     1   1   5000U   65   F      24\n",
       "        4       8     1   1   5000U   65   F      37\n",
       "        5      12     1   1   5000U   65   F      39\n",
       "        6      16     1   1   5000U   65   F      36\n",
       "2       1       0     1   2  10000U   70   F      60\n",
       "        2       2     1   2  10000U   70   F      26\n",
       "        3       4     1   2  10000U   70   F      27\n",
       "        4       8     1   2  10000U   70   F      41"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obs\n",
       "1      45.651376\n",
       "2      37.611650\n",
       "3      37.066038\n",
       "4      39.807692\n",
       "5      42.913462\n",
       "6      45.628571\n",
       "Name: twstrs, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdystonia2.groupby(level='obs', axis=0)['twstrs'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply\n",
    "\n",
    "We can generalize the split-apply-combine methodology by using `apply` function. This allows us to invoke any function we wish on a grouped dataset and recombine them into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below takes a DataFrame and a column name, sorts by the column, and takes the `n` largest values of that column. We can use this with `apply` to return the largest values from every group in a DataFrame in a single call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top(df, column, n=5):\n",
    "    return df.sort_index(by=column, ascending=False)[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see this in action, consider the vessel transit segments dataset (which we merged with the vessel information to yield `segments_merged`). Say we wanted to return the 3 longest segments travelled by each ship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                              names  \\\n",
       "mmsi                                                                  \n",
       "1         6       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   \n",
       "          5       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   \n",
       "          7       Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...   \n",
       "9         15                             000000009/Raven/Shearwater   \n",
       "          14                             000000009/Raven/Shearwater   \n",
       "          13                             000000009/Raven/Shearwater   \n",
       "21        16                                          Us Gov Vessel   \n",
       "          25                                          Us Gov Vessel   \n",
       "          30                                          Us Gov Vessel   \n",
       "74        35                                      Mcfaul/Sarah Bell   \n",
       "          34                                      Mcfaul/Sarah Bell   \n",
       "103       37               Ron G/Us Navy Warship 103/Us Warship 103   \n",
       "...                                                             ...   \n",
       "967191190 262409                                         Pathfinder   \n",
       "          262412                                         Pathfinder   \n",
       "          262423                                         Pathfinder   \n",
       "975318642 262478                                     Island Express   \n",
       "          262482                                     Island Express   \n",
       "          262481                                     Island Express   \n",
       "987654321 262498                         Island Lookout/Island Tide   \n",
       "          262507                         Island Lookout/Island Tide   \n",
       "          262510                         Island Lookout/Island Tide   \n",
       "999999999 262520                                  Triple Attraction   \n",
       "          262524                                  Triple Attraction   \n",
       "          262525                                  Triple Attraction   \n",
       "\n",
       "                  seg_length  \n",
       "mmsi                          \n",
       "1         6             76.0  \n",
       "          5             17.4  \n",
       "          7             13.7  \n",
       "9         15            47.2  \n",
       "          14            31.4  \n",
       "          13            19.3  \n",
       "21        16            48.7  \n",
       "          25            25.3  \n",
       "          30            21.7  \n",
       "74        35             7.4  \n",
       "          34             1.4  \n",
       "103       37            87.5  \n",
       "...                      ...  \n",
       "967191190 262409        32.7  \n",
       "          262412        30.6  \n",
       "          262423        30.4  \n",
       "975318642 262478        85.8  \n",
       "          262482        29.5  \n",
       "          262481        27.7  \n",
       "987654321 262498        22.5  \n",
       "          262507        20.9  \n",
       "          262510        18.6  \n",
       "999999999 262520        65.0  \n",
       "          262524        31.5  \n",
       "          262525        19.8  \n",
       "\n",
       "[29464 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3segments = segments_merged.groupby('mmsi').apply(top, column='seg_length', n=3)[['names', 'seg_length']]\n",
    "top3segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that additional arguments for the applied function can be passed via `apply` after the function name. It assumes that the DataFrame is the first argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     names  seg_length\n",
       "mmsi                                                                  \n",
       "1    6   Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...        76.0\n",
       "     5   Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...        17.4\n",
       "     7   Bil Holman Dredge/Dredge Capt Frank/Emo/Offsho...        13.7\n",
       "9    15                         000000009/Raven/Shearwater        47.2\n",
       "     14                         000000009/Raven/Shearwater        31.4\n",
       "     13                         000000009/Raven/Shearwater        19.3\n",
       "21   16                                      Us Gov Vessel        48.7\n",
       "     25                                      Us Gov Vessel        25.3\n",
       "     30                                      Us Gov Vessel        21.7\n",
       "74   35                                  Mcfaul/Sarah Bell         7.4\n",
       "     34                                  Mcfaul/Sarah Bell         1.4\n",
       "103  37           Ron G/Us Navy Warship 103/Us Warship 103        87.5\n",
       "     41           Ron G/Us Navy Warship 103/Us Warship 103        62.6\n",
       "     43           Ron G/Us Navy Warship 103/Us Warship 103        59.1\n",
       "310  51                                           Arabella        77.4\n",
       "     58                                           Arabella        30.7\n",
       "     49                                           Arabella        30.4\n",
       "3011 74                                         Charleston       121.6\n",
       "     69                                         Charleston        89.7\n",
       "     77                                         Charleston        59.7"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3segments.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the microbiome data sets that we used previously for the concatenation example. Suppose that we wish to aggregate the data at a higher biological classification than genus. For example, we can identify samples down to *class*, which is the 3rd level of organization in each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Desulfurococcaceae Ignisphaera', u'Archaea \"Crenarchaeota\" Thermoprotei Desulfurococcales Pyrodictiaceae Pyrolobus', u'Archaea \"Crenarchaeota\" Thermoprotei Sulfolobales Sulfolobaceae Stygiolobus'], dtype='object')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb1.index[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the string methods `split` and `join` we can create an index that just uses the first three classifications: domain, phylum and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class_index = mb1.index.map(lambda x: ' '.join(x.split(' ')[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mb_class = mb1.copy()\n",
    "mb_class.index = class_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, since there are multiple taxonomic units with the same class, our index is no longer unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           Count\n",
       "Archaea \"Crenarchaeota\" Thermoprotei           7\n",
       "Archaea \"Crenarchaeota\" Thermoprotei           2\n",
       "Archaea \"Crenarchaeota\" Thermoprotei           3\n",
       "Archaea \"Crenarchaeota\" Thermoprotei           3\n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\"      7"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can re-establish a unique index by summing all rows with the same class, using `groupby`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                           Count\n",
       "Archaea \"Crenarchaeota\" Thermoprotei          15\n",
       "Archaea \"Euryarchaeota\" \"Methanomicrobia\"      9\n",
       "Archaea \"Euryarchaeota\" Archaeoglobi           2\n",
       "Archaea \"Euryarchaeota\" Halobacteria          12\n",
       "Archaea \"Euryarchaeota\" Methanococci           1\n",
       "Archaea \"Euryarchaeota\" Methanopyri           12\n",
       "Archaea \"Euryarchaeota\" Thermoplasmata         2\n",
       "Bacteria \"Actinobacteria\" Actinobacteria    1740\n",
       "Bacteria \"Aquificae\" Aquificae                11\n",
       "Bacteria \"Bacteroidetes\" \"Bacteroidia\"         1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mb_class.groupby(level=0).sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Load the dataset in `titanic.xls`. It contains data on all the passengers that travelled on the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr><h2>Data frame:titanic3</h2>1309 observations and 14 variables, maximum # NAs:1188<hr>\n",
       "<TABLE BORDER>\n",
       "<tr><td>Name</td><td>Labels</td><td>Units</td><td>Levels</td><td>Storage</td><td>NAs</td></tr>\n",
       "<tr><td>pclass</td><td></td><td></td><td><a href=\"#pclass\"><div align=right>  3</div></a></td><td>integer</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>survived</td><td>Survived</td><td></td><td><div align=right></div></td><td>double</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>name</td><td>Name</td><td></td><td><div align=right></div></td><td>character</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>sex</td><td></td><td></td><td><a href=\"#sex\"><div align=right>  2</div></a></td><td>integer</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>age</td><td>Age</td><td>Year</td><td><div align=right></div></td><td>double</td><td><div align=right> 263</div></td></tr>\n",
       "<tr><td>sibsp</td><td>Number of Siblings/Spouses Aboard</td><td></td><td><div align=right></div></td><td>double</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>parch</td><td>Number of Parents/Children Aboard</td><td></td><td><div align=right></div></td><td>double</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>ticket</td><td>Ticket Number</td><td></td><td><div align=right></div></td><td>character</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>fare</td><td>Passenger Fare</td><td>British Pound (\\243)</td><td><div align=right></div></td><td>double</td><td><div align=right>   1</div></td></tr>\n",
       "<tr><td>cabin</td><td></td><td></td><td><a href=\"#cabin\"><div align=right>187</div></a></td><td>integer</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>embarked</td><td></td><td></td><td><a href=\"#embarked\"><div align=right>  3</div></a></td><td>integer</td><td><div align=right>   2</div></td></tr>\n",
       "<tr><td>boat</td><td></td><td></td><td><a href=\"#boat\"><div align=right> 28</div></a></td><td>integer</td><td><div align=right>   0</div></td></tr>\n",
       "<tr><td>body</td><td>Body Identification Number</td><td></td><td><div align=right></div></td><td>double</td><td><div align=right>1188</div></td></tr>\n",
       "<tr><td>home.dest</td><td>Home/Destination</td><td></td><td><div align=right></div></td><td>character</td><td><div align=right>   0</div></td></tr>\n",
       "</TABLE>\n",
       "<hr>\n",
       "<TABLE BORDER>\n",
       "<tr><td>Variable</td><td>Levels</td></tr>\n",
       "<tr><td><a name=\"pclass\">pclass</a></td><td>1st</td></tr>\n",
       "<tr><td></td><td>2nd</td></tr>\n",
       "<tr><td></td><td>3rd</td></tr>\n",
       "<tr><td><a name=\"sex\">sex</a></td><td>female</td></tr>\n",
       "<tr><td></td><td>male</td></tr>\n",
       "<tr><td><a name=\"cabin\">cabin</a></td><td></td></tr>\n",
       "<tr><td></td><td>A10</td></tr>\n",
       "<tr><td></td><td>A11</td></tr>\n",
       "<tr><td></td><td>A14</td></tr>\n",
       "<tr><td></td><td>A16</td></tr>\n",
       "<tr><td></td><td>A18</td></tr>\n",
       "<tr><td></td><td>A19</td></tr>\n",
       "<tr><td></td><td>A20</td></tr>\n",
       "<tr><td></td><td>A21</td></tr>\n",
       "<tr><td></td><td>A23</td></tr>\n",
       "<tr><td></td><td>A24</td></tr>\n",
       "<tr><td></td><td>A26</td></tr>\n",
       "<tr><td></td><td>A29</td></tr>\n",
       "<tr><td></td><td>A31</td></tr>\n",
       "<tr><td></td><td>A32</td></tr>\n",
       "<tr><td></td><td>A34</td></tr>\n",
       "<tr><td></td><td>A36</td></tr>\n",
       "<tr><td></td><td>A5</td></tr>\n",
       "<tr><td></td><td>A6</td></tr>\n",
       "<tr><td></td><td>A7</td></tr>\n",
       "<tr><td></td><td>A9</td></tr>\n",
       "<tr><td></td><td>B10</td></tr>\n",
       "<tr><td></td><td>B101</td></tr>\n",
       "<tr><td></td><td>B102</td></tr>\n",
       "<tr><td></td><td>B11</td></tr>\n",
       "<tr><td></td><td>B18</td></tr>\n",
       "<tr><td></td><td>B19</td></tr>\n",
       "<tr><td></td><td>B20</td></tr>\n",
       "<tr><td></td><td>B22</td></tr>\n",
       "<tr><td></td><td>B24</td></tr>\n",
       "<tr><td></td><td>B26</td></tr>\n",
       "<tr><td></td><td>B28</td></tr>\n",
       "<tr><td></td><td>B3</td></tr>\n",
       "<tr><td></td><td>B30</td></tr>\n",
       "<tr><td></td><td>B35</td></tr>\n",
       "<tr><td></td><td>B36</td></tr>\n",
       "<tr><td></td><td>B37</td></tr>\n",
       "<tr><td></td><td>B38</td></tr>\n",
       "<tr><td></td><td>B39</td></tr>\n",
       "<tr><td></td><td>B4</td></tr>\n",
       "<tr><td></td><td>B41</td></tr>\n",
       "<tr><td></td><td>B42</td></tr>\n",
       "<tr><td></td><td>B45</td></tr>\n",
       "<tr><td></td><td>B49</td></tr>\n",
       "<tr><td></td><td>B5</td></tr>\n",
       "<tr><td></td><td>B50</td></tr>\n",
       "<tr><td></td><td>B51 B53 B55</td></tr>\n",
       "<tr><td></td><td>B52 B54 B56</td></tr>\n",
       "<tr><td></td><td>B57 B59 B63 B66</td></tr>\n",
       "<tr><td></td><td>B58 B60</td></tr>\n",
       "<tr><td></td><td>B61</td></tr>\n",
       "<tr><td></td><td>B69</td></tr>\n",
       "<tr><td></td><td>B71</td></tr>\n",
       "<tr><td></td><td>B73</td></tr>\n",
       "<tr><td></td><td>B77</td></tr>\n",
       "<tr><td></td><td>B78</td></tr>\n",
       "<tr><td></td><td>B79</td></tr>\n",
       "<tr><td></td><td>B80</td></tr>\n",
       "<tr><td></td><td>B82 B84</td></tr>\n",
       "<tr><td></td><td>B86</td></tr>\n",
       "<tr><td></td><td>B94</td></tr>\n",
       "<tr><td></td><td>B96 B98</td></tr>\n",
       "<tr><td></td><td>C101</td></tr>\n",
       "<tr><td></td><td>C103</td></tr>\n",
       "<tr><td></td><td>C104</td></tr>\n",
       "<tr><td></td><td>C105</td></tr>\n",
       "<tr><td></td><td>C106</td></tr>\n",
       "<tr><td></td><td>C110</td></tr>\n",
       "<tr><td></td><td>C111</td></tr>\n",
       "<tr><td></td><td>C116</td></tr>\n",
       "<tr><td></td><td>C118</td></tr>\n",
       "<tr><td></td><td>C123</td></tr>\n",
       "<tr><td></td><td>C124</td></tr>\n",
       "<tr><td></td><td>C125</td></tr>\n",
       "<tr><td></td><td>C126</td></tr>\n",
       "<tr><td></td><td>C128</td></tr>\n",
       "<tr><td></td><td>C130</td></tr>\n",
       "<tr><td></td><td>C132</td></tr>\n",
       "<tr><td></td><td>C148</td></tr>\n",
       "<tr><td></td><td>C2</td></tr>\n",
       "<tr><td></td><td>C22 C26</td></tr>\n",
       "<tr><td></td><td>C23 C25 C27</td></tr>\n",
       "<tr><td></td><td>C28</td></tr>\n",
       "<tr><td></td><td>C30</td></tr>\n",
       "<tr><td></td><td>C31</td></tr>\n",
       "<tr><td></td><td>C32</td></tr>\n",
       "<tr><td></td><td>C39</td></tr>\n",
       "<tr><td></td><td>C45</td></tr>\n",
       "<tr><td></td><td>C46</td></tr>\n",
       "<tr><td></td><td>C47</td></tr>\n",
       "<tr><td></td><td>C49</td></tr>\n",
       "<tr><td></td><td>C50</td></tr>\n",
       "<tr><td></td><td>C51</td></tr>\n",
       "<tr><td></td><td>C52</td></tr>\n",
       "<tr><td></td><td>C53</td></tr>\n",
       "<tr><td></td><td>C54</td></tr>\n",
       "<tr><td></td><td>C55 C57</td></tr>\n",
       "<tr><td></td><td>C6</td></tr>\n",
       "<tr><td></td><td>C62 C64</td></tr>\n",
       "<tr><td></td><td>C65</td></tr>\n",
       "<tr><td></td><td>C68</td></tr>\n",
       "<tr><td></td><td>C7</td></tr>\n",
       "<tr><td></td><td>C70</td></tr>\n",
       "<tr><td></td><td>C78</td></tr>\n",
       "<tr><td></td><td>C80</td></tr>\n",
       "<tr><td></td><td>C82</td></tr>\n",
       "<tr><td></td><td>C83</td></tr>\n",
       "<tr><td></td><td>C85</td></tr>\n",
       "<tr><td></td><td>C86</td></tr>\n",
       "<tr><td></td><td>C87</td></tr>\n",
       "<tr><td></td><td>C89</td></tr>\n",
       "<tr><td></td><td>C90</td></tr>\n",
       "<tr><td></td><td>C91</td></tr>\n",
       "<tr><td></td><td>C92</td></tr>\n",
       "<tr><td></td><td>C93</td></tr>\n",
       "<tr><td></td><td>C95</td></tr>\n",
       "<tr><td></td><td>C97</td></tr>\n",
       "<tr><td></td><td>C99</td></tr>\n",
       "<tr><td></td><td>D</td></tr>\n",
       "<tr><td></td><td>D10 D12</td></tr>\n",
       "<tr><td></td><td>D11</td></tr>\n",
       "<tr><td></td><td>D15</td></tr>\n",
       "<tr><td></td><td>D17</td></tr>\n",
       "<tr><td></td><td>D19</td></tr>\n",
       "<tr><td></td><td>D20</td></tr>\n",
       "<tr><td></td><td>D21</td></tr>\n",
       "<tr><td></td><td>D22</td></tr>\n",
       "<tr><td></td><td>D26</td></tr>\n",
       "<tr><td></td><td>D28</td></tr>\n",
       "<tr><td></td><td>D30</td></tr>\n",
       "<tr><td></td><td>D33</td></tr>\n",
       "<tr><td></td><td>D34</td></tr>\n",
       "<tr><td></td><td>D35</td></tr>\n",
       "<tr><td></td><td>D36</td></tr>\n",
       "<tr><td></td><td>D37</td></tr>\n",
       "<tr><td></td><td>D38</td></tr>\n",
       "<tr><td></td><td>D40</td></tr>\n",
       "<tr><td></td><td>D43</td></tr>\n",
       "<tr><td></td><td>D45</td></tr>\n",
       "<tr><td></td><td>D46</td></tr>\n",
       "<tr><td></td><td>D47</td></tr>\n",
       "<tr><td></td><td>D48</td></tr>\n",
       "<tr><td></td><td>D49</td></tr>\n",
       "<tr><td></td><td>D50</td></tr>\n",
       "<tr><td></td><td>D56</td></tr>\n",
       "<tr><td></td><td>D6</td></tr>\n",
       "<tr><td></td><td>D7</td></tr>\n",
       "<tr><td></td><td>D9</td></tr>\n",
       "<tr><td></td><td>E10</td></tr>\n",
       "<tr><td></td><td>E101</td></tr>\n",
       "<tr><td></td><td>E12</td></tr>\n",
       "<tr><td></td><td>E121</td></tr>\n",
       "<tr><td></td><td>E17</td></tr>\n",
       "<tr><td></td><td>E24</td></tr>\n",
       "<tr><td></td><td>E25</td></tr>\n",
       "<tr><td></td><td>E31</td></tr>\n",
       "<tr><td></td><td>E33</td></tr>\n",
       "<tr><td></td><td>E34</td></tr>\n",
       "<tr><td></td><td>E36</td></tr>\n",
       "<tr><td></td><td>E38</td></tr>\n",
       "<tr><td></td><td>E39 E41</td></tr>\n",
       "<tr><td></td><td>E40</td></tr>\n",
       "<tr><td></td><td>E44</td></tr>\n",
       "<tr><td></td><td>E45</td></tr>\n",
       "<tr><td></td><td>E46</td></tr>\n",
       "<tr><td></td><td>E49</td></tr>\n",
       "<tr><td></td><td>E50</td></tr>\n",
       "<tr><td></td><td>E52</td></tr>\n",
       "<tr><td></td><td>E58</td></tr>\n",
       "<tr><td></td><td>E60</td></tr>\n",
       "<tr><td></td><td>E63</td></tr>\n",
       "<tr><td></td><td>E67</td></tr>\n",
       "<tr><td></td><td>E68</td></tr>\n",
       "<tr><td></td><td>E77</td></tr>\n",
       "<tr><td></td><td>E8</td></tr>\n",
       "<tr><td></td><td>F</td></tr>\n",
       "<tr><td></td><td>F E46</td></tr>\n",
       "<tr><td></td><td>F E57</td></tr>\n",
       "<tr><td></td><td>F E69</td></tr>\n",
       "<tr><td></td><td>F G63</td></tr>\n",
       "<tr><td></td><td>F G73</td></tr>\n",
       "<tr><td></td><td>F2</td></tr>\n",
       "<tr><td></td><td>F33</td></tr>\n",
       "<tr><td></td><td>F38</td></tr>\n",
       "<tr><td></td><td>F4</td></tr>\n",
       "<tr><td></td><td>G6</td></tr>\n",
       "<tr><td></td><td>T</td></tr>\n",
       "<tr><td><a name=\"embarked\">embarked</a></td><td>Cherbourg</td></tr>\n",
       "<tr><td></td><td>Queenstown</td></tr>\n",
       "<tr><td></td><td>Southampton</td></tr>\n",
       "<tr><td><a name=\"boat\">boat</a></td><td></td></tr>\n",
       "<tr><td></td><td>1</td></tr>\n",
       "<tr><td></td><td>10</td></tr>\n",
       "<tr><td></td><td>11</td></tr>\n",
       "<tr><td></td><td>12</td></tr>\n",
       "<tr><td></td><td>13</td></tr>\n",
       "<tr><td></td><td>13 15</td></tr>\n",
       "<tr><td></td><td>13 15 B</td></tr>\n",
       "<tr><td></td><td>14</td></tr>\n",
       "<tr><td></td><td>15</td></tr>\n",
       "<tr><td></td><td>15 16</td></tr>\n",
       "<tr><td></td><td>16</td></tr>\n",
       "<tr><td></td><td>2</td></tr>\n",
       "<tr><td></td><td>3</td></tr>\n",
       "<tr><td></td><td>4</td></tr>\n",
       "<tr><td></td><td>5</td></tr>\n",
       "<tr><td></td><td>5 7</td></tr>\n",
       "<tr><td></td><td>5 9</td></tr>\n",
       "<tr><td></td><td>6</td></tr>\n",
       "<tr><td></td><td>7</td></tr>\n",
       "<tr><td></td><td>8</td></tr>\n",
       "<tr><td></td><td>8 10</td></tr>\n",
       "<tr><td></td><td>9</td></tr>\n",
       "<tr><td></td><td>A</td></tr>\n",
       "<tr><td></td><td>B</td></tr>\n",
       "<tr><td></td><td>C</td></tr>\n",
       "<tr><td></td><td>C D</td></tr>\n",
       "<tr><td></td><td>D</td></tr>\n",
       "</TABLE>\n",
       "<hr>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(filename='data/titanic.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Women and children first?\n",
    "\n",
    "1. Use the `groupby` method to calculate the proportion of passengers that survived by sex.\n",
    "2. Calculate the same proportion, but by class and sex.\n",
    "3. Create age categories: children (under 14 years), adolescents (14-20), adult (21-64), and senior(65+), and calculate survival proportions by age category, class and sex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
